{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sofiamatias/learning-equality-model-sm?scriptVersionId=117773714\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"# Kaggle Challenge - Learning Equality","metadata":{"id":"88080462"}},{"cell_type":"markdown","source":"https://www.kaggle.com/competitions/learning-equality-curriculum-recommendations/overview\n\n## Goal of the Competition\n\nThe goal of this competition is to streamline the process of matching educational content to specific topics in a curriculum. You will develop an accurate and efficient model trained on a library of K-12 educational materials that have been organized into a variety of topic taxonomies. These materials are in diverse languages, and cover a wide range of topics, particularly in STEM (Science, Technology, Engineering, and Mathematics).\n\nYour work will enable students and educators to more readily access relevant educational content to support and supplement learning.","metadata":{"id":"e44162a6"}},{"cell_type":"markdown","source":"## Submission File\n\nFor each **topic_id** in the test set, you must predict a space-delimited list of recommended **content_ids** for that topic. The file should contain a header and have the following format:\n\n~~~\ntopic_id,content_ids\nt_00004da3a1b2,c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c_76231f9d0b5e\nt_00068291e9a4,c_639ea2ef9c95 c_89ce9367be10 c_ac1672cdcd2c c_ebb7fdf10a7e\nt_00069b63a70a,c_11a1dc0bfb99\n...\n~~~","metadata":{"id":"d827eb0b"}},{"cell_type":"markdown","source":"## Scoring\nMean F2 score","metadata":{"id":"de5f7ef4"}},{"cell_type":"markdown","source":"## Evaluation Metric - Efficiency Scoring\nWe compute a submission's efficiency score by:\n\n\\begin{equation} \\text{Efficiency} = \\frac{1}{ \\text{Benchmark} - \\max\\text{F2} }\\text{F2} + \\frac{1}{32400}\\text{RuntimeSeconds} \\end{equation}\n\n\nwhere **F2** is the submission's score on the main competition metric, **Benchmark** is the score of the benchmark sample_submission.csv, **maxF2** is the maximum  of all submissions on the Private Leaderboard, and **RuntimeSeconds** is the number of seconds it takes for the submission to be evaluated. The objective is to minimize the efficiency score.\n\nDuring the training period of the competition, you may see a leaderboard for the public test data in the following notebook, updated daily: Efficiency Leaderboard. After the competition ends, we will update this leaderboard with efficiency scores on the private data. During the training period, this leaderboard will show only the rank of each team, but not the complete score.","metadata":{"id":"b86e3e62"}},{"cell_type":"markdown","source":"# How To Solve This Challenge","metadata":{}},{"cell_type":"markdown","source":"## Model Train\n\n* Calculate embeddings: for topics (title, description) and contents (title, description and text), use SentenceTransformer. Split sentences by language.\n* Use KNN model: train model with content embeddings and use topic embeddings to predict content matches, use k=10, 20, 30, 50\n* Calculate F2 to choose best k.\n* Submit predictions\n* Set X_train, X_test, y_train, y_test: split by category (use 'aligned' for validation), set has_content = True for validation. Check dimensions\n* Use all features for X, including topic_id and content_id, topic_title and content_title. Use the KNN predictions to \"mount\" X and y. Check dimensions.\n* Use correlations to get y: if KNN topic-content match with correlations, y is 1, else is 0\n* Use SVM RBF or KNN again for multiclass classification\n* Use RandomizedSearch to get best hyperparameters. Use model score \"recall\". Split the dataset in languages for training: train model for each language individually\n* Calculate F2 and see if we've got improvements from KNN.\n* Submit predictions\n\n## Submissions\n\n* Use submission sample and get topics and contents\n* Apply KNN model to get topic-content matches. Get contents per topic\n* Filter \"good matches\" with second classification model\n* Compare predicts with submission sample and calculate F2\n\n## Efficiency\n\n* Use KNN and 2nd model without GPU and check if it takes a long time to calculate sample submissions","metadata":{}},{"cell_type":"markdown","source":"# Data","metadata":{"id":"e2cc9cb4"}},{"cell_type":"markdown","source":"## Imports","metadata":{"id":"eb712db6"}},{"cell_type":"code","source":"import sys, os\nsys.path.append(\"../input/sentence-transformer-package/sentence-transformers-2.2.2/sentence-transformers-2.2.2\") \nimport sentence_transformers","metadata":{"id":"2eBKbVKiQm-Z","execution":{"iopub.status.busy":"2023-01-30T23:05:44.038531Z","iopub.execute_input":"2023-01-30T23:05:44.038956Z","iopub.status.idle":"2023-01-30T23:05:45.221192Z","shell.execute_reply.started":"2023-01-30T23:05:44.038918Z","shell.execute_reply":"2023-01-30T23:05:45.21985Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install -q /kaggle/input/loguru-lib-ds/loguru-0.5.3-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:05:45.224438Z","iopub.execute_input":"2023-01-30T23:05:45.224817Z","iopub.status.idle":"2023-01-30T23:06:16.723356Z","shell.execute_reply.started":"2023-01-30T23:05:45.224783Z","shell.execute_reply":"2023-01-30T23:06:16.722162Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport string\nimport torch\nfrom pathlib import Path\nfrom sentence_transformers import SentenceTransformer, util\nfrom sklearn.metrics import precision_score, recall_score, fbeta_score\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import FunctionTransformer, OneHotEncoder\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_validate, train_test_split","metadata":{"id":"b5f3a3b6","execution":{"iopub.status.busy":"2023-01-30T23:06:16.725959Z","iopub.execute_input":"2023-01-30T23:06:16.726352Z","iopub.status.idle":"2023-01-30T23:06:16.73923Z","shell.execute_reply.started":"2023-01-30T23:06:16.726316Z","shell.execute_reply":"2023-01-30T23:06:16.738249Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"DATA_PATH = Path.cwd().parent.resolve()\ndrive_path = DATA_PATH / 'input'\nfiles_path = DATA_PATH / 'input/learning-equality-curriculum-recommendations'\ndataset_path = drive_path / 'learningequalityfiles'\nwork_path = DATA_PATH / 'working'\nmodel_path = '/kaggle/input/sentence-transformer-package/ST-all-MiniLM-L6-v2-trained/ST-all-MiniLM-L6-v2-trained'","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:11:09.194224Z","iopub.execute_input":"2023-01-30T23:11:09.194631Z","iopub.status.idle":"2023-01-30T23:11:09.201337Z","shell.execute_reply.started":"2023-01-30T23:11:09.194598Z","shell.execute_reply":"2023-01-30T23:11:09.200006Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Data Collection","metadata":{"id":"e55f4587"}},{"cell_type":"markdown","source":"## Load dataframes","metadata":{"id":"FJLGLdJ-wKZI"}},{"cell_type":"code","source":"def read_file_in_chunks(filename):\n        \n    list_chunks = []\n    chunksize = 10000\n    with pd.read_csv(filename, chunksize=chunksize, index_col=0) as reader:\n        for chunk in reader:\n            list_chunks.append(chunk)\n    df = pd.concat(list_chunks)\n    return df","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:12:47.870699Z","iopub.execute_input":"2023-01-30T23:12:47.871128Z","iopub.status.idle":"2023-01-30T23:12:47.877481Z","shell.execute_reply.started":"2023-01-30T23:12:47.871081Z","shell.execute_reply":"2023-01-30T23:12:47.876262Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# loading dataframes from existing .csv files\n\nprint (f\"\\nLoading dataframes...\")\n\nlow=0 #row number to start dataset subset\nhigh=1000 #row number to end dataset subset\n\ndf_content = pd.DataFrame([])\ndf_topics = pd.DataFrame([])\ndf_corr = pd.DataFrame([])\ndf_sample = pd.DataFrame([])\nfor path, subdirs, files in os.walk(drive_path):\n    for file in files:\n        if file.endswith(\".csv\") == True:\n            filepath = os.path.join(path, file)\n            df = read_file_in_chunks(filepath)\n            if set(['copyright_holder', 'kind']).issubset(df.columns):\n                df_content = df[low:high].fillna({\"title\": \"\", \"description\": \"\"})\n                display(df_content)\n                print (f\"\\nLoaded 'df_content' from {filepath}\")\n            elif set(['channel', 'parent']).issubset(df.columns):\n                df_topics = df[low:high].fillna({\"title\": \"\", \"description\": \"\"})\n                display(df_topics)\n                print (f\"\\nLoaded 'df_topics' from {filepath}\")\n            elif ('content_ids' in df.columns) and ('sample' not in file):\n                df_corr = df\n                display(df_corr)\n                print (f\"\\nLoaded 'df_corr' from {filepath}\")\n            if ('sample' in file):\n                df_sample = df\n                display(df_sample)\n                print (f\"\\nLoaded 'df_sample' from {filepath}\")","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:15:06.026159Z","iopub.execute_input":"2023-01-30T23:15:06.02659Z","iopub.status.idle":"2023-01-30T23:15:18.485684Z","shell.execute_reply.started":"2023-01-30T23:15:06.026553Z","shell.execute_reply":"2023-01-30T23:15:18.484251Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"\nLoading dataframes...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                                      content_ids\ntopic_id                                                         \nt_00004da3a1b2  c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c...\nt_00068291e9a4  c_639ea2ef9c95 c_89ce9367be10 c_ac1672cdcd2c c...\nt_00069b63a70a                                     c_11a1dc0bfb99\nt_0006d41a73a8  c_0c6473c3480d c_1c57a1316568 c_5e375cf14c47 c...\nt_4054df11a74e                      c_3695c5dc1df6 c_f2d184a98231","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content_ids</th>\n    </tr>\n    <tr>\n      <th>topic_id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>t_00004da3a1b2</th>\n      <td>c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c...</td>\n    </tr>\n    <tr>\n      <th>t_00068291e9a4</th>\n      <td>c_639ea2ef9c95 c_89ce9367be10 c_ac1672cdcd2c c...</td>\n    </tr>\n    <tr>\n      <th>t_00069b63a70a</th>\n      <td>c_11a1dc0bfb99</td>\n    </tr>\n    <tr>\n      <th>t_0006d41a73a8</th>\n      <td>c_0c6473c3480d c_1c57a1316568 c_5e375cf14c47 c...</td>\n    </tr>\n    <tr>\n      <th>t_4054df11a74e</th>\n      <td>c_3695c5dc1df6 c_f2d184a98231</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nLoaded 'df_sample' from /kaggle/input/learning-equality-curriculum-recommendations/sample_submission.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                                            title  \\\nid                                                                  \nt_00004da3a1b2                         Откриването на резисторите   \nt_000095e03056             Unit 3.3 Enlargements and Similarities   \nt_00068291e9a4                    Entradas e saídas de uma função   \nt_00069b63a70a                                        Transcripts   \nt_0006d41a73a8  Графики на експоненциални функции (Алгебра 2 н...   \n...                                                           ...   \nt_0353f7c74647                        Peninsular Plateau of India   \nt_0355125ac080                              Techniques of Control   \nt_035617cf7ce2               2.2 - Iterative patterns & processes   \nt_03583877314a            5.2.4 Theorems on Similar plane figuers   \nt_03587f1794c6                                             7: DNA   \n\n                                                      description channel  \\\nid                                                                          \nt_00004da3a1b2  Изследване на материали, които предизвикват на...  000cf7   \nt_000095e03056                                                     b3f329   \nt_00068291e9a4               Entenda um pouco mais sobre funções.  8e286a   \nt_00069b63a70a                                                     6e3ba4   \nt_0006d41a73a8  Научи повече за графиките на сложните показате...  000cf7   \n...                                                           ...     ...   \nt_0353f7c74647                                                     ef2088   \nt_0355125ac080                                                     ef2088   \nt_035617cf7ce2                                                     c6dab5   \nt_03583877314a                                                     5d4a02   \nt_03587f1794c6                                                     ebc86c   \n\n                    category  level language          parent  has_content  \nid                                                                         \nt_00004da3a1b2        source      4       bg  t_16e29365b50d         True  \nt_000095e03056       aligned      2       en  t_aa32fb6252dc        False  \nt_00068291e9a4        source      4       pt  t_d14b6c2a2b70         True  \nt_00069b63a70a        source      3       en  t_4054df11a74e         True  \nt_0006d41a73a8        source      4       bg  t_e2452e21d252         True  \n...                      ...    ...      ...             ...          ...  \nt_0353f7c74647  supplemental      5       en  t_cc5779490262         True  \nt_0355125ac080  supplemental      5       en  t_96a9a6b73988         True  \nt_035617cf7ce2        source      3       en  t_41e08e0fb197        False  \nt_03583877314a       aligned      4       en  t_e035ff1aed4b         True  \nt_03587f1794c6  supplemental      4       en  t_d8f9c73e85e4         True  \n\n[1000 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>description</th>\n      <th>channel</th>\n      <th>category</th>\n      <th>level</th>\n      <th>language</th>\n      <th>parent</th>\n      <th>has_content</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>t_00004da3a1b2</th>\n      <td>Откриването на резисторите</td>\n      <td>Изследване на материали, които предизвикват на...</td>\n      <td>000cf7</td>\n      <td>source</td>\n      <td>4</td>\n      <td>bg</td>\n      <td>t_16e29365b50d</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>t_000095e03056</th>\n      <td>Unit 3.3 Enlargements and Similarities</td>\n      <td></td>\n      <td>b3f329</td>\n      <td>aligned</td>\n      <td>2</td>\n      <td>en</td>\n      <td>t_aa32fb6252dc</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>t_00068291e9a4</th>\n      <td>Entradas e saídas de uma função</td>\n      <td>Entenda um pouco mais sobre funções.</td>\n      <td>8e286a</td>\n      <td>source</td>\n      <td>4</td>\n      <td>pt</td>\n      <td>t_d14b6c2a2b70</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>t_00069b63a70a</th>\n      <td>Transcripts</td>\n      <td></td>\n      <td>6e3ba4</td>\n      <td>source</td>\n      <td>3</td>\n      <td>en</td>\n      <td>t_4054df11a74e</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>t_0006d41a73a8</th>\n      <td>Графики на експоненциални функции (Алгебра 2 н...</td>\n      <td>Научи повече за графиките на сложните показате...</td>\n      <td>000cf7</td>\n      <td>source</td>\n      <td>4</td>\n      <td>bg</td>\n      <td>t_e2452e21d252</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>t_0353f7c74647</th>\n      <td>Peninsular Plateau of India</td>\n      <td></td>\n      <td>ef2088</td>\n      <td>supplemental</td>\n      <td>5</td>\n      <td>en</td>\n      <td>t_cc5779490262</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>t_0355125ac080</th>\n      <td>Techniques of Control</td>\n      <td></td>\n      <td>ef2088</td>\n      <td>supplemental</td>\n      <td>5</td>\n      <td>en</td>\n      <td>t_96a9a6b73988</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>t_035617cf7ce2</th>\n      <td>2.2 - Iterative patterns &amp; processes</td>\n      <td></td>\n      <td>c6dab5</td>\n      <td>source</td>\n      <td>3</td>\n      <td>en</td>\n      <td>t_41e08e0fb197</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>t_03583877314a</th>\n      <td>5.2.4 Theorems on Similar plane figuers</td>\n      <td></td>\n      <td>5d4a02</td>\n      <td>aligned</td>\n      <td>4</td>\n      <td>en</td>\n      <td>t_e035ff1aed4b</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>t_03587f1794c6</th>\n      <td>7: DNA</td>\n      <td></td>\n      <td>ebc86c</td>\n      <td>supplemental</td>\n      <td>4</td>\n      <td>en</td>\n      <td>t_d8f9c73e85e4</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 8 columns</p>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nLoaded 'df_topics' from /kaggle/input/learning-equality-curriculum-recommendations/topics.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                                      content_ids\ntopic_id                                                         \nt_00004da3a1b2  c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c...\nt_00068291e9a4  c_639ea2ef9c95 c_89ce9367be10 c_ac1672cdcd2c c...\nt_00069b63a70a                                     c_11a1dc0bfb99\nt_0006d41a73a8  c_0c6473c3480d c_1c57a1316568 c_5e375cf14c47 c...\nt_0008768bdee6       c_34e1424229b4 c_7d1a964d66d5 c_aab93ee667f4\n...                                                           ...\nt_fff830472691                      c_61fb63326e5d c_8f224e321c87\nt_fff9e5407d13  c_026db653a269 c_0fb048a6412c c_20de77522603 c...\nt_fffbe1d5d43c                      c_46f852a49c08 c_6659207b25d5\nt_fffe14f1be1e                                     c_cece166bad6a\nt_fffe811a6da9                                     c_92b8fad372ee\n\n[61517 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content_ids</th>\n    </tr>\n    <tr>\n      <th>topic_id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>t_00004da3a1b2</th>\n      <td>c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c...</td>\n    </tr>\n    <tr>\n      <th>t_00068291e9a4</th>\n      <td>c_639ea2ef9c95 c_89ce9367be10 c_ac1672cdcd2c c...</td>\n    </tr>\n    <tr>\n      <th>t_00069b63a70a</th>\n      <td>c_11a1dc0bfb99</td>\n    </tr>\n    <tr>\n      <th>t_0006d41a73a8</th>\n      <td>c_0c6473c3480d c_1c57a1316568 c_5e375cf14c47 c...</td>\n    </tr>\n    <tr>\n      <th>t_0008768bdee6</th>\n      <td>c_34e1424229b4 c_7d1a964d66d5 c_aab93ee667f4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>t_fff830472691</th>\n      <td>c_61fb63326e5d c_8f224e321c87</td>\n    </tr>\n    <tr>\n      <th>t_fff9e5407d13</th>\n      <td>c_026db653a269 c_0fb048a6412c c_20de77522603 c...</td>\n    </tr>\n    <tr>\n      <th>t_fffbe1d5d43c</th>\n      <td>c_46f852a49c08 c_6659207b25d5</td>\n    </tr>\n    <tr>\n      <th>t_fffe14f1be1e</th>\n      <td>c_cece166bad6a</td>\n    </tr>\n    <tr>\n      <th>t_fffe811a6da9</th>\n      <td>c_92b8fad372ee</td>\n    </tr>\n  </tbody>\n</table>\n<p>61517 rows × 1 columns</p>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nLoaded 'df_corr' from /kaggle/input/learning-equality-curriculum-recommendations/correlations.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                                            title  \\\nid                                                                  \nc_00002381196d   Sumar números de varios dígitos: 48,029+233,930    \nc_000087304a9e                     Trovare i fattori di un numero   \nc_0000ad142ddb                            Sumar curvas de demanda   \nc_0000c03adc8d                                Nado de aproximação   \nc_00016694ea2a                   geometry-m3-topic-a-overview.pdf   \n...                                                           ...   \nc_01b62d0b9b40  Cómo pegar un ensamble de caja y espiga o de c...   \nc_01b6e399bea7  Lección 29: La energía lumínica y energía química   \nc_01b71b0ee2ba  Transformation et parallélogramme - Triangles ...   \nc_01b749c8ebc8                                          Lección 1   \nc_01b7b5d2a012  Mini voces al aire, otra alternativa de aprend...   \n\n                                                      description      kind  \\\nid                                                                            \nc_00002381196d  Suma 48,029+233,930 mediante el algoritmo está...     video   \nc_000087304a9e                    Sal trova i fattori di 120.\\n\\n     video   \nc_0000ad142ddb                  Cómo añadir curvas de demanda\\n\\n     video   \nc_0000c03adc8d  Neste vídeo você vai aprender o nado de aproxi...  document   \nc_00016694ea2a                   geometry-m3-topic-a-overview.pdf  document   \n...                                                           ...       ...   \nc_01b62d0b9b40  Con este vídeo aprenderás a pegar piezas de ma...  document   \nc_01b6e399bea7                                                     exercise   \nc_01b71b0ee2ba                                                        html5   \nc_01b749c8ebc8  Lectura de textos nuevos sobre ranas extrañas ...  document   \nc_01b7b5d2a012                                                     document   \n\n                                                             text language  \\\nid                                                                           \nc_00002381196d                                                NaN       es   \nc_000087304a9e                                                NaN       it   \nc_0000ad142ddb                                                NaN       es   \nc_0000c03adc8d  \\nNado de aproximação\\nSaber nadar nas ondas ...       pt   \nc_00016694ea2a  Estándares Comunes del Estado de Nueva York\\n\\...       es   \n...                                                           ...      ...   \nc_01b62d0b9b40  \\nCómo pegar un ensamble de caja\\ny espiga o ...       es   \nc_01b6e399bea7  La fotosíntesis provocó el cambio en la atmósf...       es   \nc_01b71b0ee2ba                                                NaN       fr   \nc_01b749c8ebc8  Grade 3: Module 2A: Unit 3: Lesson 1\\nReading ...       es   \nc_01b7b5d2a012  4\\n\\nMini voces al aire, otra alternativa\\nde ...       es   \n\n                                                 copyright_holder      license  \nid                                                                              \nc_00002381196d                                                NaN          NaN  \nc_000087304a9e                                                NaN          NaN  \nc_0000ad142ddb                                                NaN          NaN  \nc_0000c03adc8d                                   Sikana Education  CC BY-NC-ND  \nc_00016694ea2a                                          Engage NY  CC BY-NC-SA  \n...                                                           ...          ...  \nc_01b62d0b9b40                                   Sikana Education  CC BY-NC-ND  \nc_01b6e399bea7  Publicado por el Lic. Edelberto Andino(edelber...  CC BY-NC-SA  \nc_01b71b0ee2ba                                                NaN          NaN  \nc_01b749c8ebc8                                          Engage NY  CC BY-NC-SA  \nc_01b7b5d2a012  Publicado por el Lic. Edelberto Andino(edelber...  CC BY-NC-SA  \n\n[1000 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>description</th>\n      <th>kind</th>\n      <th>text</th>\n      <th>language</th>\n      <th>copyright_holder</th>\n      <th>license</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>c_00002381196d</th>\n      <td>Sumar números de varios dígitos: 48,029+233,930</td>\n      <td>Suma 48,029+233,930 mediante el algoritmo está...</td>\n      <td>video</td>\n      <td>NaN</td>\n      <td>es</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>c_000087304a9e</th>\n      <td>Trovare i fattori di un numero</td>\n      <td>Sal trova i fattori di 120.\\n\\n</td>\n      <td>video</td>\n      <td>NaN</td>\n      <td>it</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>c_0000ad142ddb</th>\n      <td>Sumar curvas de demanda</td>\n      <td>Cómo añadir curvas de demanda\\n\\n</td>\n      <td>video</td>\n      <td>NaN</td>\n      <td>es</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>c_0000c03adc8d</th>\n      <td>Nado de aproximação</td>\n      <td>Neste vídeo você vai aprender o nado de aproxi...</td>\n      <td>document</td>\n      <td>\\nNado de aproximação\\nSaber nadar nas ondas ...</td>\n      <td>pt</td>\n      <td>Sikana Education</td>\n      <td>CC BY-NC-ND</td>\n    </tr>\n    <tr>\n      <th>c_00016694ea2a</th>\n      <td>geometry-m3-topic-a-overview.pdf</td>\n      <td>geometry-m3-topic-a-overview.pdf</td>\n      <td>document</td>\n      <td>Estándares Comunes del Estado de Nueva York\\n\\...</td>\n      <td>es</td>\n      <td>Engage NY</td>\n      <td>CC BY-NC-SA</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>c_01b62d0b9b40</th>\n      <td>Cómo pegar un ensamble de caja y espiga o de c...</td>\n      <td>Con este vídeo aprenderás a pegar piezas de ma...</td>\n      <td>document</td>\n      <td>\\nCómo pegar un ensamble de caja\\ny espiga o ...</td>\n      <td>es</td>\n      <td>Sikana Education</td>\n      <td>CC BY-NC-ND</td>\n    </tr>\n    <tr>\n      <th>c_01b6e399bea7</th>\n      <td>Lección 29: La energía lumínica y energía química</td>\n      <td></td>\n      <td>exercise</td>\n      <td>La fotosíntesis provocó el cambio en la atmósf...</td>\n      <td>es</td>\n      <td>Publicado por el Lic. Edelberto Andino(edelber...</td>\n      <td>CC BY-NC-SA</td>\n    </tr>\n    <tr>\n      <th>c_01b71b0ee2ba</th>\n      <td>Transformation et parallélogramme - Triangles ...</td>\n      <td></td>\n      <td>html5</td>\n      <td>NaN</td>\n      <td>fr</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>c_01b749c8ebc8</th>\n      <td>Lección 1</td>\n      <td>Lectura de textos nuevos sobre ranas extrañas ...</td>\n      <td>document</td>\n      <td>Grade 3: Module 2A: Unit 3: Lesson 1\\nReading ...</td>\n      <td>es</td>\n      <td>Engage NY</td>\n      <td>CC BY-NC-SA</td>\n    </tr>\n    <tr>\n      <th>c_01b7b5d2a012</th>\n      <td>Mini voces al aire, otra alternativa de aprend...</td>\n      <td></td>\n      <td>document</td>\n      <td>4\\n\\nMini voces al aire, otra alternativa\\nde ...</td>\n      <td>es</td>\n      <td>Publicado por el Lic. Edelberto Andino(edelber...</td>\n      <td>CC BY-NC-SA</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 7 columns</p>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nLoaded 'df_content' from /kaggle/input/learning-equality-curriculum-recommendations/content.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                                      content_ids\ntopic_id                                                         \nt_00004da3a1b2  c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c...\nt_00068291e9a4  c_639ea2ef9c95 c_89ce9367be10 c_ac1672cdcd2c c...\nt_00069b63a70a                                     c_11a1dc0bfb99\nt_0006d41a73a8  c_0c6473c3480d c_1c57a1316568 c_5e375cf14c47 c...\nt_0008768bdee6       c_34e1424229b4 c_7d1a964d66d5 c_aab93ee667f4\n...                                                           ...\nt_fff830472691                      c_61fb63326e5d c_8f224e321c87\nt_fff9e5407d13  c_026db653a269 c_0fb048a6412c c_20de77522603 c...\nt_fffbe1d5d43c                      c_46f852a49c08 c_6659207b25d5\nt_fffe14f1be1e                                     c_cece166bad6a\nt_fffe811a6da9                                     c_92b8fad372ee\n\n[61517 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content_ids</th>\n    </tr>\n    <tr>\n      <th>topic_id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>t_00004da3a1b2</th>\n      <td>c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c...</td>\n    </tr>\n    <tr>\n      <th>t_00068291e9a4</th>\n      <td>c_639ea2ef9c95 c_89ce9367be10 c_ac1672cdcd2c c...</td>\n    </tr>\n    <tr>\n      <th>t_00069b63a70a</th>\n      <td>c_11a1dc0bfb99</td>\n    </tr>\n    <tr>\n      <th>t_0006d41a73a8</th>\n      <td>c_0c6473c3480d c_1c57a1316568 c_5e375cf14c47 c...</td>\n    </tr>\n    <tr>\n      <th>t_0008768bdee6</th>\n      <td>c_34e1424229b4 c_7d1a964d66d5 c_aab93ee667f4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>t_fff830472691</th>\n      <td>c_61fb63326e5d c_8f224e321c87</td>\n    </tr>\n    <tr>\n      <th>t_fff9e5407d13</th>\n      <td>c_026db653a269 c_0fb048a6412c c_20de77522603 c...</td>\n    </tr>\n    <tr>\n      <th>t_fffbe1d5d43c</th>\n      <td>c_46f852a49c08 c_6659207b25d5</td>\n    </tr>\n    <tr>\n      <th>t_fffe14f1be1e</th>\n      <td>c_cece166bad6a</td>\n    </tr>\n    <tr>\n      <th>t_fffe811a6da9</th>\n      <td>c_92b8fad372ee</td>\n    </tr>\n  </tbody>\n</table>\n<p>61517 rows × 1 columns</p>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nLoaded 'df_corr' from /kaggle/input/learningequalityfiles/correlations.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"#Sampling 'df_topics' and 'df_content' with sample_submission\nif ~df_sample.empty:\n    df_topics = df_topics.merge(df_sample, how='inner', left_index=True, right_index=True)\n    print (f\"\\nFiltered 'df_topics' according to 'sample_submission'\")\nif df_content.empty and df_topics.empty:\n    print ('Error: there are no topics or content files to work with')\n    quit()","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:15:18.488133Z","iopub.execute_input":"2023-01-30T23:15:18.488641Z","iopub.status.idle":"2023-01-30T23:15:18.516171Z","shell.execute_reply.started":"2023-01-30T23:15:18.488594Z","shell.execute_reply":"2023-01-30T23:15:18.514715Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"\nFiltered 'df_topics' according to 'sample_submission'\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"                                                            title  \\\nt_00004da3a1b2                         Откриването на резисторите   \nt_00068291e9a4                    Entradas e saídas de uma função   \nt_00069b63a70a                                        Transcripts   \nt_0006d41a73a8  Графики на експоненциални функции (Алгебра 2 н...   \n\n                                                      description channel  \\\nt_00004da3a1b2  Изследване на материали, които предизвикват на...  000cf7   \nt_00068291e9a4               Entenda um pouco mais sobre funções.  8e286a   \nt_00069b63a70a                                                     6e3ba4   \nt_0006d41a73a8  Научи повече за графиките на сложните показате...  000cf7   \n\n               category  level language          parent  has_content  \\\nt_00004da3a1b2   source      4       bg  t_16e29365b50d         True   \nt_00068291e9a4   source      4       pt  t_d14b6c2a2b70         True   \nt_00069b63a70a   source      3       en  t_4054df11a74e         True   \nt_0006d41a73a8   source      4       bg  t_e2452e21d252         True   \n\n                                                      content_ids  \nt_00004da3a1b2  c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c...  \nt_00068291e9a4  c_639ea2ef9c95 c_89ce9367be10 c_ac1672cdcd2c c...  \nt_00069b63a70a                                     c_11a1dc0bfb99  \nt_0006d41a73a8  c_0c6473c3480d c_1c57a1316568 c_5e375cf14c47 c...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>description</th>\n      <th>channel</th>\n      <th>category</th>\n      <th>level</th>\n      <th>language</th>\n      <th>parent</th>\n      <th>has_content</th>\n      <th>content_ids</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>t_00004da3a1b2</th>\n      <td>Откриването на резисторите</td>\n      <td>Изследване на материали, които предизвикват на...</td>\n      <td>000cf7</td>\n      <td>source</td>\n      <td>4</td>\n      <td>bg</td>\n      <td>t_16e29365b50d</td>\n      <td>True</td>\n      <td>c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c...</td>\n    </tr>\n    <tr>\n      <th>t_00068291e9a4</th>\n      <td>Entradas e saídas de uma função</td>\n      <td>Entenda um pouco mais sobre funções.</td>\n      <td>8e286a</td>\n      <td>source</td>\n      <td>4</td>\n      <td>pt</td>\n      <td>t_d14b6c2a2b70</td>\n      <td>True</td>\n      <td>c_639ea2ef9c95 c_89ce9367be10 c_ac1672cdcd2c c...</td>\n    </tr>\n    <tr>\n      <th>t_00069b63a70a</th>\n      <td>Transcripts</td>\n      <td></td>\n      <td>6e3ba4</td>\n      <td>source</td>\n      <td>3</td>\n      <td>en</td>\n      <td>t_4054df11a74e</td>\n      <td>True</td>\n      <td>c_11a1dc0bfb99</td>\n    </tr>\n    <tr>\n      <th>t_0006d41a73a8</th>\n      <td>Графики на експоненциални функции (Алгебра 2 н...</td>\n      <td>Научи повече за графиките на сложните показате...</td>\n      <td>000cf7</td>\n      <td>source</td>\n      <td>4</td>\n      <td>bg</td>\n      <td>t_e2452e21d252</td>\n      <td>True</td>\n      <td>c_0c6473c3480d c_1c57a1316568 c_5e375cf14c47 c...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# load 'correlations' data into pandas dataframe\n# Restructure 'df_corr' (correlations): explode the target column to be more practical to use - one topic -> one content\ny = df_corr.copy()\ny['content_ids'] = y.content_ids.str.split(' ')\ny = y.explode('content_ids')\ny.reset_index(inplace=True)\nprint (f\"\\nChanged 'df_corr' to exploded 'y'\")\ndisplay(y)","metadata":{"id":"29667ed7","outputId":"8f3c7bd9-ebd8-4729-a901-ba908e7739fb","execution":{"iopub.status.busy":"2023-01-30T23:15:51.084623Z","iopub.execute_input":"2023-01-30T23:15:51.085034Z","iopub.status.idle":"2023-01-30T23:15:51.225792Z","shell.execute_reply.started":"2023-01-30T23:15:51.084998Z","shell.execute_reply":"2023-01-30T23:15:51.224541Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"\nChanged 'df_corr' to exploded 'y'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"              topic_id     content_ids\n0       t_00004da3a1b2  c_1108dd0c7a5d\n1       t_00004da3a1b2  c_376c5a8eb028\n2       t_00004da3a1b2  c_5bc0e1e2cba0\n3       t_00004da3a1b2  c_76231f9d0b5e\n4       t_00068291e9a4  c_639ea2ef9c95\n...                ...             ...\n279914  t_fff9e5407d13  c_d64037a72376\n279915  t_fffbe1d5d43c  c_46f852a49c08\n279916  t_fffbe1d5d43c  c_6659207b25d5\n279917  t_fffe14f1be1e  c_cece166bad6a\n279918  t_fffe811a6da9  c_92b8fad372ee\n\n[279919 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic_id</th>\n      <th>content_ids</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>t_00004da3a1b2</td>\n      <td>c_1108dd0c7a5d</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>t_00004da3a1b2</td>\n      <td>c_376c5a8eb028</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>t_00004da3a1b2</td>\n      <td>c_5bc0e1e2cba0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>t_00004da3a1b2</td>\n      <td>c_76231f9d0b5e</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>t_00068291e9a4</td>\n      <td>c_639ea2ef9c95</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>279914</th>\n      <td>t_fff9e5407d13</td>\n      <td>c_d64037a72376</td>\n    </tr>\n    <tr>\n      <th>279915</th>\n      <td>t_fffbe1d5d43c</td>\n      <td>c_46f852a49c08</td>\n    </tr>\n    <tr>\n      <th>279916</th>\n      <td>t_fffbe1d5d43c</td>\n      <td>c_6659207b25d5</td>\n    </tr>\n    <tr>\n      <th>279917</th>\n      <td>t_fffe14f1be1e</td>\n      <td>c_cece166bad6a</td>\n    </tr>\n    <tr>\n      <th>279918</th>\n      <td>t_fffe811a6da9</td>\n      <td>c_92b8fad372ee</td>\n    </tr>\n  </tbody>\n</table>\n<p>279919 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Create Topic Breadcrumbs Functions","metadata":{}},{"cell_type":"code","source":"# define some helper functions and classes to aid with data traversal\n\ndef get_topic_breadcrumbs (df_topic):\n    print (f\"Creating breadcrumbs...\")\n    topic_breadcrumbs=[]\n    topic_ids=[]\n    if 'topic_id' == df_topics.index.name:\n        col_name = 'topic_id'\n    else:\n        col_name = 'id'\n    for i, topic in enumerate(df_topic.index):\n        if (i % 5000 == 0) and (i > 0):\n            print (f'Created {i} breadcrumbs...')\n        if df_topic.loc[topic].parent in df_topic.index:\n            topic_ids.append (topic)\n            topic_breadcrumbs.append (Topic(topic).get_breadcrumbs(separator=' '))\n    print (f\"Creating dataframe from breadcrumbs 'df_topics_breadcrumbs'...\")\n    df_topics_breadcrumbs = pd.DataFrame (topic_breadcrumbs, \n                                          index = topic_ids,\n                                          columns = ['topic_breadcrumbs'])\n    return df_topics_breadcrumbs\n\n\ndef print_markdown(md):\n    display(Markdown(md))\n\nclass Topic:\n    def __init__(self, topic_id):\n        self.id = topic_id\n\n    @property\n    def parent(self):\n        parent_id = df_topics.loc[self.id].parent\n        if pd.isna(parent_id):\n            return None\n        else:\n            return Topic(parent_id)\n\n    @property\n    def ancestors(self):\n        ancestors = []\n        parent = self.parent\n        while (parent is not None) and (parent.id in df_topics.index):\n            ancestors.append(parent)\n            parent = parent.parent\n        return ancestors\n\n    @property\n    def siblings(self):\n        if not self.parent:\n            return []\n        else:\n            return [topic for topic in self.parent.children if topic != self]\n\n    @property\n    def content(self):\n        if self.id in df_corr.index:\n            return [ContentItem(content_id) for content_id in df_corr.loc[self.id].content_ids.split()]\n        else:\n            return tuple([]) if self.has_content else []\n\n    def get_breadcrumbs(self, separator=\" >> \", include_self=True, include_root=True):\n        ancestors = self.ancestors\n        if include_self:\n            ancestors = [self] + ancestors\n        if not include_root:\n            ancestors = ancestors[:-1]\n        return separator.join(reversed([a.title for a in ancestors]))\n\n    @property\n    def children(self):\n        return [Topic(child_id) for child_id in df_topics[df_topics.parent == self.id].index]\n\n    def subtree_markdown(self, depth=0):\n        markdown = \"  \" * depth + \"- \" + self.title + \"\\n\"\n        for child in self.children:\n            markdown += child.subtree_markdown(depth=depth + 1)\n        for content in self.content:\n            markdown += (\"  \" * (depth + 1) + \"- \" + \"[\" + content.kind.title() + \"] \" + content.title) + \"\\n\"\n        return markdown\n\n    def __eq__(self, other):\n        if not isinstance(other, Topic):\n            return False\n        return self.id == other.id\n\n    def __getattr__(self, name):\n        return df_topics.loc[self.id][name]\n\n    def __str__(self):\n        return self.title\n    \n    def __repr__(self):\n        return f\"<Topic(id={self.id}, title=\\\"{self.title}\\\")>\"\n\n\nclass ContentItem:\n    def __init__(self, content_id):\n        self.id = content_id\n\n    @property\n    def topics(self):\n        return [Topic(topic_id) for topic_id in df_topics.loc[df_corr[df_corr.content_ids.str.contains(self.id)].index].index]\n\n    def __getattr__(self, name):\n        return content_df.loc[self.id][name]\n\n    def __str__(self):\n        return self.title\n    \n    def __repr__(self):\n        return f\"<ContentItem(id={self.id}, title=\\\"{self.title}\\\")>\"\n\n    def __eq__(self, other):\n        if not isinstance(other, ContentItem):\n            return False\n        return self.id == other.id\n\n    def get_all_breadcrumbs(self, separator=\" >> \", include_root=True):\n        breadcrumbs = []\n        for topic in self.topics:\n            new_breadcrumb = topic.get_breadcrumbs(separator=separator, include_root=include_root)\n            if new_breadcrumb:\n                new_breadcrumb = new_breadcrumb + separator + self.title\n            else:\n                new_breadcrumb = self.title\n            breadcrumbs.append(new_breadcrumb)\n        return breadcrumbs","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:15:55.63163Z","iopub.execute_input":"2023-01-30T23:15:55.632032Z","iopub.status.idle":"2023-01-30T23:15:55.659721Z","shell.execute_reply.started":"2023-01-30T23:15:55.631997Z","shell.execute_reply":"2023-01-30T23:15:55.658255Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"## Data Cleaning","metadata":{"id":"CP4lmcnV20yH"}},{"cell_type":"markdown","source":"## Data cleaning params","metadata":{"id":"rjw9Pdqqlzdp"}},{"cell_type":"code","source":"levels = {1: 'one', 2: 'two', 3: 'three', 4: 'four', 5: 'five', 6: 'six', 7: 'seven', 8: 'eight',\n          9: 'nine', 10: 'ten', 0: 'zero'}\ntopics_cols = ['title', 'description', 'topic_breadcrumbs']\ncontent_cols = ['title', 'description', 'text']\ncat_for_val = 'aligned'\nprint (f\"\\nLoaded cleaning parameters\")","metadata":{"id":"qpgsrMQyl10Y","execution":{"iopub.status.busy":"2023-01-30T23:15:56.808979Z","iopub.execute_input":"2023-01-30T23:15:56.8094Z","iopub.status.idle":"2023-01-30T23:15:56.817083Z","shell.execute_reply.started":"2023-01-30T23:15:56.809365Z","shell.execute_reply":"2023-01-30T23:15:56.815978Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"\nLoaded cleaning parameters\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Data cleaning functions","metadata":{"id":"Hwk6JtmRbn42"}},{"cell_type":"code","source":"# Clean up text\ndef clean_text(text_col):\n    \"\"\"\n    Clean ponctuation and special chars from a dataframe column\n    \"\"\"\n    punctuations = string.punctuation\n    text_col = text_col.str.replace('\\W', ' ', regex=True)\n    for punct in string.punctuation:\n        text_col = text_col.str.replace(punct, ' ', regex=True)\n    return text_col","metadata":{"id":"xRgKUBVjbstB","execution":{"iopub.status.busy":"2023-01-30T23:15:57.543046Z","iopub.execute_input":"2023-01-30T23:15:57.543462Z","iopub.status.idle":"2023-01-30T23:15:57.550488Z","shell.execute_reply.started":"2023-01-30T23:15:57.543431Z","shell.execute_reply":"2023-01-30T23:15:57.549272Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"### Topics\n\n*   Changing 'level' values from integers to strings\n*   Clean strings: ponctuation and special chars (\\n\\t...)\n*   Sort values by language","metadata":{"id":"WmkMQLZHaDmd"}},{"cell_type":"code","source":"def build_topic_features (topics_df, df_topics_breadcrumbs, levels, topic_cols):\n    \"\"\"\n    Create 'topics_features' from df_topics, clean parameters and functions\n    \"\"\"\n    print (f\"\\nCreating and cleaning topic features...\")\n    topics_features = topics_df.copy()\n    topics_features = topics_features.replace ({'level': levels})\n    topics_features = topics_features.merge (df_topic_breadcrumbs, how='outer', right_index=True, left_index=True)\n    for col in topics_cols:\n        topics_features[col] = clean_text(topics_features[col])\n    topics_features['sentences'] = topics_features[topics_cols].apply(lambda x: '.'.join(x.dropna().astype(str)), axis=1)\n    topics_features = topics_features.drop(columns=['parent'] + topics_cols) \n    print (f\"\\nCreated 'topic_features'\")\n    display (topics_features.head())\n    \n    return topics_features\n","metadata":{"id":"prh6uaPXlyMr","execution":{"iopub.status.busy":"2023-01-30T23:15:58.317841Z","iopub.execute_input":"2023-01-30T23:15:58.318293Z","iopub.status.idle":"2023-01-30T23:15:58.327877Z","shell.execute_reply.started":"2023-01-30T23:15:58.318257Z","shell.execute_reply":"2023-01-30T23:15:58.326224Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"### Contents\n\n\n*   Remove columns 'copyright_holder' and 'language' (for 'language' assume that topic-content match with correlations is same language)\n*   Clean strings: ponctuation and special chars (\\n\\t...)","metadata":{"id":"m-sO4fCibFIb"}},{"cell_type":"code","source":"def build_content_features (content_df, content_cols):\n    \"\"\"\n    Create 'content_features' from df_content, clean parameters and functions\n    \"\"\"\n    print (f\"\\nCreating and cleaning content features...\")\n    content_features = content_df.copy()\n    for col in content_cols:\n        content_features[col] = clean_text(content_features[col])\n    content_features['sentences'] =  content_features[content_cols].apply(lambda x: '.'.join(x.dropna().astype(str)), axis=1)\n    content_features = content_features.drop(columns=['copyright_holder', 'license'] + content_cols)\n    print (f\"\\nCreated 'content_features'\")\n    display (content_features.head())\n    \n    return content_features","metadata":{"id":"fa3508db","execution":{"iopub.status.busy":"2023-01-30T23:15:59.003793Z","iopub.execute_input":"2023-01-30T23:15:59.005524Z","iopub.status.idle":"2023-01-30T23:15:59.013741Z","shell.execute_reply.started":"2023-01-30T23:15:59.005461Z","shell.execute_reply":"2023-01-30T23:15:59.012535Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"# Model Train","metadata":{}},{"cell_type":"markdown","source":"### Models params","metadata":{"id":"iI-1sqraZhLv"}},{"cell_type":"code","source":"#General\ndevice = 'cpu'\nif torch.cuda.is_available():\n    device = torch.device('cuda:0')\n#Sentence Transformer\nall_mini = 'all-MiniLM-L6-v2'\nparaphrase = 'paraphrase-multilingual-MiniLM-L12-v2'\ntrained_model = model_path\n# KNN\nk = [5,10,20,30,50,100]\nalg = 'kd_tree' #'ball_tree','brute'\nleaf = 10\nprint (f\"\\nLoaded models parameters\")","metadata":{"id":"HJou8xoM4H2A","execution":{"iopub.status.busy":"2023-01-30T23:16:00.063797Z","iopub.execute_input":"2023-01-30T23:16:00.064246Z","iopub.status.idle":"2023-01-30T23:16:00.072237Z","shell.execute_reply.started":"2023-01-30T23:16:00.064208Z","shell.execute_reply":"2023-01-30T23:16:00.070564Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"\nLoaded models parameters\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Scoring functions","metadata":{}},{"cell_type":"code","source":"def model_scoring (y_test, y_pred, average='macro'):\n    \"\"\"\n    Calculate precision, recall and f2-score for y_test and y_pred\n    \"\"\"\n    precision = precision_score(y_test['content_ids'], y_pred['content_ids'], average=average)\n    print ('Precision:', precision)\n    recall = recall_score(y_test['content_ids'], y_pred['content_ids'], average=average)\n    print ('Recall:', recall)\n    F2macro = fbeta_score(y_test['content_ids'], y_pred['content_ids'], beta=2, average='macro')\n    print ('F2 macro:', F2macro)\n    F2micro = fbeta_score(y_test['content_ids'], y_pred['content_ids'], beta=2, average='micro')\n    print ('F2 micro:', F2micro)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:16:00.725611Z","iopub.execute_input":"2023-01-30T23:16:00.726239Z","iopub.status.idle":"2023-01-30T23:16:00.735084Z","shell.execute_reply.started":"2023-01-30T23:16:00.726055Z","shell.execute_reply":"2023-01-30T23:16:00.733527Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def calculate_Fscore(prediction_df, actual_df):\n    \n    prediction_df['content_ids'] = prediction_df.content_ids.str.split(' ')\n    prediction_df.columns=['topic_id', 'content_ids_pred']\n    actual_df['content_ids'] = actual_df.content_ids.str.split(' ')\n    actual_df.columns=['topic_id', 'content_ids_actual']\n    df = pd.merge(prediction_df, actual_df, how='inner', on='topic_id')\n    df['correct_pred'] = df[['content_ids_pred', 'content_ids_actual']].apply(lambda x: len([d for d in x[0] if d in x[1]]), axis=1)\n    df['precision'] = df['correct_pred']/(df.content_ids_actual.str.len() + 1e-7)\n    df['recall'] = df['correct_pred']/(df.content_ids_pred.str.len() + 1e-7)\n    for beta in [0.5, 1, 2]:\n        df['f'+str(beta)] = ((1 + beta**2) * df['precision'] * df['recall'])/((beta**2 * df['precision']) + df['recall'] + 1e-7) \n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:16:01.065835Z","iopub.execute_input":"2023-01-30T23:16:01.066317Z","iopub.status.idle":"2023-01-30T23:16:01.079043Z","shell.execute_reply.started":"2023-01-30T23:16:01.066277Z","shell.execute_reply":"2023-01-30T23:16:01.077625Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"#example_pred = [{ 'topic_id': 't1', 'content_ids': 'c1 c2 c3 c10 c12 c13 c14'}, { 'topic_id': 't2', 'content_ids': 'c1 c2 c3 c14'}]\n#example_actual = [{ 'topic_id': 't1', 'content_ids': 'c1 c2 c3 c4 c5'}, { 'topic_id': 't2', 'content_ids': 'c2 c4 c5'}]\n#calculate_Fscore(pd.DataFrame(example_pred), pd.DataFrame(example_actual))","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:16:01.391507Z","iopub.execute_input":"2023-01-30T23:16:01.391954Z","iopub.status.idle":"2023-01-30T23:16:01.396756Z","shell.execute_reply.started":"2023-01-30T23:16:01.391917Z","shell.execute_reply":"2023-01-30T23:16:01.39554Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"## Calculate Embeddings Functions","metadata":{"id":"0866f1f5"}},{"cell_type":"markdown","source":"* Use output as pytorch tensor and normalize tensor embeddings\n* Convert to numpy array","metadata":{}},{"cell_type":"code","source":"def get_embeddings(topics_features, content_features):\n    \"\"\"\n    Calculate embeddings for both topics and content\n    From text in columns:\n    topic_cols=['title','description', 'topic_breadcrumbs'] \n    content_cols=['title','description', 'text']\n    \"\"\"\n    device = 'cpu'\n    if torch.cuda.is_available():\n        device = torch.device('cuda:0')\n\n    encoder = SentenceTransformer(trained_model)\n    topics_id_for_embeddings=[]\n    topics_embeddings=[]\n    content_ids_for_embeddings=[]\n    content_embeddings=[]\n    topics_aux = []\n    content_aux = []\n\n    topics_sentences = topics_features['sentences']\n    print (f'\\nGetting embeddings for {len(topics_sentences)} sentences from topics')\n    # topics embeddings\n    topics_aux = encoder.encode(topics_sentences, convert_to_tensor=True, show_progress_bar=False)\n    topics_id_for_embeddings = topics_sentences.index\n    topics_embeddings = util.normalize_embeddings(topics_aux.to(device)).detach().cpu().numpy()\n    # content embeddings\n    content_sentences = content_features['sentences']\n    print (f'\\nGetting embeddings for {len(content_sentences)} sentences from contents')\n    content_ids_for_embeddings = content_sentences.index\n    content_aux = encoder.encode(content_sentences, convert_to_tensor=True, show_progress_bar=True)\n    content_embeddings = util.normalize_embeddings(content_aux.to(device)).detach().cpu().numpy()\n    \n    return topics_embeddings, content_embeddings, topics_id_for_embeddings, content_ids_for_embeddings","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:16:02.653832Z","iopub.execute_input":"2023-01-30T23:16:02.654264Z","iopub.status.idle":"2023-01-30T23:16:02.66471Z","shell.execute_reply.started":"2023-01-30T23:16:02.654228Z","shell.execute_reply":"2023-01-30T23:16:02.663336Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"## Apply Nearest Neighbours Functions","metadata":{}},{"cell_type":"markdown","source":"* Use unsupervised NN. Use GPU when available, otherwise use sklearn NN","metadata":{}},{"cell_type":"markdown","source":"### topic-content predictions functions (df's)","metadata":{}},{"cell_type":"code","source":"def get_preds(list_aux, topics_id_for_embeddings):\n    \"\"\"\n    df_preds = Dataframe with topic_id's and KNN chosen content_ids\n    \"\"\"\n    df = pd.DataFrame(zip (list_aux, topics_id_for_embeddings), columns=['content_ids', 'topic_id'])\n    df = df.iloc[:,[1,0]]\n    df.content_ids = df.content_ids.str.join(' ')\n    df = df.fillna('')\n    return df","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:16:04.743895Z","iopub.execute_input":"2023-01-30T23:16:04.74447Z","iopub.status.idle":"2023-01-30T23:16:04.754294Z","shell.execute_reply.started":"2023-01-30T23:16:04.74442Z","shell.execute_reply":"2023-01-30T23:16:04.75193Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def get_true(df_corr, df):\n    \"\"\"\n    Ground truth\n    df_true = Dataframe with same topic_id's from 'get_preds' function but content_id's taken from correlations, \n    for score calculations. Returns the format defined in 'correlations.csv' but as dataframe.\n    \"\"\"\n    df_true = df_corr.copy().reset_index().merge (df, how='right', on='topic_id')[['topic_id', 'content_ids_x']].rename(columns={'content_ids_x': 'content_ids'})\n    df_true = df_true.fillna('')\n    return df_true","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:16:05.794609Z","iopub.execute_input":"2023-01-30T23:16:05.795227Z","iopub.status.idle":"2023-01-30T23:16:05.801628Z","shell.execute_reply.started":"2023-01-30T23:16:05.79519Z","shell.execute_reply":"2023-01-30T23:16:05.80027Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"### Calculate k neighbors / F2 scoring function","metadata":{}},{"cell_type":"code","source":"def k_neighbors (k, topics_embeddings, content_embeddings, topics_id_for_embeddings, content_ids_for_embeddings, df_corr):\n    \"\"\"\n    Calculate k neighbors of contents_id's for each topic_id\n    \"\"\"\n        \n    device = 'cpu'\n    if torch.cuda.is_available():\n        device = torch.device('cuda:0')\n    if device == 'cpu':\n        from sklearn.neighbors import NearestNeighbors\n    else:\n        import cudf\n        import cuml\n        from cuml.neighbors import NearestNeighbors\n\n    # Check if number of samples is below preset K value and reconfigure content_embeddings \n    topics_count = int(sum(x.size for sublist in topics_embeddings for x in sublist)/384)\n    #Model\n    print ('\\n K value:', k)\n    model = NearestNeighbors(n_neighbors=k,\n                             n_jobs=-1)\n\n    print ('\\nFitting KNN model...')\n    # Fit and Predictions\n    print (f\"\\nGetting content_ids for {topics_count} topics... \")\n    nbrs = model.fit(content_embeddings)\n    _, indices = nbrs.kneighbors(topics_embeddings)\n    content_id_list = np.array([content_ids_for_embeddings[val] for row in indices for val in row]).reshape(indices.shape)\n    \n    print ('\\nCalculating scores...')\n    #Define dataframes for predictions and ground truth\n    df_preds = get_preds(content_id_list, topics_id_for_embeddings)\n    df_true = get_true(df_corr, df_preds)\n    fscore = calculate_Fscore(df_preds.copy(), df_true.copy())\n    print ('\\nTopics to match content:', topics_count+1)\n    print ('\\nCorrect predictions:', fscore.correct_pred.sum())\n    print ('\\nF2 Score:', fscore.f2.mean())\n    #print ('\\n\\nF2 score by sklearn functions:')\n    #model_scoring (df_preds.copy(), df_true.copy(), average='micro')\n    print ('\\n')\n    \n    return model, df_preds, df_true, fscore","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:31:52.059464Z","iopub.execute_input":"2023-01-30T23:31:52.059882Z","iopub.status.idle":"2023-01-30T23:31:52.072021Z","shell.execute_reply.started":"2023-01-30T23:31:52.05985Z","shell.execute_reply":"2023-01-30T23:31:52.070486Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"## K parameter vs F2 score","metadata":{}},{"cell_type":"markdown","source":"# Setup Features and Target Functions","metadata":{}},{"cell_type":"markdown","source":"* Set X_train, X_test, y_train, y_test: split by category (use 'aligned' for validation); set has_content = True for validation. Check dimensions\n* Use all features for X, including topic_id and content_id, topic_title and content_title\n* Use the KNN predictions to \"mount\" X and y. Check dimensions.\n* Use correlations to get y: if KNN topic-content match with correlations, y is 1, else is 0\n* Use LGBMClassifier for multiclass classification","metadata":{}},{"cell_type":"code","source":"def get_target(preds):\n    \"\"\"\n    Get a binary target from comparing NN predictions y_preds with ground truth 'y' from 'df_corr'\n    \"\"\"\n    preds_aux = preds.copy()\n    preds_aux.content_ids = preds_aux.content_ids.str.split(' ')\n    preds_aux = preds_aux.explode('content_ids')\n    y_int = preds_aux.merge (y, on='topic_id', how='left')\n    y_int['match'] = (y_int.iloc[:,1] == y_int.iloc[:,2]).astype (int) \n    y_int = y_int.groupby(['topic_id', 'content_ids_x']).sum().reset_index()\n    return y_int","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:16:09.200945Z","iopub.execute_input":"2023-01-30T23:16:09.201858Z","iopub.status.idle":"2023-01-30T23:16:09.209518Z","shell.execute_reply.started":"2023-01-30T23:16:09.201819Z","shell.execute_reply":"2023-01-30T23:16:09.208323Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"def get_features (y_aux, topics_features, content_features):\n    \"\"\" \n    Get features for classification. Using topic_id, topic_title, content_id and content_title, \n    among remaining class features. Returns Xcolumns=X. and y_target.\n    \"\"\"\n    print (\"\\nSorting features for X...\\n\")\n    X = y_aux.copy()\n    X = X.merge (topics_features.reset_index(), how='left', left_on='topic_id', right_on='index')\n    X['topic_title'] = X.sentences.str.split('.').str[0]\n    X.drop(columns=X.iloc[:,[3,9,10]].columns.tolist(), inplace=True)\n    content_aux = contents_features.reset_index().drop(columns=contents_features.iloc[:,1].name) \n    X = X.merge (content_aux, how='left', left_on='content_ids_x', right_on=contents_features.reset_index().iloc[:,0].name)\n    X = X[X.has_content == True]\n    X['content_title'] = X.sentences.str.split('.').str[0]\n    X.drop(columns=X.iloc[:,[9,12]].columns.tolist(), inplace=True)\n    X.columns = X.columns.str.replace('_x', '')\n    X = X.sort_values('language')\n    print (\"\\nSorting binary y_target...\\n\\n\")\n    y_target = X.iloc[:,2]\n    #X=X.drop(columns=X.iloc[:,2].columns.tolist(), inplace=True)\n    print (\"\\nX and y_target are defined.\")\n    return X, y_target","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:59:28.614922Z","iopub.execute_input":"2023-01-30T23:59:28.615533Z","iopub.status.idle":"2023-01-30T23:59:28.629604Z","shell.execute_reply.started":"2023-01-30T23:59:28.615489Z","shell.execute_reply":"2023-01-30T23:59:28.627867Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"markdown","source":"# Feature Preprocessing\n\n","metadata":{}},{"cell_type":"code","source":"#Getting parameters\nK = 100 #k[4] #50","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:42:39.005476Z","iopub.execute_input":"2023-01-30T23:42:39.005892Z","iopub.status.idle":"2023-01-30T23:42:39.011249Z","shell.execute_reply.started":"2023-01-30T23:42:39.005859Z","shell.execute_reply":"2023-01-30T23:42:39.009927Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"#Getting topics breadcrumbs or topics context\nprint (\"\\n* Getting 'topics_breadcrumbs' dataframe...\\n\")\ndf_topic_breadcrumbs = get_topic_breadcrumbs (df_topics)\n\n#Cleaning data and getting topics and contents features\nprint ('\\n* Calculating topics_features dataframe...\\n')\ntopics_features = build_topic_features (df_topics, df_topic_breadcrumbs, levels, topics_cols)\n\nprint ('\\n* Calculating content_features dataframe...\\n')\ncontents_features = build_content_features (df_content, content_cols)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:32:44.13564Z","iopub.execute_input":"2023-01-30T23:32:44.136036Z","iopub.status.idle":"2023-01-30T23:32:44.874331Z","shell.execute_reply.started":"2023-01-30T23:32:44.136004Z","shell.execute_reply":"2023-01-30T23:32:44.872948Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"\n* Getting 'topics_breadcrumbs' dataframe...\n\nCreating breadcrumbs...\nCreating dataframe from breadcrumbs 'df_topics_breadcrumbs'...\n\n* Calculating topics_features dataframe...\n\n\nCreating and cleaning topic features...\n\nCreated 'topic_features'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"               channel category  level language  has_content  \\\nt_00004da3a1b2  000cf7   source   four       bg         True   \nt_00068291e9a4  8e286a   source   four       pt         True   \nt_00069b63a70a  6e3ba4   source  three       en         True   \nt_0006d41a73a8  000cf7   source   four       bg         True   \n\n                                                      content_ids  \\\nt_00004da3a1b2  c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c...   \nt_00068291e9a4  c_639ea2ef9c95 c_89ce9367be10 c_ac1672cdcd2c c...   \nt_00069b63a70a                                     c_11a1dc0bfb99   \nt_0006d41a73a8  c_0c6473c3480d c_1c57a1316568 c_5e375cf14c47 c...   \n\n                                                        sentences  \nt_00004da3a1b2  Откриването на резисторите.Изследване на матер...  \nt_00068291e9a4  Entradas e saídas de uma função.Entenda um pou...  \nt_00069b63a70a                                       Transcripts.  \nt_0006d41a73a8  Графики на експоненциални функции  Алгебра 2 н...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>channel</th>\n      <th>category</th>\n      <th>level</th>\n      <th>language</th>\n      <th>has_content</th>\n      <th>content_ids</th>\n      <th>sentences</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>t_00004da3a1b2</th>\n      <td>000cf7</td>\n      <td>source</td>\n      <td>four</td>\n      <td>bg</td>\n      <td>True</td>\n      <td>c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c...</td>\n      <td>Откриването на резисторите.Изследване на матер...</td>\n    </tr>\n    <tr>\n      <th>t_00068291e9a4</th>\n      <td>8e286a</td>\n      <td>source</td>\n      <td>four</td>\n      <td>pt</td>\n      <td>True</td>\n      <td>c_639ea2ef9c95 c_89ce9367be10 c_ac1672cdcd2c c...</td>\n      <td>Entradas e saídas de uma função.Entenda um pou...</td>\n    </tr>\n    <tr>\n      <th>t_00069b63a70a</th>\n      <td>6e3ba4</td>\n      <td>source</td>\n      <td>three</td>\n      <td>en</td>\n      <td>True</td>\n      <td>c_11a1dc0bfb99</td>\n      <td>Transcripts.</td>\n    </tr>\n    <tr>\n      <th>t_0006d41a73a8</th>\n      <td>000cf7</td>\n      <td>source</td>\n      <td>four</td>\n      <td>bg</td>\n      <td>True</td>\n      <td>c_0c6473c3480d c_1c57a1316568 c_5e375cf14c47 c...</td>\n      <td>Графики на експоненциални функции  Алгебра 2 н...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\n* Calculating content_features dataframe...\n\n\nCreating and cleaning content features...\n\nCreated 'content_features'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                    kind language  \\\nid                                  \nc_00002381196d     video       es   \nc_000087304a9e     video       it   \nc_0000ad142ddb     video       es   \nc_0000c03adc8d  document       pt   \nc_00016694ea2a  document       es   \n\n                                                        sentences  \nid                                                                 \nc_00002381196d  Sumar números de varios dígitos  48 029 233 93...  \nc_000087304a9e  Trovare i fattori di un numero.Sal trova i fat...  \nc_0000ad142ddb  Sumar curvas de demanda.Cómo añadir curvas de ...  \nc_0000c03adc8d  Nado de aproximação.Neste vídeo você vai apren...  \nc_00016694ea2a  geometry m3 topic a overview pdf.geometry m3 t...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>kind</th>\n      <th>language</th>\n      <th>sentences</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>c_00002381196d</th>\n      <td>video</td>\n      <td>es</td>\n      <td>Sumar números de varios dígitos  48 029 233 93...</td>\n    </tr>\n    <tr>\n      <th>c_000087304a9e</th>\n      <td>video</td>\n      <td>it</td>\n      <td>Trovare i fattori di un numero.Sal trova i fat...</td>\n    </tr>\n    <tr>\n      <th>c_0000ad142ddb</th>\n      <td>video</td>\n      <td>es</td>\n      <td>Sumar curvas de demanda.Cómo añadir curvas de ...</td>\n    </tr>\n    <tr>\n      <th>c_0000c03adc8d</th>\n      <td>document</td>\n      <td>pt</td>\n      <td>Nado de aproximação.Neste vídeo você vai apren...</td>\n    </tr>\n    <tr>\n      <th>c_00016694ea2a</th>\n      <td>document</td>\n      <td>es</td>\n      <td>geometry m3 topic a overview pdf.geometry m3 t...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#Calculating embeddings from text\nprint ('\\n* Calculating embeddings for both topics and contents text columns...\\n')\ntopics_embeds, contents_embeds, topic_id_embeds, content_ids_embeds = get_embeddings(topics_features, contents_features)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:32:49.471216Z","iopub.execute_input":"2023-01-30T23:32:49.471607Z","iopub.status.idle":"2023-01-30T23:33:47.866672Z","shell.execute_reply.started":"2023-01-30T23:32:49.471575Z","shell.execute_reply":"2023-01-30T23:33:47.865482Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"\n* Calculating embeddings for both topics and contents text columns...\n\n\nGetting embeddings for 4 sentences from topics\n\nGetting embeddings for 1000 sentences from contents\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/32 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8363b5e0f87d437a9e4199479b63208f"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Getting topics-contents from NN  ","metadata":{}},{"cell_type":"code","source":"#Calculating unsupervised k neighbours contents, for topics\nprint ('\\n* Calculating k neighnors predictions...\\n')\nmodel, preds, ground_truth, fscore = k_neighbors (K, topics_embeds, contents_embeds, topic_id_embeds, content_ids_embeds, df_corr)\npreds.to_csv('knn_predictions.csv', index=False)\nprint ('\\n All finished!\\n')\nprint ('\\n*** Predictions ***\\n')\ndisplay(preds)\nprint ('\\n*** Score for KNN only ***\\n')\ndisplay(fscore)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:42:44.115563Z","iopub.execute_input":"2023-01-30T23:42:44.11599Z","iopub.status.idle":"2023-01-30T23:42:44.317504Z","shell.execute_reply.started":"2023-01-30T23:42:44.115954Z","shell.execute_reply":"2023-01-30T23:42:44.316201Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"\n* Calculating k neighnors predictions...\n\n\n K value: 100\n\nFitting KNN model...\n\nGetting content_ids for 4 topics... \n\nCalculating scores...\n\nTopics to match content: 5\n\nCorrect predictions: 0\n\nF2 Score: 0.0\n\n\n\n All finished!\n\n\n*** Predictions ***\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"         topic_id                                        content_ids\n0  t_00004da3a1b2  c_005a7c3eadf3 c_004312ef7ecd c_0041092041cd c...\n1  t_00068291e9a4  c_0173e0b292fb c_00b2e5bc0065 c_019c6cf2cdac c...\n2  t_00069b63a70a  c_000f7fcdaacc c_0112c0ea6b55 c_00c05add5064 c...\n3  t_0006d41a73a8  c_0124fb4b510b c_01b0c3e81481 c_010c8b0e946f c...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic_id</th>\n      <th>content_ids</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>t_00004da3a1b2</td>\n      <td>c_005a7c3eadf3 c_004312ef7ecd c_0041092041cd c...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>t_00068291e9a4</td>\n      <td>c_0173e0b292fb c_00b2e5bc0065 c_019c6cf2cdac c...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>t_00069b63a70a</td>\n      <td>c_000f7fcdaacc c_0112c0ea6b55 c_00c05add5064 c...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>t_0006d41a73a8</td>\n      <td>c_0124fb4b510b c_01b0c3e81481 c_010c8b0e946f c...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\n*** Score for KNN only ***\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"         topic_id                                   content_ids_pred  \\\n0  t_00004da3a1b2  [c_005a7c3eadf3, c_004312ef7ecd, c_0041092041c...   \n1  t_00068291e9a4  [c_0173e0b292fb, c_00b2e5bc0065, c_019c6cf2cda...   \n2  t_00069b63a70a  [c_000f7fcdaacc, c_0112c0ea6b55, c_00c05add506...   \n3  t_0006d41a73a8  [c_0124fb4b510b, c_01b0c3e81481, c_010c8b0e946...   \n\n                                  content_ids_actual  correct_pred  precision  \\\n0  [c_1108dd0c7a5d, c_376c5a8eb028, c_5bc0e1e2cba...             0        0.0   \n1  [c_639ea2ef9c95, c_89ce9367be10, c_ac1672cdcd2...             0        0.0   \n2                                   [c_11a1dc0bfb99]             0        0.0   \n3  [c_0c6473c3480d, c_1c57a1316568, c_5e375cf14c4...             0        0.0   \n\n   recall  f0.5   f1   f2  \n0     0.0   0.0  0.0  0.0  \n1     0.0   0.0  0.0  0.0  \n2     0.0   0.0  0.0  0.0  \n3     0.0   0.0  0.0  0.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic_id</th>\n      <th>content_ids_pred</th>\n      <th>content_ids_actual</th>\n      <th>correct_pred</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f0.5</th>\n      <th>f1</th>\n      <th>f2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>t_00004da3a1b2</td>\n      <td>[c_005a7c3eadf3, c_004312ef7ecd, c_0041092041c...</td>\n      <td>[c_1108dd0c7a5d, c_376c5a8eb028, c_5bc0e1e2cba...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>t_00068291e9a4</td>\n      <td>[c_0173e0b292fb, c_00b2e5bc0065, c_019c6cf2cda...</td>\n      <td>[c_639ea2ef9c95, c_89ce9367be10, c_ac1672cdcd2...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>t_00069b63a70a</td>\n      <td>[c_000f7fcdaacc, c_0112c0ea6b55, c_00c05add506...</td>\n      <td>[c_11a1dc0bfb99]</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>t_0006d41a73a8</td>\n      <td>[c_0124fb4b510b, c_01b0c3e81481, c_010c8b0e946...</td>\n      <td>[c_0c6473c3480d, c_1c57a1316568, c_5e375cf14c4...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Setup Features and Target","metadata":{}},{"cell_type":"code","source":"# Get features and target, split into train and validation sets\npreds_expl = get_target(preds)\nX, y_target = get_features (preds_expl, topics_features, contents_features)\nX_train, X_val, y_train, y_val = train_test_split (X, y_target, random_state = 42)\nprint ('\\nDisplaying datasets:\\n\\n')\ndisplay (X_train.head())\ndisplay (y_train.head())\ndisplay (X_val.head())\ndisplay (y_val.head())\nprint (f'Shapes: X_train {X_train.shape}, y_train {y_train.shape}, X_val {X_val.shape}, y_val {y_val.shape}')","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:59:35.790355Z","iopub.execute_input":"2023-01-30T23:59:35.790836Z","iopub.status.idle":"2023-01-30T23:59:35.97655Z","shell.execute_reply.started":"2023-01-30T23:59:35.790797Z","shell.execute_reply":"2023-01-30T23:59:35.972887Z"},"trusted":true},"execution_count":125,"outputs":[{"name":"stdout","text":"\nSorting features for X...\n\n\nSorting binary y_target...\n\n\n\nX and y_target are defined.\n\nDisplaying datasets:\n\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"           topic_id     content_ids  match channel category  level language  \\\n286  t_00069b63a70a  c_018659c04857      0  6e3ba4   source  three       en   \n65   t_00004da3a1b2  c_012ec315a05c      0  000cf7   source   four       bg   \n341  t_0006d41a73a8  c_00d3ad407855      0  000cf7   source   four       bg   \n392  t_0006d41a73a8  c_01997eee2b70      0  000cf7   source   four       bg   \n21   t_00004da3a1b2  c_006694575048      0  000cf7   source   four       bg   \n\n     has_content                                        topic_title      kind  \\\n286         True                                        Transcripts     video   \n65          True                         Откриването на резисторите     video   \n341         True  Графики на експоненциални функции  Алгебра 2 н...  document   \n392         True  Графики на експоненциални функции  Алгебра 2 н...     video   \n21          True                         Откриването на резисторите     video   \n\n                                             sentences  \n286    Subsidairy Book Analytical Petty Cash Book   I.  \n65   يتعر ف مفهوم العلاقة والإقتران  الاقتران أو ال...  \n341  Precalculus Module 1  Topic A  Lesson 5  Teach...  \n392  Хипоталамус и хипофизна жлеза.Какво кара ендок...  \n21   Axe de symétrie.Qu est ce qu un axe de symétri...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic_id</th>\n      <th>content_ids</th>\n      <th>match</th>\n      <th>channel</th>\n      <th>category</th>\n      <th>level</th>\n      <th>language</th>\n      <th>has_content</th>\n      <th>topic_title</th>\n      <th>kind</th>\n      <th>sentences</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>286</th>\n      <td>t_00069b63a70a</td>\n      <td>c_018659c04857</td>\n      <td>0</td>\n      <td>6e3ba4</td>\n      <td>source</td>\n      <td>three</td>\n      <td>en</td>\n      <td>True</td>\n      <td>Transcripts</td>\n      <td>video</td>\n      <td>Subsidairy Book Analytical Petty Cash Book   I.</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>t_00004da3a1b2</td>\n      <td>c_012ec315a05c</td>\n      <td>0</td>\n      <td>000cf7</td>\n      <td>source</td>\n      <td>four</td>\n      <td>bg</td>\n      <td>True</td>\n      <td>Откриването на резисторите</td>\n      <td>video</td>\n      <td>يتعر ف مفهوم العلاقة والإقتران  الاقتران أو ال...</td>\n    </tr>\n    <tr>\n      <th>341</th>\n      <td>t_0006d41a73a8</td>\n      <td>c_00d3ad407855</td>\n      <td>0</td>\n      <td>000cf7</td>\n      <td>source</td>\n      <td>four</td>\n      <td>bg</td>\n      <td>True</td>\n      <td>Графики на експоненциални функции  Алгебра 2 н...</td>\n      <td>document</td>\n      <td>Precalculus Module 1  Topic A  Lesson 5  Teach...</td>\n    </tr>\n    <tr>\n      <th>392</th>\n      <td>t_0006d41a73a8</td>\n      <td>c_01997eee2b70</td>\n      <td>0</td>\n      <td>000cf7</td>\n      <td>source</td>\n      <td>four</td>\n      <td>bg</td>\n      <td>True</td>\n      <td>Графики на експоненциални функции  Алгебра 2 н...</td>\n      <td>video</td>\n      <td>Хипоталамус и хипофизна жлеза.Какво кара ендок...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>t_00004da3a1b2</td>\n      <td>c_006694575048</td>\n      <td>0</td>\n      <td>000cf7</td>\n      <td>source</td>\n      <td>four</td>\n      <td>bg</td>\n      <td>True</td>\n      <td>Откриването на резисторите</td>\n      <td>video</td>\n      <td>Axe de symétrie.Qu est ce qu un axe de symétri...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"286    0\n65     0\n341    0\n392    0\n21     0\nName: match, dtype: int64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"           topic_id     content_ids  match channel category  level language  \\\n262  t_00069b63a70a  c_012531c609f8      0  6e3ba4   source  three       en   \n242  t_00069b63a70a  c_00e0a8939f54      0  6e3ba4   source  three       en   \n308  t_0006d41a73a8  c_002624bb326b      0  000cf7   source   four       bg   \n256  t_00069b63a70a  c_011616a5716c      0  6e3ba4   source  three       en   \n368  t_0006d41a73a8  c_014d183f009c      0  000cf7   source   four       bg   \n\n     has_content                                        topic_title      kind  \\\n262         True                                        Transcripts     html5   \n242         True                                        Transcripts  document   \n308         True  Графики на експоненциални функции  Алгебра 2 н...  document   \n256         True                                        Transcripts     video   \n368         True  Графики на експоненциални функции  Алгебра 2 н...     html5   \n\n                                             sentences  \n262         Induction Proof  Greeting with Handshakes.  \n242  Grade 10 ELA Module 4  Unit 1 Overview.Grade 1...  \n308  math g7 m6 topic e lesson 27 student spanish p...  \n256                               Study of Detergents.  \n368  I Am Latvia  Research Report ..Jump to navigat...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic_id</th>\n      <th>content_ids</th>\n      <th>match</th>\n      <th>channel</th>\n      <th>category</th>\n      <th>level</th>\n      <th>language</th>\n      <th>has_content</th>\n      <th>topic_title</th>\n      <th>kind</th>\n      <th>sentences</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>262</th>\n      <td>t_00069b63a70a</td>\n      <td>c_012531c609f8</td>\n      <td>0</td>\n      <td>6e3ba4</td>\n      <td>source</td>\n      <td>three</td>\n      <td>en</td>\n      <td>True</td>\n      <td>Transcripts</td>\n      <td>html5</td>\n      <td>Induction Proof  Greeting with Handshakes.</td>\n    </tr>\n    <tr>\n      <th>242</th>\n      <td>t_00069b63a70a</td>\n      <td>c_00e0a8939f54</td>\n      <td>0</td>\n      <td>6e3ba4</td>\n      <td>source</td>\n      <td>three</td>\n      <td>en</td>\n      <td>True</td>\n      <td>Transcripts</td>\n      <td>document</td>\n      <td>Grade 10 ELA Module 4  Unit 1 Overview.Grade 1...</td>\n    </tr>\n    <tr>\n      <th>308</th>\n      <td>t_0006d41a73a8</td>\n      <td>c_002624bb326b</td>\n      <td>0</td>\n      <td>000cf7</td>\n      <td>source</td>\n      <td>four</td>\n      <td>bg</td>\n      <td>True</td>\n      <td>Графики на експоненциални функции  Алгебра 2 н...</td>\n      <td>document</td>\n      <td>math g7 m6 topic e lesson 27 student spanish p...</td>\n    </tr>\n    <tr>\n      <th>256</th>\n      <td>t_00069b63a70a</td>\n      <td>c_011616a5716c</td>\n      <td>0</td>\n      <td>6e3ba4</td>\n      <td>source</td>\n      <td>three</td>\n      <td>en</td>\n      <td>True</td>\n      <td>Transcripts</td>\n      <td>video</td>\n      <td>Study of Detergents.</td>\n    </tr>\n    <tr>\n      <th>368</th>\n      <td>t_0006d41a73a8</td>\n      <td>c_014d183f009c</td>\n      <td>0</td>\n      <td>000cf7</td>\n      <td>source</td>\n      <td>four</td>\n      <td>bg</td>\n      <td>True</td>\n      <td>Графики на експоненциални функции  Алгебра 2 н...</td>\n      <td>html5</td>\n      <td>I Am Latvia  Research Report ..Jump to navigat...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"262    0\n242    0\n308    0\n256    0\n368    0\nName: match, dtype: int64"},"metadata":{}},{"name":"stdout","text":"Shapes: X_train (300, 11), y_train (300,), X_val (100, 11), y_val (100,)\n","output_type":"stream"}]},{"cell_type":"code","source":"# save out features and target\nDATA_PATH = Path.cwd().parent.resolve()\nwork_path = DATA_PATH / 'working'\n\nx_train_pth = work_path / \"x_train.csv\"\nx_train_pth.parent.mkdir(exist_ok=True, parents=True)\ny_train_pth = work_path / \"y_train.csv\"\nx_val_pth = work_path / \"x_val.csv\"\ny_val_pth = work_path / \"y_val.csv\"\n\nX_train.to_csv (x_train_pth, index=False)\nX_val.to_csv (x_val_pth, index=False)\ny_train.to_csv (y_train_pth, index=False)\ny_val.to_csv (y_val_pth, index=False)\nprint (f\"\\nTraining and validation sets saved in files at {work_path}.\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:59:40.938851Z","iopub.execute_input":"2023-01-30T23:59:40.939605Z","iopub.status.idle":"2023-01-30T23:59:40.982333Z","shell.execute_reply.started":"2023-01-30T23:59:40.93956Z","shell.execute_reply":"2023-01-30T23:59:40.980856Z"},"trusted":true},"execution_count":126,"outputs":[{"name":"stdout","text":"\nTraining and validation sets saved in files at /kaggle/working.\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Using LGBMClassifier","metadata":{}},{"cell_type":"markdown","source":"As a classifier, the choice is LightGBM's LGBMClassifier.\n\nIt has the advantage of not needing hot-encoding and being 8-times faster than the same OneHotEncoder from sklearn.\n\nBelow, the %%writefile line magic is used to write out a training script. Then ! to run a shell command from the jupyter notebook, and kick off the script. This is due to a [bug](https://github.com/microsoft/LightGBM/issues/4229).\n\nWe'll use the typer package to make our script easy to run in the command line.","metadata":{}},{"cell_type":"code","source":"%%writefile train_gbm_model.py\nimport lightgbm as lgb\n\nimport joblib\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\nfrom loguru import logger\nimport typer\n\nDATA_PATH = Path.cwd().parent.resolve()\nMODEL_DIR = DATA_PATH / 'working'\n\ndef main(\n    features_path= MODEL_DIR / \"x_train.csv\",\n    labels_path=MODEL_DIR / \"y_train.csv\",\n    model_save_path=MODEL_DIR / \"lgb_classifier.txt\",\n):\n    \"\"\"\n    Train a LightGBM model based on training features in features_path and\n    training labels in labels_path. Save our the trained model to model_save_path\n    \"\"\"\n\n    # load saved features and labels\n    X_train = pd.read_csv (features_path, dtype=\"category\")\n    y_train = pd.read_csv (labels_path, dtype=int)\n    \n    logger.info(f\"Loaded training features of shape {X_train.shape} from {features_path}\")\n    logger.info(f\"Loading training labels of shape {y_train.shape} from {labels_path}\")\n    # instantiate tree model\n    model = lgb.LGBMClassifier(\n        boosting_type='gbdt',\n        objective='binary',\n        num_leaves= 50,\n        random_state=10)\n\n    # fit model\n    fit_params={\n            'feature_name': 'auto',\n            'categorical_feature': 'auto'\n           }\n    \n    logger.info(\"Fitting LGBM model\")\n    model.fit(X_train, y_train, **fit_params)\n    print(model)\n\n    # save out model weights\n    joblib.dump(model, str(model_save_path))\n    logger.success(f\"Model weights saved to {model_save_path}\")\n\n\nif __name__ == \"__main__\":\n    typer.run(main)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:53:08.392371Z","iopub.execute_input":"2023-01-30T23:53:08.392886Z","iopub.status.idle":"2023-01-30T23:53:08.404402Z","shell.execute_reply.started":"2023-01-30T23:53:08.392843Z","shell.execute_reply":"2023-01-30T23:53:08.402676Z"},"trusted":true},"execution_count":115,"outputs":[{"name":"stdout","text":"Overwriting train_gbm_model.py\n","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile train_gbm_model.py\nimport lightgbm as lgb\n\nimport joblib\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\nfrom loguru import logger\nimport typer\n\nDATA_PATH = Path.cwd().parent.resolve()\nMODEL_DIR = DATA_PATH / 'working'\n\ndef main(\n    features_path= MODEL_DIR / \"x_train.csv\",\n    labels_path=MODEL_DIR / \"y_train.csv\",\n    model_save_path=MODEL_DIR / \"lgb_classifier.txt\",\n):\n    \"\"\"\n    Train a LightGBM model based on training features in features_path and\n    training labels in labels_path. Save our the trained model to model_save_path\n    \"\"\"\n\n    # load saved features and labels\n    X_train = pd.read_csv (features_path, dtype=\"category\")\n    y_train = pd.read_csv (labels_path, dtype=int)\n\n    logger.info(f\"Loaded training features of shape {X_train.shape} from {features_path}\")\n    logger.info(f\"Loading training labels of shape {y_train.shape} from {labels_path}\")\n    \n    hyper_params = {\n    'task': 'train',\n    'boosting_type': 'gbdt',\n    'objective': 'binary',\n    'metric': 'recall',\n    'learning_rate': 0.1,\n    \"num_leaves\": 20,  \n    \"max_bin\": 100,\n    }\n\n    lgb_train = lgb.Dataset(X_train, y_train)    \n    logger.info(\"Fitting LGBM model\")\n    \n\n    # instantiate tree model and train\n    model = lgb.train(hyper_params, lgb_train, num_boost_round=10)\n\n    # save out model weights\n    joblib.dump(model, str(model_save_path))\n    logger.success(f\"Model weights saved to {model_save_path}\")\n\n\nif __name__ == \"__main__\":\n    typer.run(main)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:44:21.162606Z","iopub.execute_input":"2023-01-30T23:44:21.163125Z","iopub.status.idle":"2023-01-30T23:44:21.17398Z","shell.execute_reply.started":"2023-01-30T23:44:21.163066Z","shell.execute_reply":"2023-01-30T23:44:21.172477Z"},"trusted":true},"execution_count":92,"outputs":[{"name":"stdout","text":"Overwriting train_gbm_model.py\n","output_type":"stream"}]},{"cell_type":"code","source":"!python train_gbm_model.py","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:53:23.479965Z","iopub.execute_input":"2023-01-30T23:53:23.480446Z","iopub.status.idle":"2023-01-30T23:53:26.762859Z","shell.execute_reply.started":"2023-01-30T23:53:23.48041Z","shell.execute_reply":"2023-01-30T23:53:26.760992Z"},"trusted":true},"execution_count":116,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\u001b[32m2023-01-30 23:53:26.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mLoaded training features of shape (300, 11) from /kaggle/working/x_train.csv\u001b[0m\n\u001b[32m2023-01-30 23:53:26.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mLoading training labels of shape (300, 1) from /kaggle/working/y_train.csv\u001b[0m\n\u001b[32m2023-01-30 23:53:26.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mFitting LGBM model\u001b[0m\n/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\nLGBMClassifier(num_leaves=50, objective='binary', random_state=10)\n\u001b[32m2023-01-30 23:53:26.413\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m48\u001b[0m - \u001b[32m\u001b[1mModel weights saved to /kaggle/working/lgb_classifier.txt\u001b[0m\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Validation predictions","metadata":{}},{"cell_type":"code","source":"%%writefile predict_gbm_model.py\nimport lightgbm as lgb\n\nimport joblib\nfrom loguru import logger\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport typer\n\nDATA_PATH = Path.cwd().parent.resolve()\nMODEL_DIR = DATA_PATH / 'working'\n\ndef main(\n    model_weights_path=MODEL_DIR / \"lgb_classifier.txt\",\n    features_path=MODEL_DIR / \"x_val.csv\",\n    preds_save_path=MODEL_DIR / \"y_preds.npy\",\n):\n    \"\"\"\n    Generate predictions with a LightGBM model using weights saved at model_weights_path\n    and features saved at features_path. Save out predictions to preds_save_path.\n    \"\"\"\n    # load model weights\n    lgb_model = joblib.load(model_weights_path)\n    logger.info(f\"Loaded model {lgb_model} from {model_weights_path}\")\n\n    # load the features\n    X_val = pd.read_csv (features_path, dtype=\"category\")\n    logger.info(f\"Loaded features of shape {X_val.shape} from {features_path}\")\n\n    # generate predictions\n    y_preds = lgb_model.predict(X_val)\n\n    # save out predictions\n    with open(preds_save_path, \"wb\") as f:\n        np.save(f, y_preds)\n    logger.success(f\"Predictions saved to {preds_save_path}\")\n\n\nif __name__ == \"__main__\":\n    typer.run(main)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:53:31.384191Z","iopub.execute_input":"2023-01-30T23:53:31.384657Z","iopub.status.idle":"2023-01-30T23:53:31.39505Z","shell.execute_reply.started":"2023-01-30T23:53:31.384615Z","shell.execute_reply":"2023-01-30T23:53:31.393839Z"},"trusted":true},"execution_count":117,"outputs":[{"name":"stdout","text":"Overwriting predict_gbm_model.py\n","output_type":"stream"}]},{"cell_type":"code","source":"!python predict_gbm_model.py","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:53:32.709364Z","iopub.execute_input":"2023-01-30T23:53:32.709974Z","iopub.status.idle":"2023-01-30T23:53:36.073085Z","shell.execute_reply.started":"2023-01-30T23:53:32.709939Z","shell.execute_reply":"2023-01-30T23:53:36.071241Z"},"trusted":true},"execution_count":118,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\u001b[32m2023-01-30 23:53:35.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLoaded model LGBMClassifier(num_leaves=50, objective='binary', random_state=10) from /kaggle/working/lgb_classifier.txt\u001b[0m\n\u001b[32m2023-01-30 23:53:35.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mLoaded features of shape (100, 11) from /kaggle/working/x_val.csv\u001b[0m\n\u001b[32m2023-01-30 23:53:35.694\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m36\u001b[0m - \u001b[32m\u001b[1mPredictions saved to /kaggle/working/y_preds.npy\u001b[0m\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model Scoring","metadata":{}},{"cell_type":"code","source":"preds_pth = work_path / \"y_preds.npy\"\nwith open(preds_pth, \"rb\") as f:\n    y_preds = np.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-01-31T00:40:28.752086Z","iopub.execute_input":"2023-01-31T00:40:28.752502Z","iopub.status.idle":"2023-01-31T00:40:28.758903Z","shell.execute_reply.started":"2023-01-31T00:40:28.75247Z","shell.execute_reply":"2023-01-31T00:40:28.757761Z"},"trusted":true},"execution_count":197,"outputs":[]},{"cell_type":"code","source":"df = X_val[y_preds.astype(bool)].iloc[:, [0,1]]\ny_final_preds=df.set_index('topic_id').groupby(level=0).agg(lambda x: ' '.join(x)).reset_index()\ndisplay (y_final_preds)\ndf = X_val[y_val.astype(bool)].iloc[:, [0,1]]\ny_final_val=df.set_index('topic_id').groupby(level=0).agg(lambda x: ' '.join(x)).reset_index()\ndisplay (y_final_val)","metadata":{"execution":{"iopub.status.busy":"2023-01-31T00:46:14.593277Z","iopub.execute_input":"2023-01-31T00:46:14.593726Z","iopub.status.idle":"2023-01-31T00:46:14.623765Z","shell.execute_reply.started":"2023-01-31T00:46:14.59369Z","shell.execute_reply":"2023-01-31T00:46:14.622595Z"},"trusted":true},"execution_count":212,"outputs":[{"output_type":"display_data","data":{"text/plain":"         topic_id                                   content_ids\n0  t_00004da3a1b2  c_0143c0f8a522 c_00d2cf51f5f0 c_000ba728719e\n1  t_00068291e9a4                                c_0058a31b8ecf\n2  t_00069b63a70a                 c_009fa1daa174 c_014990ad8fbc\n3  t_0006d41a73a8                                c_016cb9cf0b7b","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic_id</th>\n      <th>content_ids</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>t_00004da3a1b2</td>\n      <td>c_0143c0f8a522 c_00d2cf51f5f0 c_000ba728719e</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>t_00068291e9a4</td>\n      <td>c_0058a31b8ecf</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>t_00069b63a70a</td>\n      <td>c_009fa1daa174 c_014990ad8fbc</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>t_0006d41a73a8</td>\n      <td>c_016cb9cf0b7b</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Empty DataFrame\nColumns: [topic_id, content_ids]\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic_id</th>\n      <th>content_ids</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"y_preds = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0])","metadata":{"execution":{"iopub.status.busy":"2023-01-31T00:46:13.510057Z","iopub.execute_input":"2023-01-31T00:46:13.51055Z","iopub.status.idle":"2023-01-31T00:46:13.520038Z","shell.execute_reply.started":"2023-01-31T00:46:13.510513Z","shell.execute_reply":"2023-01-31T00:46:13.518536Z"},"trusted":true},"execution_count":211,"outputs":[]},{"cell_type":"code","source":"y_final_val = y_final_preds","metadata":{"execution":{"iopub.status.busy":"2023-01-31T00:46:16.593051Z","iopub.execute_input":"2023-01-31T00:46:16.593451Z","iopub.status.idle":"2023-01-31T00:46:16.598393Z","shell.execute_reply.started":"2023-01-31T00:46:16.59342Z","shell.execute_reply":"2023-01-31T00:46:16.597177Z"},"trusted":true},"execution_count":213,"outputs":[]},{"cell_type":"code","source":"# Calculate the scoring for the final classification model\ndisplay(y_final_val)\ndisplay(y_final_preds)\ncalculate_Fscore(y_final_preds, y_final_val)","metadata":{"execution":{"iopub.status.busy":"2023-01-31T00:46:37.330013Z","iopub.execute_input":"2023-01-31T00:46:37.330766Z","iopub.status.idle":"2023-01-31T00:46:37.383201Z","shell.execute_reply.started":"2023-01-31T00:46:37.330729Z","shell.execute_reply":"2023-01-31T00:46:37.381634Z"},"trusted":true},"execution_count":216,"outputs":[{"output_type":"display_data","data":{"text/plain":"         topic_id                                  content_ids_pred\n0  t_00004da3a1b2  [c_0143c0f8a522, c_00d2cf51f5f0, c_000ba728719e]\n1  t_00068291e9a4                                  [c_0058a31b8ecf]\n2  t_00069b63a70a                  [c_009fa1daa174, c_014990ad8fbc]\n3  t_0006d41a73a8                                  [c_016cb9cf0b7b]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic_id</th>\n      <th>content_ids_pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>t_00004da3a1b2</td>\n      <td>[c_0143c0f8a522, c_00d2cf51f5f0, c_000ba728719e]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>t_00068291e9a4</td>\n      <td>[c_0058a31b8ecf]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>t_00069b63a70a</td>\n      <td>[c_009fa1daa174, c_014990ad8fbc]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>t_0006d41a73a8</td>\n      <td>[c_016cb9cf0b7b]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"         topic_id                                  content_ids_pred\n0  t_00004da3a1b2  [c_0143c0f8a522, c_00d2cf51f5f0, c_000ba728719e]\n1  t_00068291e9a4                                  [c_0058a31b8ecf]\n2  t_00069b63a70a                  [c_009fa1daa174, c_014990ad8fbc]\n3  t_0006d41a73a8                                  [c_016cb9cf0b7b]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic_id</th>\n      <th>content_ids_pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>t_00004da3a1b2</td>\n      <td>[c_0143c0f8a522, c_00d2cf51f5f0, c_000ba728719e]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>t_00068291e9a4</td>\n      <td>[c_0058a31b8ecf]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>t_00069b63a70a</td>\n      <td>[c_009fa1daa174, c_014990ad8fbc]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>t_0006d41a73a8</td>\n      <td>[c_016cb9cf0b7b]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_92/2712477381.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_final_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_final_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcalculate_Fscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_final_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_final_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_92/2056230066.py\u001b[0m in \u001b[0;36mcalculate_Fscore\u001b[0;34m(prediction_df, actual_df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_Fscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprediction_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content_ids'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprediction_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'topic_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'content_ids_pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mactual_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content_ids'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactual_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'content_ids'"],"ename":"AttributeError","evalue":"'DataFrame' object has no attribute 'content_ids'","output_type":"error"}]},{"cell_type":"markdown","source":"# Submissions","metadata":{}},{"cell_type":"code","source":"#import pickle\n#pickle.dump(model, open(f'ST-KNN-{k[1]}', 'wb'))\npreds.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T15:10:11.90159Z","iopub.status.idle":"2023-01-30T15:10:11.902244Z","shell.execute_reply.started":"2023-01-30T15:10:11.902024Z","shell.execute_reply":"2023-01-30T15:10:11.902047Z"},"trusted":true},"execution_count":null,"outputs":[]}]}