{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Kaggle Challenge - Learning Equality","metadata":{"id":"88080462"}},{"cell_type":"markdown","source":"https://www.kaggle.com/competitions/learning-equality-curriculum-recommendations/overview\n\n## Goal of the Competition\n\nThe goal of this competition is to streamline the process of matching educational content to specific topics in a curriculum. You will develop an accurate and efficient model trained on a library of K-12 educational materials that have been organized into a variety of topic taxonomies. These materials are in diverse languages, and cover a wide range of topics, particularly in STEM (Science, Technology, Engineering, and Mathematics).\n\nYour work will enable students and educators to more readily access relevant educational content to support and supplement learning.","metadata":{"id":"e44162a6"}},{"cell_type":"markdown","source":"## Submission File\n\nFor each **topic_id** in the test set, you must predict a space-delimited list of recommended **content_ids** for that topic. The file should contain a header and have the following format:\n\n~~~\ntopic_id,content_ids\nt_00004da3a1b2,c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c_76231f9d0b5e\nt_00068291e9a4,c_639ea2ef9c95 c_89ce9367be10 c_ac1672cdcd2c c_ebb7fdf10a7e\nt_00069b63a70a,c_11a1dc0bfb99\n...\n~~~","metadata":{"id":"d827eb0b"}},{"cell_type":"markdown","source":"## Scoring\nMean F2 score","metadata":{"id":"de5f7ef4"}},{"cell_type":"markdown","source":"## Evaluation Metric - Efficiency Scoring\nWe compute a submission's efficiency score by:\n\n\\begin{equation} \\text{Efficiency} = \\frac{1}{ \\text{Benchmark} - \\max\\text{F2} }\\text{F2} + \\frac{1}{32400}\\text{RuntimeSeconds} \\end{equation}\n\n\nwhere **F2** is the submission's score on the main competition metric, **Benchmark** is the score of the benchmark sample_submission.csv, **maxF2** is the maximum  of all submissions on the Private Leaderboard, and **RuntimeSeconds** is the number of seconds it takes for the submission to be evaluated. The objective is to minimize the efficiency score.\n\nDuring the training period of the competition, you may see a leaderboard for the public test data in the following notebook, updated daily: Efficiency Leaderboard. After the competition ends, we will update this leaderboard with efficiency scores on the private data. During the training period, this leaderboard will show only the rank of each team, but not the complete score.","metadata":{"id":"b86e3e62"}},{"cell_type":"markdown","source":"# How To Solve This Challenge","metadata":{}},{"cell_type":"markdown","source":"## Model Train\n\n* Calculate embeddings: for topics (title, description) and contents (title, description and text), use SentenceTransformer. Split sentences by language.\n* Use KNN model: train model with content embeddings and use topic embeddings to predict content matches, use k=10, 20, 30, 50\n* Calculate F2 to choose best k.\n* Submit predictions\n* Set X_train, X_test, y_train, y_test: split by category (use 'aligned' for validation), set has_content = True for validation. Check dimensions\n* Use all features for X, including topic_id and content_id, topic_title and content_title. Use the KNN predictions to \"mount\" X and y. Check dimensions.\n* Use correlations to get y: if KNN topic-content match with correlations, y is 1, else is 0\n* Use SVM RBF or KNN again for multiclass classification\n* Use RandomizedSearch to get best hyperparameters. Use model score \"recall\". Split the dataset in languages for training: train model for each language individually\n* Calculate F2 and see if we've got improvements from KNN.\n* Submit predictions\n\n## Submissions\n\n* Use submission sample and get topics and contents\n* Apply KNN model to get topic-content matches. Get contents per topic\n* Filter \"good matches\" with second classification model\n* Compare predicts with submission sample and calculate F2\n\n## Efficiency\n\n* Use KNN and 2nd model without GPU and check if it takes a long time to calculate sample submissions","metadata":{}},{"cell_type":"markdown","source":"# Data","metadata":{"id":"e2cc9cb4"}},{"cell_type":"markdown","source":"## Imports","metadata":{"id":"eb712db6"}},{"cell_type":"code","source":"drive_path = '/kaggle/input/learning-equality-curriculum-recommendations/'\ndataset_path = '/kaggle/input/learningequalityfiles/'\nwork_path = '/kaggle/working/'\nmodel_path = '/kaggle/input/learning-equality-files/ST-all-MiniLM-L6-v2-trained/ST-all-MiniLM-L6-v2-trained'","metadata":{"execution":{"iopub.status.busy":"2023-01-26T18:45:40.926498Z","iopub.execute_input":"2023-01-26T18:45:40.927497Z","iopub.status.idle":"2023-01-26T18:45:40.963715Z","shell.execute_reply.started":"2023-01-26T18:45:40.927391Z","shell.execute_reply":"2023-01-26T18:45:40.962804Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import sys, os\nsys.path.append(\"../input/sentence-transformer-package/sentence-transformers-2.2.2/sentence-transformers-2.2.2\") \nimport sentence_transformers","metadata":{"id":"2eBKbVKiQm-Z","execution":{"iopub.status.busy":"2023-01-26T18:45:40.965483Z","iopub.execute_input":"2023-01-26T18:45:40.966091Z","iopub.status.idle":"2023-01-26T18:45:45.767267Z","shell.execute_reply.started":"2023-01-26T18:45:40.966038Z","shell.execute_reply":"2023-01-26T18:45:45.766334Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport string\nimport torch\nfrom sentence_transformers import SentenceTransformer, util\nfrom sklearn.metrics import precision_score, recall_score, fbeta_score\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import FunctionTransformer, OneHotEncoder\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_validate","metadata":{"id":"b5f3a3b6","execution":{"iopub.status.busy":"2023-01-26T18:45:45.768710Z","iopub.execute_input":"2023-01-26T18:45:45.769480Z","iopub.status.idle":"2023-01-26T18:45:45.785666Z","shell.execute_reply.started":"2023-01-26T18:45:45.769445Z","shell.execute_reply":"2023-01-26T18:45:45.784683Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Data Collection","metadata":{"id":"e55f4587"}},{"cell_type":"markdown","source":"## Load dataframes","metadata":{"id":"FJLGLdJ-wKZI"}},{"cell_type":"code","source":"# load 'topics' data into pandas dataframe\n#df_topics = pd.read_csv(f'{drive_path}topics.csv', index_col=0).fillna({\"title\": \"\", \"description\": \"\"})\n#print (f\"\\nLoaded 'df_topics'\")\n#df_topics","metadata":{"id":"debc1002","outputId":"6ac0efe1-3179-41ba-f8c1-bc3c77928517","execution":{"iopub.status.busy":"2023-01-26T18:45:45.788454Z","iopub.execute_input":"2023-01-26T18:45:45.789669Z","iopub.status.idle":"2023-01-26T18:45:46.414603Z","shell.execute_reply.started":"2023-01-26T18:45:45.789619Z","shell.execute_reply":"2023-01-26T18:45:46.413517Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\nLoaded 'df_topics'\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                            title  \\\nid                                                                  \nt_00004da3a1b2                         Откриването на резисторите   \nt_000095e03056             Unit 3.3 Enlargements and Similarities   \nt_00068291e9a4                    Entradas e saídas de uma função   \nt_00069b63a70a                                        Transcripts   \nt_0006d41a73a8  Графики на експоненциални функции (Алгебра 2 н...   \n...                                                           ...   \nt_fffb0bf2801d                             4.3 Graph of functions   \nt_fffbe1d5d43c                   Inscribed shapes problem solving   \nt_fffe14f1be1e                                          Lección 7   \nt_fffe811a6da9  تحديد العلاقة بين الإحداثيّات القطبية والإحداث...   \nt_fffe88835149  Formation of shadows and eclipses (umbra and p...   \n\n                                                      description channel  \\\nid                                                                          \nt_00004da3a1b2  Изследване на материали, които предизвикват на...  000cf7   \nt_000095e03056                                                     b3f329   \nt_00068291e9a4               Entenda um pouco mais sobre funções.  8e286a   \nt_00069b63a70a                                                     6e3ba4   \nt_0006d41a73a8  Научи повече за графиките на сложните показате...  000cf7   \n...                                                           ...     ...   \nt_fffb0bf2801d                                                     e77b55   \nt_fffbe1d5d43c  Use properties of inscribed angles to prove pr...  0c929f   \nt_fffe14f1be1e                                                     6e90a7   \nt_fffe811a6da9                           5b9e5ca86571f90499ea987f  9fd860   \nt_fffe88835149                                                     c7ca13   \n\n               category  level language          parent  has_content  \nid                                                                    \nt_00004da3a1b2   source      4       bg  t_16e29365b50d         True  \nt_000095e03056  aligned      2       en  t_aa32fb6252dc        False  \nt_00068291e9a4   source      4       pt  t_d14b6c2a2b70         True  \nt_00069b63a70a   source      3       en  t_4054df11a74e         True  \nt_0006d41a73a8   source      4       bg  t_e2452e21d252         True  \n...                 ...    ...      ...             ...          ...  \nt_fffb0bf2801d  aligned      4       en  t_676e6a1a4dc7        False  \nt_fffbe1d5d43c   source      4       sw  t_50145b9bab3f         True  \nt_fffe14f1be1e  aligned      6       es  t_d448c707984d         True  \nt_fffe811a6da9   source      2       ar  t_5b4f3ba4eb7d         True  \nt_fffe88835149  aligned      4       en  t_988923176459        False  \n\n[76972 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>description</th>\n      <th>channel</th>\n      <th>category</th>\n      <th>level</th>\n      <th>language</th>\n      <th>parent</th>\n      <th>has_content</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>t_00004da3a1b2</th>\n      <td>Откриването на резисторите</td>\n      <td>Изследване на материали, които предизвикват на...</td>\n      <td>000cf7</td>\n      <td>source</td>\n      <td>4</td>\n      <td>bg</td>\n      <td>t_16e29365b50d</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>t_000095e03056</th>\n      <td>Unit 3.3 Enlargements and Similarities</td>\n      <td></td>\n      <td>b3f329</td>\n      <td>aligned</td>\n      <td>2</td>\n      <td>en</td>\n      <td>t_aa32fb6252dc</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>t_00068291e9a4</th>\n      <td>Entradas e saídas de uma função</td>\n      <td>Entenda um pouco mais sobre funções.</td>\n      <td>8e286a</td>\n      <td>source</td>\n      <td>4</td>\n      <td>pt</td>\n      <td>t_d14b6c2a2b70</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>t_00069b63a70a</th>\n      <td>Transcripts</td>\n      <td></td>\n      <td>6e3ba4</td>\n      <td>source</td>\n      <td>3</td>\n      <td>en</td>\n      <td>t_4054df11a74e</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>t_0006d41a73a8</th>\n      <td>Графики на експоненциални функции (Алгебра 2 н...</td>\n      <td>Научи повече за графиките на сложните показате...</td>\n      <td>000cf7</td>\n      <td>source</td>\n      <td>4</td>\n      <td>bg</td>\n      <td>t_e2452e21d252</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>t_fffb0bf2801d</th>\n      <td>4.3 Graph of functions</td>\n      <td></td>\n      <td>e77b55</td>\n      <td>aligned</td>\n      <td>4</td>\n      <td>en</td>\n      <td>t_676e6a1a4dc7</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>t_fffbe1d5d43c</th>\n      <td>Inscribed shapes problem solving</td>\n      <td>Use properties of inscribed angles to prove pr...</td>\n      <td>0c929f</td>\n      <td>source</td>\n      <td>4</td>\n      <td>sw</td>\n      <td>t_50145b9bab3f</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>t_fffe14f1be1e</th>\n      <td>Lección 7</td>\n      <td></td>\n      <td>6e90a7</td>\n      <td>aligned</td>\n      <td>6</td>\n      <td>es</td>\n      <td>t_d448c707984d</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>t_fffe811a6da9</th>\n      <td>تحديد العلاقة بين الإحداثيّات القطبية والإحداث...</td>\n      <td>5b9e5ca86571f90499ea987f</td>\n      <td>9fd860</td>\n      <td>source</td>\n      <td>2</td>\n      <td>ar</td>\n      <td>t_5b4f3ba4eb7d</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>t_fffe88835149</th>\n      <td>Formation of shadows and eclipses (umbra and p...</td>\n      <td></td>\n      <td>c7ca13</td>\n      <td>aligned</td>\n      <td>4</td>\n      <td>en</td>\n      <td>t_988923176459</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>76972 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# load 'content' data into pandas dataframe\n#df_content = pd.read_csv(f'{drive_path}content.csv', index_col=0).fillna(\"\")\n#print (f\"\\nLoaded 'df_content'\")\n#df_content","metadata":{"id":"f29e0027","outputId":"7a7843d3-0ba6-4d0f-b57a-b94df23137c1","execution":{"iopub.status.busy":"2023-01-26T18:45:46.415989Z","iopub.execute_input":"2023-01-26T18:45:46.416411Z","iopub.status.idle":"2023-01-26T18:46:09.012542Z","shell.execute_reply.started":"2023-01-26T18:45:46.416378Z","shell.execute_reply":"2023-01-26T18:46:09.011170Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"\nLoaded 'df_content'\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                           title  \\\nid                                                                 \nc_00002381196d  Sumar números de varios dígitos: 48,029+233,930    \nc_000087304a9e                    Trovare i fattori di un numero   \nc_0000ad142ddb                           Sumar curvas de demanda   \nc_0000c03adc8d                               Nado de aproximação   \nc_00016694ea2a                  geometry-m3-topic-a-overview.pdf   \n...                                                          ...   \nc_fffcbdd4de8b                                  2. 12: Diffusion   \nc_fffe15a2d069                      Sommare facendo gruppi da 10   \nc_fffed7b0d13a                            Introdução à subtração   \nc_ffff04ba7ac7                                      SA of a Cone   \nc_ffffe5254266                                          The Jats   \n\n                                                      description      kind  \\\nid                                                                            \nc_00002381196d  Suma 48,029+233,930 mediante el algoritmo está...     video   \nc_000087304a9e                    Sal trova i fattori di 120.\\n\\n     video   \nc_0000ad142ddb                  Cómo añadir curvas de demanda\\n\\n     video   \nc_0000c03adc8d  Neste vídeo você vai aprender o nado de aproxi...  document   \nc_00016694ea2a                   geometry-m3-topic-a-overview.pdf  document   \n...                                                           ...       ...   \nc_fffcbdd4de8b                                                        html5   \nc_fffe15a2d069  Sal somma 5+68 spezzando il 5 in un 2 e un 3.\\n\\n     video   \nc_fffed7b0d13a  Sal fala sobre o que significa subtrair. Os ex...     video   \nc_ffff04ba7ac7                                                        video   \nc_ffffe5254266                                                        video   \n\n                                                             text language  \\\nid                                                                           \nc_00002381196d                                                          es   \nc_000087304a9e                                                          it   \nc_0000ad142ddb                                                          es   \nc_0000c03adc8d  \\nNado de aproximação\\nSaber nadar nas ondas ...       pt   \nc_00016694ea2a  Estándares Comunes del Estado de Nueva York\\n\\...       es   \n...                                                           ...      ...   \nc_fffcbdd4de8b  What will eventually happen to these dyes?\\n\\n...       en   \nc_fffe15a2d069                                                          it   \nc_fffed7b0d13a                                                          pt   \nc_ffff04ba7ac7                                                          en   \nc_ffffe5254266                                                          en   \n\n                copyright_holder      license  \nid                                             \nc_00002381196d                                 \nc_000087304a9e                                 \nc_0000ad142ddb                                 \nc_0000c03adc8d  Sikana Education  CC BY-NC-ND  \nc_00016694ea2a         Engage NY  CC BY-NC-SA  \n...                          ...          ...  \nc_fffcbdd4de8b    CSU and Merlot  CC BY-NC-SA  \nc_fffe15a2d069                                 \nc_fffed7b0d13a                                 \nc_ffff04ba7ac7                                 \nc_ffffe5254266                                 \n\n[154047 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>description</th>\n      <th>kind</th>\n      <th>text</th>\n      <th>language</th>\n      <th>copyright_holder</th>\n      <th>license</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>c_00002381196d</th>\n      <td>Sumar números de varios dígitos: 48,029+233,930</td>\n      <td>Suma 48,029+233,930 mediante el algoritmo está...</td>\n      <td>video</td>\n      <td></td>\n      <td>es</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>c_000087304a9e</th>\n      <td>Trovare i fattori di un numero</td>\n      <td>Sal trova i fattori di 120.\\n\\n</td>\n      <td>video</td>\n      <td></td>\n      <td>it</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>c_0000ad142ddb</th>\n      <td>Sumar curvas de demanda</td>\n      <td>Cómo añadir curvas de demanda\\n\\n</td>\n      <td>video</td>\n      <td></td>\n      <td>es</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>c_0000c03adc8d</th>\n      <td>Nado de aproximação</td>\n      <td>Neste vídeo você vai aprender o nado de aproxi...</td>\n      <td>document</td>\n      <td>\\nNado de aproximação\\nSaber nadar nas ondas ...</td>\n      <td>pt</td>\n      <td>Sikana Education</td>\n      <td>CC BY-NC-ND</td>\n    </tr>\n    <tr>\n      <th>c_00016694ea2a</th>\n      <td>geometry-m3-topic-a-overview.pdf</td>\n      <td>geometry-m3-topic-a-overview.pdf</td>\n      <td>document</td>\n      <td>Estándares Comunes del Estado de Nueva York\\n\\...</td>\n      <td>es</td>\n      <td>Engage NY</td>\n      <td>CC BY-NC-SA</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>c_fffcbdd4de8b</th>\n      <td>2. 12: Diffusion</td>\n      <td></td>\n      <td>html5</td>\n      <td>What will eventually happen to these dyes?\\n\\n...</td>\n      <td>en</td>\n      <td>CSU and Merlot</td>\n      <td>CC BY-NC-SA</td>\n    </tr>\n    <tr>\n      <th>c_fffe15a2d069</th>\n      <td>Sommare facendo gruppi da 10</td>\n      <td>Sal somma 5+68 spezzando il 5 in un 2 e un 3.\\n\\n</td>\n      <td>video</td>\n      <td></td>\n      <td>it</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>c_fffed7b0d13a</th>\n      <td>Introdução à subtração</td>\n      <td>Sal fala sobre o que significa subtrair. Os ex...</td>\n      <td>video</td>\n      <td></td>\n      <td>pt</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>c_ffff04ba7ac7</th>\n      <td>SA of a Cone</td>\n      <td></td>\n      <td>video</td>\n      <td></td>\n      <td>en</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>c_ffffe5254266</th>\n      <td>The Jats</td>\n      <td></td>\n      <td>video</td>\n      <td></td>\n      <td>en</td>\n      <td></td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n<p>154047 rows × 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# load 'correlations' data into pandas dataframe\nif os.path.exists (f'{drive_path}correlations.csv'):\n    df_corr = pd.read_csv(f'{drive_path}correlations.csv', index_col=0)\n    print (f\"\\nLoaded 'df_corr'\")\n    # Restructure 'df_corr' (correlations): explode the target column to be more practical to use - one topic -> one content\n    y = df_corr.copy()\n    y['content_ids'] = y.content_ids.str.split(' ')\n    y = y.explode('content_ids')\n    y.reset_index(inplace=True)\n    print (f\"\\nLoaded 'df_corr'\")\n    display(y)","metadata":{"id":"29667ed7","outputId":"8f3c7bd9-ebd8-4729-a901-ba908e7739fb","execution":{"iopub.status.busy":"2023-01-26T18:46:09.014077Z","iopub.execute_input":"2023-01-26T18:46:09.014446Z","iopub.status.idle":"2023-01-26T18:46:09.201119Z","shell.execute_reply.started":"2023-01-26T18:46:09.014412Z","shell.execute_reply":"2023-01-26T18:46:09.200052Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"\nLoaded 'df_corr'\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                      content_ids\ntopic_id                                                         \nt_00004da3a1b2  c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c...\nt_00068291e9a4  c_639ea2ef9c95 c_89ce9367be10 c_ac1672cdcd2c c...\nt_00069b63a70a                                     c_11a1dc0bfb99\nt_0006d41a73a8  c_0c6473c3480d c_1c57a1316568 c_5e375cf14c47 c...\nt_0008768bdee6       c_34e1424229b4 c_7d1a964d66d5 c_aab93ee667f4\n...                                                           ...\nt_fff830472691                      c_61fb63326e5d c_8f224e321c87\nt_fff9e5407d13  c_026db653a269 c_0fb048a6412c c_20de77522603 c...\nt_fffbe1d5d43c                      c_46f852a49c08 c_6659207b25d5\nt_fffe14f1be1e                                     c_cece166bad6a\nt_fffe811a6da9                                     c_92b8fad372ee\n\n[61517 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content_ids</th>\n    </tr>\n    <tr>\n      <th>topic_id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>t_00004da3a1b2</th>\n      <td>c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c...</td>\n    </tr>\n    <tr>\n      <th>t_00068291e9a4</th>\n      <td>c_639ea2ef9c95 c_89ce9367be10 c_ac1672cdcd2c c...</td>\n    </tr>\n    <tr>\n      <th>t_00069b63a70a</th>\n      <td>c_11a1dc0bfb99</td>\n    </tr>\n    <tr>\n      <th>t_0006d41a73a8</th>\n      <td>c_0c6473c3480d c_1c57a1316568 c_5e375cf14c47 c...</td>\n    </tr>\n    <tr>\n      <th>t_0008768bdee6</th>\n      <td>c_34e1424229b4 c_7d1a964d66d5 c_aab93ee667f4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>t_fff830472691</th>\n      <td>c_61fb63326e5d c_8f224e321c87</td>\n    </tr>\n    <tr>\n      <th>t_fff9e5407d13</th>\n      <td>c_026db653a269 c_0fb048a6412c c_20de77522603 c...</td>\n    </tr>\n    <tr>\n      <th>t_fffbe1d5d43c</th>\n      <td>c_46f852a49c08 c_6659207b25d5</td>\n    </tr>\n    <tr>\n      <th>t_fffe14f1be1e</th>\n      <td>c_cece166bad6a</td>\n    </tr>\n    <tr>\n      <th>t_fffe811a6da9</th>\n      <td>c_92b8fad372ee</td>\n    </tr>\n  </tbody>\n</table>\n<p>61517 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# load 'topic_breadcrumbs' data into pandas dataframe\n#df_topic_breadcrumbs = pd.read_csv(f'{dataset_path}topic_breadcrumbs.csv', index_col=0)\n#print (f\"\\nLoaded 'df_topic_breadcrumbs'\")\n#df_topic_breadcrumbs","metadata":{"outputId":"7681b90b-c5fe-425a-8588-a482bca3a5ae","id":"uHXeHxwfQ4qX","execution":{"iopub.status.busy":"2023-01-26T18:46:09.202573Z","iopub.execute_input":"2023-01-26T18:46:09.203033Z","iopub.status.idle":"2023-01-26T18:46:09.208757Z","shell.execute_reply.started":"2023-01-26T18:46:09.202988Z","shell.execute_reply":"2023-01-26T18:46:09.207142Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Load test dataframes","metadata":{}},{"cell_type":"code","source":"# load 'topics.csv' and 'content.csv' with sample submission data\n# This will allow to simulate submitting real predicts for the challenge\ndf_topics_test = pd.read_csv(f'{drive_path}topics.csv', index_col=0).fillna({\"title\": \"\", \"description\": \"\"})\ndf_content_test = pd.read_csv(f'{drive_path}content.csv', index_col=0).fillna({\"title\": \"\", \"description\": \"\"})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Topic Breadcrumbs","metadata":{}},{"cell_type":"code","source":"# define some helper functions and classes to aid with data traversal\n\ndef get_topic_breadcrumbs (df_topic):\n    print (f\"Creating breadcrumbs...\")\n    topic_breadcrumbs=[]\n    topic_ids=[]\n    df_topic = df_topic.reset_index()\n    if 'topic_id' in df_topic.columns:\n        col_name = 'topic_id'\n    else:\n        col_name = 'id'\n    for i, topic in enumerate(df_topic[col_name]):\n        if (i % 5000 == 0) and (i > 0):\n            print (f'Created {i} breadcrumbs...')\n        topic_ids.append (topic)\n        topic_breadcrumbs.append (Topic(topic).get_breadcrumbs(separator=' '))\n    print (f\"Creating dataframe from breadcrumbs 'df_topics_breadcrumbs'...\")\n    df_topics_breadcrumbs = pd.DataFrame (topic_breadcrumbs, \n                                          index = topic_ids,\n                                          columns = ['topic_breadcrumbs'])\n    return df_topics_breadcrumbs\n\n\ndef print_markdown(md):\n    display(Markdown(md))\n\nclass Topic:\n    def __init__(self, topic_id):\n        self.id = topic_id\n\n    @property\n    def parent(self):\n        parent_id = df_topics.loc[self.id].parent\n        if pd.isna(parent_id):\n            return None\n        else:\n            return Topic(parent_id)\n\n    @property\n    def ancestors(self):\n        ancestors = []\n        parent = self.parent\n        while parent is not None:\n            ancestors.append(parent)\n            parent = parent.parent\n        return ancestors\n\n    @property\n    def siblings(self):\n        if not self.parent:\n            return []\n        else:\n            return [topic for topic in self.parent.children if topic != self]\n\n    @property\n    def content(self):\n        if self.id in df_corr.index:\n            return [ContentItem(content_id) for content_id in df_corr.loc[self.id].content_ids.split()]\n        else:\n            return tuple([]) if self.has_content else []\n\n    def get_breadcrumbs(self, separator=\" >> \", include_self=True, include_root=True):\n        ancestors = self.ancestors\n        if include_self:\n            ancestors = [self] + ancestors\n        if not include_root:\n            ancestors = ancestors[:-1]\n        return separator.join(reversed([a.title for a in ancestors]))\n\n    @property\n    def children(self):\n        return [Topic(child_id) for child_id in df_topics[df_topics.parent == self.id].index]\n\n    def subtree_markdown(self, depth=0):\n        markdown = \"  \" * depth + \"- \" + self.title + \"\\n\"\n        for child in self.children:\n            markdown += child.subtree_markdown(depth=depth + 1)\n        for content in self.content:\n            markdown += (\"  \" * (depth + 1) + \"- \" + \"[\" + content.kind.title() + \"] \" + content.title) + \"\\n\"\n        return markdown\n\n    def __eq__(self, other):\n        if not isinstance(other, Topic):\n            return False\n        return self.id == other.id\n\n    def __getattr__(self, name):\n        return df_topics.loc[self.id][name]\n\n    def __str__(self):\n        return self.title\n    \n    def __repr__(self):\n        return f\"<Topic(id={self.id}, title=\\\"{self.title}\\\")>\"\n\n\nclass ContentItem:\n    def __init__(self, content_id):\n        self.id = content_id\n\n    @property\n    def topics(self):\n        return [Topic(topic_id) for topic_id in df_topics.loc[df_corr[df_corr.content_ids.str.contains(self.id)].index].index]\n\n    def __getattr__(self, name):\n        return content_df.loc[self.id][name]\n\n    def __str__(self):\n        return self.title\n    \n    def __repr__(self):\n        return f\"<ContentItem(id={self.id}, title=\\\"{self.title}\\\")>\"\n\n    def __eq__(self, other):\n        if not isinstance(other, ContentItem):\n            return False\n        return self.id == other.id\n\n    def get_all_breadcrumbs(self, separator=\" >> \", include_root=True):\n        breadcrumbs = []\n        for topic in self.topics:\n            new_breadcrumb = topic.get_breadcrumbs(separator=separator, include_root=include_root)\n            if new_breadcrumb:\n                new_breadcrumb = new_breadcrumb + separator + self.title\n            else:\n                new_breadcrumb = self.title\n            breadcrumbs.append(new_breadcrumb)\n        return breadcrumbs","metadata":{"execution":{"iopub.status.busy":"2023-01-26T18:46:09.398682Z","iopub.execute_input":"2023-01-26T18:46:09.399037Z","iopub.status.idle":"2023-01-26T18:46:09.422983Z","shell.execute_reply.started":"2023-01-26T18:46:09.399007Z","shell.execute_reply":"2023-01-26T18:46:09.422111Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Data Cleaning","metadata":{"id":"CP4lmcnV20yH"}},{"cell_type":"markdown","source":"## Data cleaning params","metadata":{"id":"rjw9Pdqqlzdp"}},{"cell_type":"code","source":"levels = {1: 'one', 2: 'two', 3: 'three', 4: 'four', 5: 'five', 6: 'six', 7: 'seven', 8: 'eight',\n          9: 'nine', 10: 'ten', 0: 'zero'}\ntopics_cols = ['title', 'description', 'topic_breadcrumbs']\ncontent_cols = ['title', 'description', 'text']\ncat_for_val = 'aligned'\nprint (f\"\\nLoaded cleaning parameters\")","metadata":{"id":"qpgsrMQyl10Y","execution":{"iopub.status.busy":"2023-01-26T18:46:09.424379Z","iopub.execute_input":"2023-01-26T18:46:09.424755Z","iopub.status.idle":"2023-01-26T18:46:09.448862Z","shell.execute_reply.started":"2023-01-26T18:46:09.424724Z","shell.execute_reply":"2023-01-26T18:46:09.447605Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"\nLoaded cleaning parameters\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Data cleaning functions","metadata":{"id":"Hwk6JtmRbn42"}},{"cell_type":"code","source":"# Clean up text\ndef clean_text(text_col):\n    \"\"\"\n    Clean ponctuation and special chars from a dataframe column\n    \"\"\"\n    punctuations = string.punctuation\n    text_col = text_col.str.replace('\\W', ' ', regex=True)\n    for punct in string.punctuation:\n        text_col = text_col.str.replace(punct, ' ', regex=True)\n    return text_col","metadata":{"id":"xRgKUBVjbstB","execution":{"iopub.status.busy":"2023-01-26T18:46:09.450362Z","iopub.execute_input":"2023-01-26T18:46:09.451229Z","iopub.status.idle":"2023-01-26T18:46:09.460503Z","shell.execute_reply.started":"2023-01-26T18:46:09.451185Z","shell.execute_reply":"2023-01-26T18:46:09.459303Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Topics\n\n*   Changing 'level' values from integers to strings\n*   Clean strings: ponctuation and special chars (\\n\\t...)\n*   Sort values by language","metadata":{"id":"WmkMQLZHaDmd"}},{"cell_type":"code","source":"def build_topic_features (topics_df, df_topics_breadcrumbs, levels, topic_cols):\n    \"\"\"\n    Create 'topics_features' from df_topics, clean parameters and functions\n    \"\"\"\n    print (f\"\\nCreating and cleaning topic features...\")\n    topics_features = topics_df.copy()\n    topics_features = topics_features.replace ({'level': levels})\n    topics_features = topics_features.merge (df_topic_breadcrumbs, how='outer', right_index=True, left_index=True)\n    for col in topics_cols:\n        topics_features[col] = clean_text(topics_features[col])\n    topics_features['sentences'] = topics_features[topics_cols].apply(lambda x: '.'.join(x.dropna().astype(str)), axis=1)\n    topics_features = topics_features.drop(columns=['parent'] + topics_cols) \n    print (f\"\\nCreated 'topic_features'\")\n    display (topics_features.head())\n    \n    return topics_features\n","metadata":{"id":"prh6uaPXlyMr","execution":{"iopub.status.busy":"2023-01-26T18:46:09.461877Z","iopub.execute_input":"2023-01-26T18:46:09.462237Z","iopub.status.idle":"2023-01-26T18:46:09.472850Z","shell.execute_reply.started":"2023-01-26T18:46:09.462204Z","shell.execute_reply":"2023-01-26T18:46:09.471600Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Contents\n\n\n*   Remove columns 'copyright_holder' and 'language' (for 'language' assume that topic-content match with correlations is same language)\n*   Clean strings: ponctuation and special chars (\\n\\t...)","metadata":{"id":"m-sO4fCibFIb"}},{"cell_type":"code","source":"def build_content_features (content_df, content_cols):\n    \"\"\"\n    Create 'content_features' from df_content, clean parameters and functions\n    \"\"\"\n    print (f\"\\nCreating and cleaning content features...\")\n    content_features = content_df.copy()\n    for col in content_cols:\n        content_features[col] = clean_text(content_features[col])\n    content_features['sentences'] =  content_features[content_cols].apply(lambda x: '.'.join(x.dropna().astype(str)), axis=1)\n    content_features = content_features.drop(columns=['copyright_holder'] + content_cols)\n    print (f\"\\nCreated 'content_features'\")\n    display (content_features.head())\n    \n    return content_features","metadata":{"id":"fa3508db","execution":{"iopub.status.busy":"2023-01-26T18:46:09.474307Z","iopub.execute_input":"2023-01-26T18:46:09.474644Z","iopub.status.idle":"2023-01-26T18:46:09.484821Z","shell.execute_reply.started":"2023-01-26T18:46:09.474615Z","shell.execute_reply":"2023-01-26T18:46:09.483943Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Model training","metadata":{}},{"cell_type":"markdown","source":"### Models params","metadata":{"id":"iI-1sqraZhLv"}},{"cell_type":"code","source":"#General\ndevice = 'cpu'\nif torch.cuda.is_available():\n    device = torch.device('cuda:0')\n#Sentence Transformer\nall_mini = 'all-MiniLM-L6-v2'\nparaphrase = 'paraphrase-multilingual-MiniLM-L12-v2'\ntrained_model = '/kaggle/input/learning-equality-files/ST-all-MiniLM-L6-v2-trained/ST-all-MiniLM-L6-v2-trained'\n# KNN\nk = [5,10,20,30,50]\nalg = 'kd_tree' #'ball_tree','brute'\nleaf = 10\nprint (f\"\\nLoaded models parameters\")","metadata":{"id":"HJou8xoM4H2A","execution":{"iopub.status.busy":"2023-01-26T18:46:09.486207Z","iopub.execute_input":"2023-01-26T18:46:09.486500Z","iopub.status.idle":"2023-01-26T18:46:09.501173Z","shell.execute_reply.started":"2023-01-26T18:46:09.486473Z","shell.execute_reply":"2023-01-26T18:46:09.500045Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"\nLoaded models parameters\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Scoring functions","metadata":{}},{"cell_type":"code","source":"def model_scoring (y_test, y_pred, average='macro'):\n    \"\"\"\n    Calculate precision, recall and f2-score for y_test and y_pred\n    \"\"\"\n    precision = precision_score(y_test['content_ids'], y_pred['content_ids'], average=average)\n    print ('Precision:', precision)\n    recall = recall_score(y_test['content_ids'], y_pred['content_ids'], average=average)\n    print ('Recall:', recall)\n    F2macro = fbeta_score(y_test['content_ids'], y_pred['content_ids'], beta=2, average='macro')\n    print ('F2 macro:', F2macro)\n    F2micro = fbeta_score(y_test['content_ids'], y_pred['content_ids'], beta=2, average='micro')\n    print ('F2 micro:', F2micro)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T18:46:09.502865Z","iopub.execute_input":"2023-01-26T18:46:09.503389Z","iopub.status.idle":"2023-01-26T18:46:09.512079Z","shell.execute_reply.started":"2023-01-26T18:46:09.503353Z","shell.execute_reply":"2023-01-26T18:46:09.510603Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def calculate_Fscore(prediction_df, actual_df):\n    \n    prediction_df['content_ids'] = prediction_df.content_ids.str.split(' ')\n    prediction_df.columns=['topic_id', 'content_ids_pred']\n    actual_df['content_ids'] = actual_df.content_ids.str.split(' ')\n    actual_df.columns=['topic_id', 'content_ids_actual']\n    df = pd.merge(prediction_df, actual_df, how='inner', on='topic_id')\n    df['correct_pred'] = df[['content_ids_pred', 'content_ids_actual']].apply(lambda x: len([d for d in x[0] if d in x[1]]), axis=1)\n    df['precision'] = df['correct_pred']/(df.content_ids_actual.str.len() + 1e-7)\n    df['recall'] = df['correct_pred']/(df.content_ids_pred.str.len() + 1e-7)\n    for beta in [0.5, 1, 2]:\n        df['f'+str(beta)] = ((1 + beta**2) * df['precision'] * df['recall'])/((beta**2 * df['precision']) + df['recall'] + 1e-7) \n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2023-01-26T18:46:09.513357Z","iopub.execute_input":"2023-01-26T18:46:09.513701Z","iopub.status.idle":"2023-01-26T18:46:09.531703Z","shell.execute_reply.started":"2023-01-26T18:46:09.513671Z","shell.execute_reply":"2023-01-26T18:46:09.530592Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"example_pred = [{ 'topic_id': 't1', 'content_ids': 'c1 c2 c3 c10 c12 c13 c14'}, { 'topic_id': 't2', 'content_ids': 'c1 c2 c3 c14'}]\nexample_actual = [{ 'topic_id': 't1', 'content_ids': 'c1 c2 c3 c4 c5'}, { 'topic_id': 't2', 'content_ids': 'c2 c4 c5'}]\ncalculate_Fscore(pd.DataFrame(example_pred), pd.DataFrame(example_actual))","metadata":{"execution":{"iopub.status.busy":"2023-01-26T18:46:09.533186Z","iopub.execute_input":"2023-01-26T18:46:09.533519Z","iopub.status.idle":"2023-01-26T18:46:09.574450Z","shell.execute_reply.started":"2023-01-26T18:46:09.533490Z","shell.execute_reply":"2023-01-26T18:46:09.573178Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"  topic_id                  content_ids_pred    content_ids_actual  \\\n0       t1  [c1, c2, c3, c10, c12, c13, c14]  [c1, c2, c3, c4, c5]   \n1       t2                 [c1, c2, c3, c14]          [c2, c4, c5]   \n\n   correct_pred  precision    recall      f0.5        f1        f2  \n0             3   0.600000  0.428571  0.555555  0.500000  0.454545  \n1             1   0.333333  0.250000  0.312500  0.285714  0.263158  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic_id</th>\n      <th>content_ids_pred</th>\n      <th>content_ids_actual</th>\n      <th>correct_pred</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f0.5</th>\n      <th>f1</th>\n      <th>f2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>t1</td>\n      <td>[c1, c2, c3, c10, c12, c13, c14]</td>\n      <td>[c1, c2, c3, c4, c5]</td>\n      <td>3</td>\n      <td>0.600000</td>\n      <td>0.428571</td>\n      <td>0.555555</td>\n      <td>0.500000</td>\n      <td>0.454545</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>t2</td>\n      <td>[c1, c2, c3, c14]</td>\n      <td>[c2, c4, c5]</td>\n      <td>1</td>\n      <td>0.333333</td>\n      <td>0.250000</td>\n      <td>0.312500</td>\n      <td>0.285714</td>\n      <td>0.263158</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Get embeddings","metadata":{"id":"0866f1f5"}},{"cell_type":"markdown","source":"* Use output as pytorch tensor and normalize tensor embeddings\n* Convert to numpy array","metadata":{}},{"cell_type":"code","source":"def get_embeddings(topics_features, content_features, langs, langs_limit):\n    \"\"\"\n    Calculate embeddings for both topics and content\n    From text in columns:\n    topic_cols=['title','description', 'topic_breadcrumbs'] \n    content_cols=['title','description', 'text']\n    \"\"\"\n    device = 'cpu'\n    if torch.cuda.is_available():\n        device = torch.device('cuda:0')\n\n    encoder = SentenceTransformer(trained_model)\n    topics_id_for_embeddings=[]\n    topics_embeddings=[]\n    content_ids_for_embeddings=[]\n    content_embeddings=[]\n    topics_aux = []\n    content_aux = []\n\n    for i, lang in enumerate(langs[:langs_limit]):\n        print (f'\\nGetting embeddings for {i+1}:{lang} from {langs_limit} languages')\n        # topics embeddings\n        topics_sentences = topics_features[topics_features.language == lang]['sentences']\n        topics_aux = encoder.encode(topics_sentences, convert_to_tensor=True, show_progress_bar=True)\n        topics_id_for_embeddings.append (topics_sentences.index)\n        topics_embeddings.append (util.normalize_embeddings(topics_aux.to(device)).detach().cpu().numpy())\n        # content embeddings\n        content_sentences = content_features[content_features.language == lang]['sentences']\n        if len(content_sentences) == 0:\n            content_embeddings.append (np.array([0]).reshape(1,-1)) \n            content_ids_for_embeddings.append (content_sentences.index)\n            continue\n        else:\n            content_ids_for_embeddings.append (content_sentences.index)\n            content_aux = encoder.encode(content_sentences, convert_to_tensor=True, show_progress_bar=True)\n            content_embeddings.append (util.normalize_embeddings(content_aux.to(device)).detach().cpu().numpy())\n    \n    return topics_embeddings, content_embeddings, topics_id_for_embeddings, content_ids_for_embeddings","metadata":{"execution":{"iopub.status.busy":"2023-01-26T18:46:09.575940Z","iopub.execute_input":"2023-01-26T18:46:09.576659Z","iopub.status.idle":"2023-01-26T18:46:09.593339Z","shell.execute_reply.started":"2023-01-26T18:46:09.576615Z","shell.execute_reply":"2023-01-26T18:46:09.592020Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Apply Nearest Neighbours","metadata":{}},{"cell_type":"markdown","source":"* Use unsupervised NN. Use GPU when available, otherwise use sklearn NN","metadata":{}},{"cell_type":"markdown","source":"### topic-content predictions functions (df's)","metadata":{}},{"cell_type":"code","source":"def get_preds(list_aux, topics_id_for_embeddings):\n    \"\"\"\n    df_preds = Dataframe with topic_id's and KNN chosen content_ids\n    \"\"\"\n    df = pd.DataFrame(list_aux)\n    df['topic_id'] = topics_id_for_embeddings\n    df = df.explode(['content_ids','topic_id'])\n    df.content_ids = df.content_ids.str.join(' ')\n    df = df.iloc[:,[0,2,1]].reset_index().drop(columns=['language', 'index'])\n    df = df.fillna('')\n    return df","metadata":{"execution":{"iopub.status.busy":"2023-01-26T18:46:09.594890Z","iopub.execute_input":"2023-01-26T18:46:09.595750Z","iopub.status.idle":"2023-01-26T18:46:09.609853Z","shell.execute_reply.started":"2023-01-26T18:46:09.595704Z","shell.execute_reply":"2023-01-26T18:46:09.608577Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def get_true(df_corr, df):\n    \"\"\"\n    Ground truth\n    df_true = Dataframe with same topic_id's from 'get_preds' function but content_id's taken from correlations, \n    for score calculations,\n    \"\"\"\n    df_true = df_corr.copy().reset_index().merge (df, how='right', on='topic_id')[['topic_id', 'content_ids_x']].rename(columns={'content_ids_x': 'content_ids'})\n    df_true = df_true.fillna('')\n    return df_true","metadata":{"execution":{"iopub.status.busy":"2023-01-26T18:46:09.611532Z","iopub.execute_input":"2023-01-26T18:46:09.612594Z","iopub.status.idle":"2023-01-26T18:46:09.626603Z","shell.execute_reply.started":"2023-01-26T18:46:09.612548Z","shell.execute_reply":"2023-01-26T18:46:09.625003Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### Calculate k neighbors for contents per topic and F2 score","metadata":{}},{"cell_type":"code","source":"%%time\ndef k_neighbors (k, topics_embeddings, content_embeddings, topics_id_for_embeddings, content_ids_for_embeddings, df_corr, langs, lang_lim):\n    \"\"\"\n    Calculate k neighbors of contents:id's for each topic_id\n    \"\"\"\n    device = 'cpu'\n    if torch.cuda.is_available():\n        device = torch.device('cuda:0')\n    if device == 'cpu':\n        from sklearn.neighbors import NearestNeighbors\n    else:\n        import cudf\n        import cuml\n        from cuml.neighbors import NearestNeighbors\n\n    print ('\\nSetting up KNN model...')\n    # Model\n    min_sample = min(len(content_embeddings[i]) for i in range(len(content_embeddings)))\n    if k > min_sample:\n        k = min_sample\n    print ('\\n K value:', k)\n    model = NearestNeighbors(n_neighbors=k, \n                             n_jobs=-1)\n\n    print ('\\nFitting KNN model...')\n    # Fit and Predictions\n    list_aux=[]\n    topics_count = 0\n    for lang in range(lang_lim):\n        print (f'\\nGetting content_ids for topics in {lang+1}:{langs[lang]} from {lang_lim} languages')\n        topics_count = topics_count + len(topics_embeddings[lang])\n        if content_embeddings[lang].size != 1:\n            nbrs = model.fit(content_embeddings[lang])\n            _, indices = nbrs.kneighbors(topics_embeddings[lang])\n            content_id_list = [content_ids_for_embeddings[1][val] for i, val in enumerate (indices)]\n            list_aux.append (dict (language=langs[lang], \n                                   content_ids=content_id_list))\n        else:\n            list_aux.append (dict (language=langs[lang], content_ids=np.zeros(len(topics_id_for_embeddings[lang]))))\n\n    print ('\\nCalculating scores...')\n    #Define dataframes for predictions and ground truth\n    df_preds = get_preds(list_aux, topics_id_for_embeddings)\n    df_true = get_true(df_corr, df_preds)\n    fscore = calculate_Fscore(df_preds.copy(), df_true.copy())\n    print ('\\nCorrect predictions:', fscore.correct_pred.sum())\n    print (fscore.f2.mean())\n    #print ('\\n\\nF2 score by sklearn functions:')\n    #model_scoring (df_preds.copy(), df_true.copy(), average='micro')\n    print ('\\n')\n    \n    return model, df_preds, df_true, fscore","metadata":{"execution":{"iopub.status.busy":"2023-01-26T18:46:09.628304Z","iopub.execute_input":"2023-01-26T18:46:09.628740Z","iopub.status.idle":"2023-01-26T18:46:09.645693Z","shell.execute_reply.started":"2023-01-26T18:46:09.628698Z","shell.execute_reply":"2023-01-26T18:46:09.644513Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"CPU times: user 7 µs, sys: 0 ns, total: 7 µs\nWall time: 13.1 µs\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## K parameter vs F2 score","metadata":{}},{"cell_type":"code","source":"Encoder = paraphrase\nLanguage_limit = 5\nK0 = 5\nF2_score0 = 0.14187983285626535\nK1 = 10\nF2_score1 = 0.14168308552036216\nK2 = 20\nF2_score2 = 0.13348882325195702\nK3 = 30\nF2_score3 = 0.1252348976238163\nLanguage_limit = 20\nK0 = 5\nF2_score0 = 0.060680956642008434\nk1 = 10\nF2_score0 = 0.04720607798794654\nk2 = 20\nF2_score1 = 0.0348693757018806\nk5 = 100\nF2_score5 = 0.016168764671525976\nEncoder = trained_model\nLanguage_limit = 10\nk1 = 2 #limited by the sample dataset\nF2_score1 = 0.32051279617850204\n","metadata":{"execution":{"iopub.status.busy":"2023-01-26T18:46:09.647804Z","iopub.execute_input":"2023-01-26T18:46:09.649175Z","iopub.status.idle":"2023-01-26T18:46:09.658370Z","shell.execute_reply.started":"2023-01-26T18:46:09.649130Z","shell.execute_reply":"2023-01-26T18:46:09.657087Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# Submissions\n\n","metadata":{}},{"cell_type":"code","source":"#Getting parameters\nlangs = df_topics_test['language'].value_counts (ascending=True).reset_index()['index'].to_list()\nlangs_limit = len(langs)\nK = k[1]\n\n#Getting topics breadcrumbs or topics context\nprint (\"\\n* Getting 'topics_breadcrumbs' dataframe...\\n\")\ndf_topic_breadcrumbs = get_topic_breadcrumbs (df_subs_topics)\n\n#Cleaning data and getting topics and contents features\nprint ('\\n* Calculating topics_features dataframe...\\n')\nsub_topics_features = build_topic_features (df_subs_topics, df_topic_breadcrumbs, levels, topics_cols)\n\nprint ('\\n* Calculating content_features dataframe...\\n')\nsub_contents_features = build_content_features (df_subs_contents, content_cols)\n\n#Calculating embeddings from text\nprint ('\\n* Calculating embeddings for both topics and contents text columns...\\n')\nsub_topics_embeds, sub_contents_embeds, topic_id_embeds, content_ids_embeds = get_embeddings(sub_topics_features, sub_contents_features, langs, lang_limit)\n\n#Calculating unsupervised k neighbours contents, for topics\nprint ('\\n* Calculating k neighnors predictions...\\n')\nmodel, preds, ground_truth, fscore = k_neighbors (K, sub_topics_embeds, sub_contents_embeds, topic_id_embeds, content_ids_embeds, df_corr, langs, lang_limit)\n\nprint ('\\n All finished!\\n')\nprint ('\\n*** Predictions ***\\n')\ndisplay(preds)\nprint ('\\n*** Score ***\\n')\ndisplay(fscore)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T16:01:57.456163Z","iopub.execute_input":"2023-01-26T16:01:57.456510Z","iopub.status.idle":"2023-01-26T16:02:01.617234Z","shell.execute_reply.started":"2023-01-26T16:01:57.456483Z","shell.execute_reply":"2023-01-26T16:02:01.616050Z"},"trusted":true},"execution_count":260,"outputs":[{"name":"stdout","text":"\n* Getting 'topics_breadcrumbs' dataframe...\n\nCreating breadcrumbs...\nCreating dataframe from breadcrumbs 'df_topics_breadcrumbs'...\n\n* Calculating topics_features dataframe...\n\n\nCreating and cleaning topic features...\n\nCreated 'topic_features'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"               channel category  level language  has_content  \\\ntopic_id                                                       \nt_00004da3a1b2  000cf7   source   four       bg         True   \nt_00068291e9a4  8e286a   source   four       pt         True   \nt_00069b63a70a  6e3ba4   source  three       en         True   \nt_0006d41a73a8  000cf7   source   four       bg         True   \nt_4054df11a74e  6e3ba4   source    two       en         True   \n\n                                                      content_ids  \\\ntopic_id                                                            \nt_00004da3a1b2  c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c...   \nt_00068291e9a4  c_639ea2ef9c95 c_89ce9367be10 c_ac1672cdcd2c c...   \nt_00069b63a70a                                     c_11a1dc0bfb99   \nt_0006d41a73a8  c_0c6473c3480d c_1c57a1316568 c_5e375cf14c47 c...   \nt_4054df11a74e                      c_3695c5dc1df6 c_f2d184a98231   \n\n                                                        sentences  \ntopic_id                                                           \nt_00004da3a1b2  Откриването на резисторите.Изследване на матер...  \nt_00068291e9a4  Entradas e saídas de uma função.Entenda um pou...  \nt_00069b63a70a  Transcripts..MIT Blossoms Engineering Flow Cha...  \nt_0006d41a73a8  Графики на експоненциални функции  Алгебра 2 н...  \nt_4054df11a74e  Flow Charts  Logical Thinking .This lesson is ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>channel</th>\n      <th>category</th>\n      <th>level</th>\n      <th>language</th>\n      <th>has_content</th>\n      <th>content_ids</th>\n      <th>sentences</th>\n    </tr>\n    <tr>\n      <th>topic_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>t_00004da3a1b2</th>\n      <td>000cf7</td>\n      <td>source</td>\n      <td>four</td>\n      <td>bg</td>\n      <td>True</td>\n      <td>c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c...</td>\n      <td>Откриването на резисторите.Изследване на матер...</td>\n    </tr>\n    <tr>\n      <th>t_00068291e9a4</th>\n      <td>8e286a</td>\n      <td>source</td>\n      <td>four</td>\n      <td>pt</td>\n      <td>True</td>\n      <td>c_639ea2ef9c95 c_89ce9367be10 c_ac1672cdcd2c c...</td>\n      <td>Entradas e saídas de uma função.Entenda um pou...</td>\n    </tr>\n    <tr>\n      <th>t_00069b63a70a</th>\n      <td>6e3ba4</td>\n      <td>source</td>\n      <td>three</td>\n      <td>en</td>\n      <td>True</td>\n      <td>c_11a1dc0bfb99</td>\n      <td>Transcripts..MIT Blossoms Engineering Flow Cha...</td>\n    </tr>\n    <tr>\n      <th>t_0006d41a73a8</th>\n      <td>000cf7</td>\n      <td>source</td>\n      <td>four</td>\n      <td>bg</td>\n      <td>True</td>\n      <td>c_0c6473c3480d c_1c57a1316568 c_5e375cf14c47 c...</td>\n      <td>Графики на експоненциални функции  Алгебра 2 н...</td>\n    </tr>\n    <tr>\n      <th>t_4054df11a74e</th>\n      <td>6e3ba4</td>\n      <td>source</td>\n      <td>two</td>\n      <td>en</td>\n      <td>True</td>\n      <td>c_3695c5dc1df6 c_f2d184a98231</td>\n      <td>Flow Charts  Logical Thinking .This lesson is ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\n* Calculating content_features dataframe...\n\n\nCreating and cleaning content features...\n\nCreated 'content_features'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                    kind language      license  \\\ncontent_ids                                      \nc_0c6473c3480d     video       bg  CC BY-NC-SA   \nc_1108dd0c7a5d     video       bg                \nc_11a1dc0bfb99  document       en  CC BY-NC-SA   \nc_1c57a1316568     video       bg  CC BY-NC-SA   \nc_3695c5dc1df6     html5       en  CC BY-NC-SA   \n\n                                                        sentences  \ncontent_ids                                                        \nc_0c6473c3480d  Чертане на показателни финкции.Сал чертае y  2...  \nc_1108dd0c7a5d  Молив като резистор.Моливът причинява промяна ...  \nc_11a1dc0bfb99  Flow Charts  Logical    Written Transcript of ...  \nc_1c57a1316568  Графики на показателни функции  стар пример .С...  \nc_3695c5dc1df6  Additional Resources for Flow Charts  Logical ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>kind</th>\n      <th>language</th>\n      <th>license</th>\n      <th>sentences</th>\n    </tr>\n    <tr>\n      <th>content_ids</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>c_0c6473c3480d</th>\n      <td>video</td>\n      <td>bg</td>\n      <td>CC BY-NC-SA</td>\n      <td>Чертане на показателни финкции.Сал чертае y  2...</td>\n    </tr>\n    <tr>\n      <th>c_1108dd0c7a5d</th>\n      <td>video</td>\n      <td>bg</td>\n      <td></td>\n      <td>Молив като резистор.Моливът причинява промяна ...</td>\n    </tr>\n    <tr>\n      <th>c_11a1dc0bfb99</th>\n      <td>document</td>\n      <td>en</td>\n      <td>CC BY-NC-SA</td>\n      <td>Flow Charts  Logical    Written Transcript of ...</td>\n    </tr>\n    <tr>\n      <th>c_1c57a1316568</th>\n      <td>video</td>\n      <td>bg</td>\n      <td>CC BY-NC-SA</td>\n      <td>Графики на показателни функции  стар пример .С...</td>\n    </tr>\n    <tr>\n      <th>c_3695c5dc1df6</th>\n      <td>html5</td>\n      <td>en</td>\n      <td>CC BY-NC-SA</td>\n      <td>Additional Resources for Flow Charts  Logical ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\n* Calculating embeddings for both topics and contents text columns...\n\n\nGetting embeddings for 1:pt from 3 languages\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cf055c9f37e4f8b99df012eb968517d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4399d56facd45b089846645031826c8"}},"metadata":{}},{"name":"stdout","text":"\nGetting embeddings for 2:bg from 3 languages\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"576786046e824a808e8cf8cabca49fdf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25e12ddf3f2c4ee5800e214196f0c6e3"}},"metadata":{}},{"name":"stdout","text":"\nGetting embeddings for 3:en from 3 languages\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e20babe40b8439bb727b3c966b5b8ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ea3354d57c04cc59feca0f8ed90af87"}},"metadata":{}},{"name":"stdout","text":"\n* Calculating k neighnors predictions...\n\n\nSetting up KNN model...\n\n K value: 2\n\nFitting KNN model...\n\nGetting content_ids for topics in 1:pt from 3 languages\n[[3 0]]\n\nGetting content_ids for topics in 2:bg from 3 languages\n[[1 4]\n [2 5]]\n\nGetting content_ids for topics in 3:en from 3 languages\n[[1 0]\n [1 0]]\n\nCalculating scores...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  language                                        content_ids  \\\n0       pt                 [[c_376c5a8eb028, c_0c6473c3480d]]   \n1       bg  [[c_1108dd0c7a5d, c_5bc0e1e2cba0], [c_1c57a131...   \n2       en  [[c_1108dd0c7a5d, c_0c6473c3480d], [c_1108dd0c...   \n\n                                            topic_id  \n0  Index(['t_00068291e9a4'], dtype='object', name...  \n1  Index(['t_00004da3a1b2', 't_0006d41a73a8'], dt...  \n2  Index(['t_00069b63a70a', 't_4054df11a74e'], dt...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>language</th>\n      <th>content_ids</th>\n      <th>topic_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>pt</td>\n      <td>[[c_376c5a8eb028, c_0c6473c3480d]]</td>\n      <td>Index(['t_00068291e9a4'], dtype='object', name...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bg</td>\n      <td>[[c_1108dd0c7a5d, c_5bc0e1e2cba0], [c_1c57a131...</td>\n      <td>Index(['t_00004da3a1b2', 't_0006d41a73a8'], dt...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>en</td>\n      <td>[[c_1108dd0c7a5d, c_0c6473c3480d], [c_1108dd0c...</td>\n      <td>Index(['t_00069b63a70a', 't_4054df11a74e'], dt...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nCorrect predictions: 4\n\nF2 score from scratch: 0.32051279617850204\n\n\nF2 score by sklearn functions:\nPrecision: 0.0\nRecall: 0.0\nF2 macro: 0.0\nF2 micro: 0.0\n\n\n\n All finished!\n\n\n*** Predictions ***\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"         topic_id                    content_ids\n0  t_00068291e9a4  c_376c5a8eb028 c_0c6473c3480d\n1  t_00004da3a1b2  c_1108dd0c7a5d c_5bc0e1e2cba0\n2  t_0006d41a73a8  c_1c57a1316568 c_5e375cf14c47\n3  t_00069b63a70a  c_1108dd0c7a5d c_0c6473c3480d\n4  t_4054df11a74e  c_1108dd0c7a5d c_0c6473c3480d","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic_id</th>\n      <th>content_ids</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>t_00068291e9a4</td>\n      <td>c_376c5a8eb028 c_0c6473c3480d</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>t_00004da3a1b2</td>\n      <td>c_1108dd0c7a5d c_5bc0e1e2cba0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>t_0006d41a73a8</td>\n      <td>c_1c57a1316568 c_5e375cf14c47</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>t_00069b63a70a</td>\n      <td>c_1108dd0c7a5d c_0c6473c3480d</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>t_4054df11a74e</td>\n      <td>c_1108dd0c7a5d c_0c6473c3480d</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\n*** Score ***\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"         topic_id                  content_ids_pred  \\\n0  t_00068291e9a4  [c_376c5a8eb028, c_0c6473c3480d]   \n1  t_00004da3a1b2  [c_1108dd0c7a5d, c_5bc0e1e2cba0]   \n2  t_0006d41a73a8  [c_1c57a1316568, c_5e375cf14c47]   \n3  t_00069b63a70a  [c_1108dd0c7a5d, c_0c6473c3480d]   \n4  t_4054df11a74e  [c_1108dd0c7a5d, c_0c6473c3480d]   \n\n                                  content_ids_actual  correct_pred  precision  \\\n0  [c_639ea2ef9c95, c_89ce9367be10, c_ac1672cdcd2...             0        0.0   \n1  [c_1108dd0c7a5d, c_376c5a8eb028, c_5bc0e1e2cba...             2        0.5   \n2  [c_0c6473c3480d, c_1c57a1316568, c_5e375cf14c4...             2        0.4   \n3                                   [c_11a1dc0bfb99]             0        0.0   \n4                   [c_3695c5dc1df6, c_f2d184a98231]             0        0.0   \n\n   recall      f0.5        f1        f2  \n0     0.0  0.000000  0.000000  0.000000  \n1     1.0  0.555555  0.666667  0.833333  \n2     1.0  0.454545  0.571429  0.769231  \n3     0.0  0.000000  0.000000  0.000000  \n4     0.0  0.000000  0.000000  0.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic_id</th>\n      <th>content_ids_pred</th>\n      <th>content_ids_actual</th>\n      <th>correct_pred</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f0.5</th>\n      <th>f1</th>\n      <th>f2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>t_00068291e9a4</td>\n      <td>[c_376c5a8eb028, c_0c6473c3480d]</td>\n      <td>[c_639ea2ef9c95, c_89ce9367be10, c_ac1672cdcd2...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>t_00004da3a1b2</td>\n      <td>[c_1108dd0c7a5d, c_5bc0e1e2cba0]</td>\n      <td>[c_1108dd0c7a5d, c_376c5a8eb028, c_5bc0e1e2cba...</td>\n      <td>2</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>0.555555</td>\n      <td>0.666667</td>\n      <td>0.833333</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>t_0006d41a73a8</td>\n      <td>[c_1c57a1316568, c_5e375cf14c47]</td>\n      <td>[c_0c6473c3480d, c_1c57a1316568, c_5e375cf14c4...</td>\n      <td>2</td>\n      <td>0.4</td>\n      <td>1.0</td>\n      <td>0.454545</td>\n      <td>0.571429</td>\n      <td>0.769231</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>t_00069b63a70a</td>\n      <td>[c_1108dd0c7a5d, c_0c6473c3480d]</td>\n      <td>[c_11a1dc0bfb99]</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>t_4054df11a74e</td>\n      <td>[c_1108dd0c7a5d, c_0c6473c3480d]</td>\n      <td>[c_3695c5dc1df6, c_f2d184a98231]</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#import pickle\n#pickle.dump(model, open(f'ST-KNN-{k[1]}', 'wb'))\npreds.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T14:24:52.528789Z","iopub.execute_input":"2023-01-26T14:24:52.529283Z","iopub.status.idle":"2023-01-26T14:24:52.538005Z","shell.execute_reply.started":"2023-01-26T14:24:52.529246Z","shell.execute_reply":"2023-01-26T14:24:52.537003Z"},"trusted":true},"execution_count":185,"outputs":[]}]}