{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sofiamatias/learning-equality-model2-predicts-sm?scriptVersionId=118150524\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"# Kaggle Challenge - Learning Equality","metadata":{"id":"88080462"}},{"cell_type":"markdown","source":"https://www.kaggle.com/competitions/learning-equality-curriculum-recommendations/overview\n\n## Goal of the Competition\n\nThe goal of this competition is to streamline the process of matching educational content to specific topics in a curriculum. You will develop an accurate and efficient model trained on a library of K-12 educational materials that have been organized into a variety of topic taxonomies. These materials are in diverse languages, and cover a wide range of topics, particularly in STEM (Science, Technology, Engineering, and Mathematics).\n\nYour work will enable students and educators to more readily access relevant educational content to support and supplement learning.","metadata":{"id":"e44162a6"}},{"cell_type":"markdown","source":"## Submission File\n\nFor each **topic_id** in the test set, you must predict a space-delimited list of recommended **content_ids** for that topic. The file should contain a header and have the following format:\n\n~~~\ntopic_id,content_ids\nt_00004da3a1b2,c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c_76231f9d0b5e\nt_00068291e9a4,c_639ea2ef9c95 c_89ce9367be10 c_ac1672cdcd2c c_ebb7fdf10a7e\nt_00069b63a70a,c_11a1dc0bfb99\n...\n~~~","metadata":{"id":"d827eb0b"}},{"cell_type":"markdown","source":"## Scoring\nMean F2 score","metadata":{"id":"de5f7ef4"}},{"cell_type":"markdown","source":"## Evaluation Metric - Efficiency Scoring\nWe compute a submission's efficiency score by:\n\n\\begin{equation} \\text{Efficiency} = \\frac{1}{ \\text{Benchmark} - \\max\\text{F2} }\\text{F2} + \\frac{1}{32400}\\text{RuntimeSeconds} \\end{equation}\n\n\nwhere **F2** is the submission's score on the main competition metric, **Benchmark** is the score of the benchmark sample_submission.csv, **maxF2** is the maximum  of all submissions on the Private Leaderboard, and **RuntimeSeconds** is the number of seconds it takes for the submission to be evaluated. The objective is to minimize the efficiency score.\n\nDuring the training period of the competition, you may see a leaderboard for the public test data in the following notebook, updated daily: Efficiency Leaderboard. After the competition ends, we will update this leaderboard with efficiency scores on the private data. During the training period, this leaderboard will show only the rank of each team, but not the complete score.","metadata":{"id":"b86e3e62"}},{"cell_type":"markdown","source":"# How To Solve This Challenge","metadata":{}},{"cell_type":"markdown","source":"## Model Train\n\n* Calculate embeddings: for topics (title, description) and contents (title, description and text), use SentenceTransformer. Split sentences by language.\n* Use KNN model: train model with content embeddings and use topic embeddings to predict content matches, use k=10, 20, 30, 50\n* Calculate F2 to choose best k.\n* Submit predictions\n* Set X_train, X_test, y_train, y_test: split by category (use 'aligned' for validation), set has_content = True for validation. Check dimensions\n* Use all features for X, including topic_id and content_id, topic_title and content_title. Use the KNN predictions to \"mount\" X and y. Check dimensions.\n* Use correlations to get y: if KNN topic-content match with correlations, y is 1, else is 0\n* Use SVM RBF , KNN or another classifier for binary classification\n* Use RandomizedSearch to get best hyperparameters. Use model score \"recall\". Split the dataset in languages for training: train model for each language individually\n* Calculate F2 and see if we've got improvements from KNN.\n* Submit predictions\n\n## Submissions\n\n* Use submission sample and get topics and contents\n* Apply KNN model to get topic-content matches. Get contents per topic\n* Filter \"good matches\" with second classification model\n* Compare predicts with submission sample and calculate F2\n\n## Efficiency\n\n* Use KNN and 2nd model without GPU and check if it takes a long time to calculate sample submissions","metadata":{}},{"cell_type":"markdown","source":"# Data","metadata":{"id":"e2cc9cb4"}},{"cell_type":"markdown","source":"## Imports","metadata":{"id":"eb712db6"}},{"cell_type":"code","source":"import sys, os\nsys.path.append(\"../input/sentence-transformer-package/sentence-transformers-2.2.2/sentence-transformers-2.2.2\") \nimport sentence_transformers","metadata":{"id":"2eBKbVKiQm-Z","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q /kaggle/input/loguru-lib-ds/loguru-0.5.3-py3-none-any.whl","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport string\nimport datetime\nimport torch\nfrom pathlib import Path\nfrom sentence_transformers import SentenceTransformer, util\nfrom sklearn.metrics import precision_score, recall_score, fbeta_score\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_validate, train_test_split","metadata":{"id":"b5f3a3b6","execution":{"iopub.status.busy":"2023-02-03T11:08:45.176162Z","iopub.execute_input":"2023-02-03T11:08:45.176555Z","iopub.status.idle":"2023-02-03T11:08:45.182829Z","shell.execute_reply.started":"2023-02-03T11:08:45.176513Z","shell.execute_reply":"2023-02-03T11:08:45.181738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_PATH = Path.cwd().parent.resolve()\ndrive_path = DATA_PATH / 'input'\nfiles_path = DATA_PATH / 'input/learning-equality-curriculum-recommendations'\ndataset_path = drive_path / 'learningequalityfiles'\nwork_path = DATA_PATH / 'working'\nmodel_path = '/kaggle/input/sentence-transformer-package/ST-all-MiniLM-L6-v2-trained/ST-all-MiniLM-L6-v2-trained'","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:08:45.184146Z","iopub.execute_input":"2023-02-03T11:08:45.184493Z","iopub.status.idle":"2023-02-03T11:08:45.19538Z","shell.execute_reply.started":"2023-02-03T11:08:45.184458Z","shell.execute_reply":"2023-02-03T11:08:45.194367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Collection","metadata":{"id":"e55f4587"}},{"cell_type":"markdown","source":"## Load dataframes","metadata":{"id":"FJLGLdJ-wKZI"}},{"cell_type":"code","source":"def read_file_in_chunks(filename):\n        \n    list_chunks = []\n    chunksize = 10000\n    with pd.read_csv(filename, chunksize=chunksize, index_col=0) as reader:\n        for chunk in reader:\n            list_chunks.append(chunk)\n    df = pd.concat(list_chunks)\n    return df","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:08:45.197491Z","iopub.execute_input":"2023-02-03T11:08:45.198425Z","iopub.status.idle":"2023-02-03T11:08:45.210509Z","shell.execute_reply.started":"2023-02-03T11:08:45.198388Z","shell.execute_reply":"2023-02-03T11:08:45.209303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loading dataframes from existing .csv files\n\nprint (f\"\\nLoading dataframes...\")\n\ndf_content = pd.DataFrame([])\ndf_topics = pd.DataFrame([])\ndf_corr = pd.DataFrame([])\ndf_sample = pd.DataFrame([])\nfor path, subdirs, files in os.walk(drive_path):\n    for file in files:\n        if file.endswith(\".csv\") == True:\n            filepath = os.path.join(path, file)\n            df = read_file_in_chunks(filepath)\n            if set(['copyright_holder', 'kind']).issubset(df.columns) and df_content.empty:\n                df_content = df.fillna({\"title\": \"\", \"description\": \"\"})\n                display(df_content.head())\n                print (f\"\\nLoaded 'df_content' from {filepath} with shape {df_content.shape}\")\n            elif set(['channel', 'parent']).issubset(df.columns):\n                df_topics = df.fillna({\"title\": \"\", \"description\": \"\"})\n                display(df_topics.head())\n                print (f\"\\nLoaded 'df_topics' from {filepath} with shape {df_topics.shape}\")\n            elif ('content_ids' in df.columns) and ('correlation' in file) and (df_corr.empty):\n                df_corr = df\n                display(df_corr.head())\n                print (f\"\\nLoaded 'df_corr' from {filepath}  with shape {df_corr.shape}\")\n            if ('sample' in file):\n                df_sample = df\n                display(df_sample)\n                print (f\"\\nLoaded 'df_sample' from {filepath}\")","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:08:45.214214Z","iopub.execute_input":"2023-02-03T11:08:45.214473Z","iopub.status.idle":"2023-02-03T11:09:09.485186Z","shell.execute_reply.started":"2023-02-03T11:08:45.214447Z","shell.execute_reply":"2023-02-03T11:09:09.484247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Sampling 'df_topics' and 'df_content' with sample_submission\n#if ~df_sample.empty:\n#    df_topics = df_topics.merge(df_sample, how='inner', left_index=True, right_index=True)\n#    print (f\"\\nFiltered 'df_topics' according to 'sample_submission'\")\n#    display (df_topics)\n\n#Sampling with limited number of rows\nnum_samples = 20000\ndf_topics = df_topics.sample(n=num_samples//2)\n#df_content = df_content.sample(n=num_samples)\nprint (f\"\\nSampled {num_samples//2} rows from 'df_topics' for model training\")\n#display (df_content)\ndisplay (df_topics)\n\nif df_content.empty and df_topics.empty:\n    print ('Error: there are no topics or content files to work with')\n    quit()","metadata":{"execution":{"iopub.status.busy":"2023-02-03T18:31:39.857434Z","iopub.execute_input":"2023-02-03T18:31:39.858404Z","iopub.status.idle":"2023-02-03T18:31:39.932588Z","shell.execute_reply.started":"2023-02-03T18:31:39.858274Z","shell.execute_reply":"2023-02-03T18:31:39.930969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load 'correlations' data into pandas dataframe\n# Restructure 'df_corr' (correlations): explode the target column to be more practical to use - one topic -> one content\ny = df_corr.copy()\ny['content_ids'] = y.content_ids.str.split(' ')\ny = y.explode('content_ids')\ny.reset_index(inplace=True)\nprint (f\"\\nChanged 'df_corr' to exploded 'y'\")\ndisplay(y)","metadata":{"id":"29667ed7","outputId":"8f3c7bd9-ebd8-4729-a901-ba908e7739fb","execution":{"iopub.status.busy":"2023-02-03T11:09:09.540924Z","iopub.execute_input":"2023-02-03T11:09:09.541257Z","iopub.status.idle":"2023-02-03T11:09:09.739613Z","shell.execute_reply.started":"2023-02-03T11:09:09.54123Z","shell.execute_reply":"2023-02-03T11:09:09.738578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Topic Breadcrumbs Functions","metadata":{}},{"cell_type":"code","source":"# define some helper functions and classes to aid with data traversal\n\ndef get_topic_breadcrumbs (df_topic):\n    print (f\"Creating breadcrumbs...\")\n    topic_breadcrumbs=[]\n    topic_ids=[]\n    if 'topic_id' == df_topics.index.name:\n        col_name = 'topic_id'\n    else:\n        col_name = 'id'\n    for i, topic in enumerate(df_topic.index):\n        if (i % 5000 == 0) and (i > 0):\n            print (f'Created {i} breadcrumbs...')\n        if df_topic.loc[topic].parent in df_topic.index:\n            topic_ids.append (topic)\n            topic_breadcrumbs.append (Topic(topic).get_breadcrumbs(separator=' '))\n    print (f\"Creating dataframe from breadcrumbs 'df_topics_breadcrumbs'...\")\n    df_topics_breadcrumbs = pd.DataFrame (topic_breadcrumbs, \n                                          index = topic_ids,\n                                          columns = ['topic_breadcrumbs'])\n    return df_topics_breadcrumbs\n\n\ndef print_markdown(md):\n    display(Markdown(md))\n\nclass Topic:\n    def __init__(self, topic_id):\n        self.id = topic_id\n\n    @property\n    def parent(self):\n        parent_id = df_topics.loc[self.id].parent\n        if pd.isna(parent_id):\n            return None\n        else:\n            return Topic(parent_id)\n\n    @property\n    def ancestors(self):\n        ancestors = []\n        parent = self.parent\n        while (parent is not None) and (parent.id in df_topics.index):\n            ancestors.append(parent)\n            parent = parent.parent\n        return ancestors\n\n    @property\n    def siblings(self):\n        if not self.parent:\n            return []\n        else:\n            return [topic for topic in self.parent.children if topic != self]\n\n    @property\n    def content(self):\n        if self.id in df_corr.index:\n            return [ContentItem(content_id) for content_id in df_corr.loc[self.id].content_ids.split()]\n        else:\n            return tuple([]) if self.has_content else []\n\n    def get_breadcrumbs(self, separator=\" >> \", include_self=True, include_root=True):\n        ancestors = self.ancestors\n        if include_self:\n            ancestors = [self] + ancestors\n        if not include_root:\n            ancestors = ancestors[:-1]\n        return separator.join(reversed([a.title for a in ancestors]))\n\n    @property\n    def children(self):\n        return [Topic(child_id) for child_id in df_topics[df_topics.parent == self.id].index]\n\n    def subtree_markdown(self, depth=0):\n        markdown = \"  \" * depth + \"- \" + self.title + \"\\n\"\n        for child in self.children:\n            markdown += child.subtree_markdown(depth=depth + 1)\n        for content in self.content:\n            markdown += (\"  \" * (depth + 1) + \"- \" + \"[\" + content.kind.title() + \"] \" + content.title) + \"\\n\"\n        return markdown\n\n    def __eq__(self, other):\n        if not isinstance(other, Topic):\n            return False\n        return self.id == other.id\n\n    def __getattr__(self, name):\n        return df_topics.loc[self.id][name]\n\n    def __str__(self):\n        return self.title\n    \n    def __repr__(self):\n        return f\"<Topic(id={self.id}, title=\\\"{self.title}\\\")>\"\n\n\nclass ContentItem:\n    def __init__(self, content_id):\n        self.id = content_id\n\n    @property\n    def topics(self):\n        return [Topic(topic_id) for topic_id in df_topics.loc[df_corr[df_corr.content_ids.str.contains(self.id)].index].index]\n\n    def __getattr__(self, name):\n        return content_df.loc[self.id][name]\n\n    def __str__(self):\n        return self.title\n    \n    def __repr__(self):\n        return f\"<ContentItem(id={self.id}, title=\\\"{self.title}\\\")>\"\n\n    def __eq__(self, other):\n        if not isinstance(other, ContentItem):\n            return False\n        return self.id == other.id\n\n    def get_all_breadcrumbs(self, separator=\" >> \", include_root=True):\n        breadcrumbs = []\n        for topic in self.topics:\n            new_breadcrumb = topic.get_breadcrumbs(separator=separator, include_root=include_root)\n            if new_breadcrumb:\n                new_breadcrumb = new_breadcrumb + separator + self.title\n            else:\n                new_breadcrumb = self.title\n            breadcrumbs.append(new_breadcrumb)\n        return breadcrumbs","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:09:09.741429Z","iopub.execute_input":"2023-02-03T11:09:09.74209Z","iopub.status.idle":"2023-02-03T11:09:09.774807Z","shell.execute_reply.started":"2023-02-03T11:09:09.742052Z","shell.execute_reply":"2023-02-03T11:09:09.773867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Cleaning","metadata":{"id":"CP4lmcnV20yH"}},{"cell_type":"markdown","source":"## Data cleaning params","metadata":{"id":"rjw9Pdqqlzdp"}},{"cell_type":"code","source":"levels = {1: 'one', 2: 'two', 3: 'three', 4: 'four', 5: 'five', 6: 'six', 7: 'seven', 8: 'eight',\n          9: 'nine', 10: 'ten', 0: 'zero'}\ntopics_cols = ['title', 'description', 'topic_breadcrumbs']\ncontent_cols = ['title', 'description', 'text']\ncat_for_val = 'aligned'\nprint (f\"\\nLoaded cleaning parameters\")","metadata":{"id":"qpgsrMQyl10Y","execution":{"iopub.status.busy":"2023-02-03T11:09:09.776507Z","iopub.execute_input":"2023-02-03T11:09:09.777164Z","iopub.status.idle":"2023-02-03T11:09:09.787866Z","shell.execute_reply.started":"2023-02-03T11:09:09.777125Z","shell.execute_reply":"2023-02-03T11:09:09.78654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data cleaning functions","metadata":{"id":"Hwk6JtmRbn42"}},{"cell_type":"code","source":"# Clean up text\ndef clean_text(text_col):\n    \"\"\"\n    Clean ponctuation and special chars from a dataframe column\n    \"\"\"\n    punctuations = string.punctuation\n    text_col = text_col.str.replace('\\W', ' ', regex=True)\n    for punct in string.punctuation:\n        text_col = text_col.str.replace(punct, ' ', regex=True)\n    return text_col","metadata":{"id":"xRgKUBVjbstB","execution":{"iopub.status.busy":"2023-02-03T11:09:09.789492Z","iopub.execute_input":"2023-02-03T11:09:09.790248Z","iopub.status.idle":"2023-02-03T11:09:09.796493Z","shell.execute_reply.started":"2023-02-03T11:09:09.790211Z","shell.execute_reply":"2023-02-03T11:09:09.795548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Topics\n\n*   Changing 'level' values from integers to strings\n*   Clean strings: ponctuation and special chars (\\n\\t...)\n*   Sort values by language","metadata":{"id":"WmkMQLZHaDmd"}},{"cell_type":"code","source":"def build_topic_features (topics_df, df_topics_breadcrumbs, levels, topic_cols):\n    \"\"\"\n    Create 'topics_features' from df_topics, clean parameters and functions\n    \"\"\"\n    print (f\"\\nCreating and cleaning topic features...\")\n    topics_features = topics_df.copy()\n    topics_features = topics_features.replace ({'level': levels})\n    topics_features = topics_features.merge (df_topic_breadcrumbs, how='outer', right_index=True, left_index=True)\n    for col in topics_cols:\n        topics_features[col] = clean_text(topics_features[col])\n    topics_features['sentences'] = topics_features[topics_cols].apply(lambda x: '.'.join(x.dropna().astype(str)), axis=1)\n    topics_features = topics_features.drop(columns=['parent'] + topics_cols) \n    print (f\"\\nCreated 'topic_features'\")\n    display (topics_features.head())\n    \n    return topics_features\n","metadata":{"id":"prh6uaPXlyMr","execution":{"iopub.status.busy":"2023-02-03T11:09:09.797975Z","iopub.execute_input":"2023-02-03T11:09:09.798606Z","iopub.status.idle":"2023-02-03T11:09:09.807726Z","shell.execute_reply.started":"2023-02-03T11:09:09.79857Z","shell.execute_reply":"2023-02-03T11:09:09.806681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Contents\n\n\n*   Remove columns 'copyright_holder' and 'language' (for 'language' assume that topic-content match with correlations is same language)\n*   Clean strings: ponctuation and special chars (\\n\\t...)","metadata":{"id":"m-sO4fCibFIb"}},{"cell_type":"code","source":"def build_content_features (content_df, content_cols):\n    \"\"\"\n    Create 'content_features' from df_content, clean parameters and functions\n    \"\"\"\n    print (f\"\\nCreating and cleaning content features...\")\n    content_features = content_df.copy()\n    for col in content_cols:\n        content_features[col] = clean_text(content_features[col])\n    content_features['sentences'] =  content_features[content_cols].apply(lambda x: '.'.join(x.dropna().astype(str)), axis=1)\n    content_features = content_features.drop(columns=['copyright_holder', 'license'] + content_cols)\n    print (f\"\\nCreated 'content_features'\")\n    display (content_features.head())\n    \n    return content_features","metadata":{"id":"fa3508db","execution":{"iopub.status.busy":"2023-02-03T11:09:09.809264Z","iopub.execute_input":"2023-02-03T11:09:09.80989Z","iopub.status.idle":"2023-02-03T11:09:09.82062Z","shell.execute_reply.started":"2023-02-03T11:09:09.809855Z","shell.execute_reply":"2023-02-03T11:09:09.819549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Train","metadata":{}},{"cell_type":"markdown","source":"### Scoring functions","metadata":{}},{"cell_type":"code","source":"def calculate_Fscore(pred_df, act_df):\n    \n    if pred_df.empty or act_df.empty:\n        print ('\\nOne or both dataframes are empty. Abort F2score calculation.')\n        return None\n    prediction_df=pred_df.copy()\n    actual_df = act_df.copy()\n    prediction_df['content_ids'] = prediction_df.content_ids.str.split(' ')\n    prediction_df.columns=['topic_id', 'content_ids_pred']\n    actual_df['content_ids'] = actual_df.content_ids.str.split(' ')\n    actual_df.columns=['topic_id', 'content_ids_actual']\n    df = pd.merge(prediction_df, actual_df, how='inner', on='topic_id')\n    df['correct_pred'] = df[['content_ids_pred', 'content_ids_actual']].apply(lambda x: len([d for d in x[0] if d in x[1]]), axis=1)\n    df_target = df.apply(lambda x: [(x[0], d) for d in x[1] if d in x[2]], axis=1).tolist()\n    df['precision'] = df['correct_pred']/(df.content_ids_actual.str.len() + 1e-7)\n    df['recall'] = df['correct_pred']/(df.content_ids_pred.str.len() + 1e-7)\n    for beta in [0.5, 1, 2]:\n        df['f'+str(beta)] = ((1 + beta**2) * df['precision'] * df['recall'])/((beta**2 * df['precision']) + df['recall'] + 1e-7) \n    print ('\\nF2score calculation finished.')\n\n    return df, df_target","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:09:09.822173Z","iopub.execute_input":"2023-02-03T11:09:09.822848Z","iopub.status.idle":"2023-02-03T11:09:09.834778Z","shell.execute_reply.started":"2023-02-03T11:09:09.822816Z","shell.execute_reply":"2023-02-03T11:09:09.833953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Calculate Embeddings Functions","metadata":{"id":"0866f1f5"}},{"cell_type":"markdown","source":"* Use output as pytorch tensor and normalize tensor embeddings\n* Convert to numpy array","metadata":{}},{"cell_type":"code","source":"def get_embeddings(topics_features, content_features):\n    \"\"\"\n    Calculate embeddings for both topics and content\n    From text in columns:\n    topic_cols=['title','description', 'topic_breadcrumbs'] \n    content_cols=['title','description', 'text']\n    \"\"\"\n    device = 'cpu'\n    if torch.cuda.is_available():\n        device = torch.device('cuda:0')\n\n    encoder = SentenceTransformer(paraphrase)\n    topics_id_for_embeddings=[]\n    topics_embeddings=[]\n    content_ids_for_embeddings=[]\n    content_embeddings=[]\n    topics_aux = []\n    content_aux = []\n\n    topics_sentences = topics_features['sentences']\n    print (f'\\nGetting embeddings for {len(topics_sentences)} sentences from topics')\n    # topics embeddings\n    topics_aux = encoder.encode(topics_sentences, convert_to_tensor=True)\n    topics_id_for_embeddings = topics_sentences.index\n    topics_embeddings = util.normalize_embeddings(topics_aux.to(device)).detach().cpu().numpy()\n    # content embeddings\n    content_sentences = content_features['sentences']\n    print (f'\\nGetting embeddings for {len(content_sentences)} sentences from contents')\n    content_ids_for_embeddings = content_sentences.index\n    content_aux = encoder.encode(content_sentences, convert_to_tensor=True)\n    content_embeddings = util.normalize_embeddings(content_aux.to(device)).detach().cpu().numpy()\n    \n    return topics_embeddings, content_embeddings, topics_id_for_embeddings, content_ids_for_embeddings","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:09:09.840625Z","iopub.execute_input":"2023-02-03T11:09:09.841282Z","iopub.status.idle":"2023-02-03T11:09:09.851456Z","shell.execute_reply.started":"2023-02-03T11:09:09.841246Z","shell.execute_reply":"2023-02-03T11:09:09.850535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Apply Sentence similarity scoring Function","metadata":{}},{"cell_type":"code","source":"# Calculating matches with similarity score\ndef similarity_matches (topic_ids_for_embeddings, content_ids_for_embeddings, content_embeds, topics_embeds, device, content_count_per_topic):\n\n    list_aux = []\n    start = datetime.datetime.now()\n    print (f\"\\nCalculating matches for {len(topics_embeds)} topic sentences...\")\n\n    if torch.is_tensor(content_embeds):\n        corpus_embeddings = content_embeds\n    else:\n        corpus_embeddings = torch.tensor(content_embeds)\n    if torch.is_tensor(topics_embeds):\n        query_embeddings = topics_embeds\n    else:\n        query_embeddings = torch.tensor(topics_embeds)\n\n    if device != torch.device('cuda:0'):\n        print ('\\nGPU is not active. Similarity calculation aborted.')\n        return None\n\n    # we use util.semantic_search to perform cosine similarty + topk\n    corpus_embeddings = corpus_embeddings.to('cuda')\n    corpus_embeddings = util.normalize_embeddings(corpus_embeddings)\n    query_embeddings = query_embeddings.to('cuda')\n    query_embeddings = util.normalize_embeddings(query_embeddings)\n    i = 0\n    for query in query_embeddings:\n        hits = util.semantic_search(query, corpus_embeddings, score_function=util.cos_sim, top_k=content_count_per_topic)\n        for hit in hits[0]:\n            list_aux.append (dict(topic_id = topic_ids_for_embeddings[i], content_ids = content_ids_for_embeddings[hit['corpus_id']], score = hit['score']))\n        i += 1\n        if i%1000 == 0:\n            print (i, ' topics matched.')\n    end  = datetime.datetime.now()\n    delta = end - start\n    print (\"Finished matching in:\", delta.total_seconds(), ' s')\n    df_preds = pd.DataFrame (list_aux)\n           \n    return df_preds","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:09:09.852802Z","iopub.execute_input":"2023-02-03T11:09:09.85361Z","iopub.status.idle":"2023-02-03T11:09:09.866455Z","shell.execute_reply.started":"2023-02-03T11:09:09.85351Z","shell.execute_reply":"2023-02-03T11:09:09.865489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_preds(df_preds):\n    \"\"\"\n    df_preds = Dataframe with topic_id's and KNN chosen content_ids\n    \"\"\"\n    df.content_ids = df.content_ids.str.join(' ')\n    df = df.fillna('')\n    return df","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:09:09.868049Z","iopub.execute_input":"2023-02-03T11:09:09.868714Z","iopub.status.idle":"2023-02-03T11:09:09.878785Z","shell.execute_reply.started":"2023-02-03T11:09:09.868677Z","shell.execute_reply":"2023-02-03T11:09:09.877768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_true(df_corr, df):\n    \"\"\"\n    Ground truth\n    df_true = Dataframe with same topic_id's from 'get_preds' function but content_id's taken from correlations, \n    for score calculations. Returns the format defined in 'correlations.csv' but as dataframe.\n    \"\"\"\n    df_true = df_corr.copy().reset_index().merge (df_preds, how='right', on='topic_id').iloc[:,[0,1]].rename(columns={'content_ids_x': 'content_ids'})\n    df_true = df_true.fillna('')\n    return df_true","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:09:09.880516Z","iopub.execute_input":"2023-02-03T11:09:09.881375Z","iopub.status.idle":"2023-02-03T11:09:09.896313Z","shell.execute_reply.started":"2023-02-03T11:09:09.881333Z","shell.execute_reply":"2023-02-03T11:09:09.895269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup Features and Target Functions","metadata":{}},{"cell_type":"markdown","source":"* Set X_train, X_test, y_train, y_test: split by category (use 'aligned' for validation); set has_content = True for validation. Check dimensions\n* Use all features for X, including topic_id and content_id, topic_title and content_title\n* Use the KNN predictions to \"mount\" X and y. Check dimensions.\n* Use correlations to get y: if KNN topic-content match with correlations, y is 1, else is 0\n* Use LGBMClassifier for multiclass classification","metadata":{}},{"cell_type":"code","source":"def get_target(preds):\n    \"\"\"\n    Get a binary target from comparing similarity predictions y_preds with ground truth 'y' from 'df_corr'\n    \"\"\"\n    preds_aux = preds.copy()\n    df_num_rows = 400\n    y_int=[]\n    for i in range(len(preds_aux)//df_num_rows):\n        print (f'\\nCalculating preds: {i+1} of {len(preds_aux)//df_num_rows} iterations...\\n')\n        max_r = df_num_rows*(i+1)\n        if max_r > len(preds_aux):\n            max_r = len(preds_aux)\n        min_r = df_num_rows*i\n        df_aux = preds_aux.iloc[min_r:max_r]\n        df_aux.iloc[:,1] = df_aux.content_ids.str.split(' ')\n        df_aux = df_aux.explode('content_ids')\n        df_aux = df_aux.merge (y, on='topic_id', how='left')\n        df_aux['match'] = (df_aux.iloc[:,1] == df_aux.iloc[:,2]).astype (int) \n        y_int.append (df_aux.groupby(['topic_id', 'content_ids_x']).sum().reset_index())\n        target = pd.concat(y_int)\n        target.to_csv('target.csv', index=False)\n\n    return target","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:09:09.897973Z","iopub.execute_input":"2023-02-03T11:09:09.904147Z","iopub.status.idle":"2023-02-03T11:09:09.921191Z","shell.execute_reply.started":"2023-02-03T11:09:09.904106Z","shell.execute_reply":"2023-02-03T11:09:09.920236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_features (y_aux, topics_features, content_features):\n    \"\"\" \n    Get features for classification. Using topic_id, topic_title, content_id and content_title, \n    among remaining class features. Returns Xcolumns=X. and y_target.\n    \"\"\"\n    print (\"\\n* Defining features for X...\\n\")\n\n    df_num_rows = 100000\n    list_X=[]\n    iterations = len(y_aux)//df_num_rows\n    if iterations == 0:\n        iterations = 1\n    for i in range(iterations):\n        print (f'\\nCalculating features: {i+1} of {iterations} iterations...\\n')\n        max_r = df_num_rows*(i+1)\n        if max_r > len(y_aux):\n            max_r = len(y_aux)\n        min_r = df_num_rows*i\n        X = y_aux[min_r:max_r]\n        topic_feat = topics_features.reset_index()\n        # Merging 'topic_features', 'content_features' and 'matching_preds' altogether. \n        # Cleaning unnecessary columns from merges  \n        X = X.merge (topic_feat, how='left', left_on=X.columns[0], right_on=topic_feat.columns[0])\n        X['topic_title'] = X.sentences.str.split('.').str[0]\n        X.drop(columns=X.iloc[:,[3,-2,-3]].columns.tolist(), inplace=True)\n        content_aux = contents_features.reset_index().drop(columns=contents_features.iloc[:,1].name) \n        X = X.merge (content_aux, how='left', left_on=X.iloc[:,1].name, right_on=contents_features.reset_index().iloc[:,0].name)\n        X['content_title'] = X.iloc[:,-1].str.split('.').str[0]\n        X.drop(columns=X.iloc[:,[2, 7, 9]].columns.tolist(), inplace=True)\n        X.columns = X.columns.str.replace('_x', '')\n        X = X.sort_values('language')\n        print (\"\\nPartial X defined.\")\n        # Appending partial dataframe to list\n        list_X.append(X)\n    X = pd.concat (list_X)\n    print (\"\\nX is defined.\")\n    return X","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:09:09.923159Z","iopub.execute_input":"2023-02-03T11:09:09.927719Z","iopub.status.idle":"2023-02-03T11:09:09.957784Z","shell.execute_reply.started":"2023-02-03T11:09:09.927672Z","shell.execute_reply":"2023-02-03T11:09:09.956416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Parameters","metadata":{}},{"cell_type":"code","source":"#General\ndevice = 'cpu'\nif torch.cuda.is_available():\n    device = torch.device('cuda:0')\n#Sentence Transformer\nall_mini = 'all-MiniLM-L6-v2'\nparaphrase = '/kaggle/input/sentence-embedding-models/paraphrase-MiniLM-L12-v2'\ntrained_model = model_path\n# Similarity\ncontent_per_topic = 100\nprint (f\"\\nLoaded models parameters\")","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:09:22.319217Z","iopub.execute_input":"2023-02-03T11:09:22.319615Z","iopub.status.idle":"2023-02-03T11:09:22.326402Z","shell.execute_reply.started":"2023-02-03T11:09:22.319567Z","shell.execute_reply":"2023-02-03T11:09:22.324969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Getting topics breadcrumbs or topics context\nprint (\"\\n* Getting 'topics_breadcrumbs' dataframe...\\n\")\ndf_topic_breadcrumbs = get_topic_breadcrumbs (df_topics)\n\n#Cleaning data and getting topics and contents features\nprint ('\\n* Calculating topics_features dataframe...\\n')\ntopics_features = build_topic_features (df_topics, df_topic_breadcrumbs, levels, topics_cols)\n\nprint ('\\n* Calculating content_features dataframe...\\n')\ncontents_features = build_content_features (df_content, content_cols)","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:09:22.328135Z","iopub.execute_input":"2023-02-03T11:09:22.328766Z","iopub.status.idle":"2023-02-03T11:11:01.638931Z","shell.execute_reply.started":"2023-02-03T11:09:22.328726Z","shell.execute_reply":"2023-02-03T11:11:01.637785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_topic_breadcrumbs","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:11:01.649064Z","iopub.execute_input":"2023-02-03T11:11:01.649371Z","iopub.status.idle":"2023-02-03T11:11:01.703015Z","shell.execute_reply.started":"2023-02-03T11:11:01.649342Z","shell.execute_reply":"2023-02-03T11:11:01.701069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"use_saved_embeds = False\nif use_saved_embeds:\n    #Loading previously saved embeddings\n    print ('\\n* Loading embeddings for both topics and contents...\\n')\n    topic_load_path = dataset_path / 'topic_embeds.npy'\n    with open(topic_load_path, \"rb\") as f:\n        topics_embeds = np.load(f)\n    content_load_path = dataset_path / 'content_embeds.npy'\n    with open(content_load_path, \"rb\") as f:\n        contents_embeds = np.load(f)\n    print ('\\n Embeddings loaded.\\n')\n    topic_id_embeds = df_topics.index.tolist()\n    content_ids_embeds = df_content.index.tolist()     \n\nelse:\n    #Calculating embeddings from text\n    print ('\\n* Calculating embeddings for both topics and contents text columns...\\n')\n    topics_embeds, contents_embeds, topic_id_embeds, content_ids_embeds = get_embeddings(topics_features, contents_features)\n\n    #Saving embeddings\n    topic_save_path = work_path / 'topic_embeds.npy'\n    with open(topic_save_path, \"wb\") as f:\n        np.save(f, topics_embeds)\n    print(f\"Embeddings saved to {topic_save_path}\")\n    contents_save_path = work_path / 'content_embeds.npy'\n    with open(contents_save_path, \"wb\") as f:\n        np.save(f, contents_embeds)\n    print(f\"Embeddings saved to {contents_save_path}\")","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:11:01.704642Z","iopub.execute_input":"2023-02-03T11:11:01.705131Z","iopub.status.idle":"2023-02-03T11:25:12.285551Z","shell.execute_reply.started":"2023-02-03T11:11:01.705072Z","shell.execute_reply":"2023-02-03T11:25:12.28443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Getting topics-contents from sentence similarity","metadata":{}},{"cell_type":"code","source":"#Calculating similar pairs by cosine_similarity function from sentence transformers\nprint('\\n * Calculating sentence similarity predictions...\\n\\n')\npreds = similarity_matches (topic_id_embeds, content_ids_embeds, contents_embeds, topics_embeds, device, content_per_topic)\nprint('\\n First predictions dataframe\\n\\n')\ndisplay(preds)\npreds.to_csv('cos_sim_predictions.csv')","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:25:12.29393Z","iopub.execute_input":"2023-02-03T11:25:12.294406Z","iopub.status.idle":"2023-02-03T11:25:42.687891Z","shell.execute_reply.started":"2023-02-03T11:25:12.294375Z","shell.execute_reply":"2023-02-03T11:25:42.686439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Calculating score for ","metadata":{}},{"cell_type":"code","source":"print('\\n Calculating F2 score for first predictions...\\n\\n')\n\n# Getting 'df_preds' with some precautions as 'preds' shape can explode to \n# number of topics x number of similarities (200) getting easily in millions of lines\n# Since we are concatenating all contents per topic in one row for score calculation\n# the dataframe 'df_preds' gets again only the number of topics as size.\ndf_num_rows = 2500000\nlist_preds=[]\niterations = len(preds)//df_num_rows\nif iterations == 0:\n    iterations = 1\nfor i in range(iterations):\n    print (f'\\nCalculating y_target: {i+1} of {iterations} iterations...\\n')\n    max_r = df_num_rows*(i+1)\n    if max_r > len(preds):\n        max_r = len(preds)\n    min_r = df_num_rows*i \n    df_preds_aux = preds.copy()[min_r:max_r]\n    df_preds_aux = df_preds_aux.iloc[:, [0,1]]\n    df_preds_aux = df_preds_aux.set_index('topic_id').groupby(level=0).agg(lambda x: ' '.join(x)).reset_index()\n    list_preds.append (df_preds_aux)\ndf_preds=pd.concat (list_preds)\ndisplay(df_preds)\n\n# Calculating fscore and validating topics-contents matches from df_preds (first predictions) with \n# df_corr (correlations.csv)\n# Results: a dataframe with scoring; a list with true positive predicted matches\nfscore, _ = calculate_Fscore(df_preds.copy(), df_corr.copy().reset_index())\n#Showing scoring results\nprint ('\\nTopics to match content:', len(df_preds))\nprint ('\\nCorrect predictions:', fscore.correct_pred.sum())\nprint ('\\nF2 Score:', fscore.f2.mean())\nprint ('\\n')\n    \nprint ('\\n*** Score dataframe for similarity matches only ***\\n')\ndisplay(fscore)\n    \nprint ('\\n*** First predictions with sentences similarity ***\\n')\ndisplay(preds)","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:25:42.708696Z","iopub.execute_input":"2023-02-03T11:25:42.70906Z","iopub.status.idle":"2023-02-03T11:25:47.190442Z","shell.execute_reply.started":"2023-02-03T11:25:42.709025Z","shell.execute_reply":"2023-02-03T11:25:47.189367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup Features and Target","metadata":{}},{"cell_type":"code","source":"print ('\\n* Calculating datasets X and y_target...\\n\\n')\n\nX_test = get_features (preds, topics_features, contents_features)\nprint ('\\nDisplaying datasets:\\n\\n')\ndisplay (X_test.head())\nprint (f'X_test shape{X_test.shape}')","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:25:47.192014Z","iopub.execute_input":"2023-02-03T11:25:47.192628Z","iopub.status.idle":"2023-02-03T11:25:59.923985Z","shell.execute_reply.started":"2023-02-03T11:25:47.192588Z","shell.execute_reply":"2023-02-03T11:25:59.920712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save out features and target\nDATA_PATH = Path.cwd().parent.resolve()\nwork_path = DATA_PATH / 'working'\n\nx_test_pth = work_path / \"x_test.csv\"\nx_test_pth.parent.mkdir(exist_ok=True, parents=True)\n\nX_test.to_csv (x_test_pth, index=False)\nprint (f\"\\nFeatures set saved in file at {x_test_pth}.\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:25:59.928316Z","iopub.execute_input":"2023-02-03T11:25:59.929055Z","iopub.status.idle":"2023-02-03T11:26:03.653638Z","shell.execute_reply.started":"2023-02-03T11:25:59.929011Z","shell.execute_reply":"2023-02-03T11:26:03.652594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using LGBMClassifier","metadata":{}},{"cell_type":"markdown","source":"As a classifier, the choice is LightGBM's LGBMClassifier.\n\nIt has the advantage of not needing hot-encoding and being 8-times faster than the same OneHotEncoder from sklearn.\n\nBelow, the %%writefile line magic is used to write out a training script. Then ! to run a shell command from the jupyter notebook, and kick off the script. This is due to a [bug](https://github.com/microsoft/LightGBM/issues/4229).\n\nWe'll use the typer package to make our script easy to run in the command line.","metadata":{}},{"cell_type":"markdown","source":"# Validation predictions","metadata":{}},{"cell_type":"code","source":"%%writefile predict_gbm_model.py\nimport lightgbm as lgb\n\nimport joblib\nfrom loguru import logger\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport typer\n\nDATA_PATH = Path.cwd().parent.resolve()\nMODEL_DIR = DATA_PATH / 'input/learningequalityfiles'\nDATA_DIR = DATA_PATH / 'working'\n\ndef main(\n    model_weights_path = MODEL_DIR / \"lgb_classifier.txt\",\n    features_path = DATA_DIR / \"x_test.csv\",\n    preds_save_path = DATA_DIR / \"y_preds.npy\",\n):\n    \"\"\"\n    Generate predictions with a LightGBM model using weights saved at model_weights_path\n    and features saved at features_path. Save out predictions to preds_save_path.\n    \"\"\"\n    # load model weights\n    lgb_model = joblib.load(model_weights_path)\n    logger.info(f\"Loaded model {lgb_model} from {model_weights_path}\")\n\n    # load the features\n    X_val = pd.read_csv (features_path, dtype=\"category\")\n    logger.info(f\"Loaded features of shape {X_val.shape} from {features_path}\")\n\n    # generate predictions\n    y_preds = lgb_model.predict(X_val)\n\n    # save out predictions\n    with open(preds_save_path, \"wb\") as f:\n        np.save(f, y_preds)\n    logger.success(f\"Predictions saved to {preds_save_path}\")\n\n\nif __name__ == \"__main__\":\n    typer.run(main)","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:26:03.655393Z","iopub.execute_input":"2023-02-03T11:26:03.655764Z","iopub.status.idle":"2023-02-03T11:26:03.663505Z","shell.execute_reply.started":"2023-02-03T11:26:03.655727Z","shell.execute_reply":"2023-02-03T11:26:03.662532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python predict_gbm_model.py","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:26:03.665163Z","iopub.execute_input":"2023-02-03T11:26:03.665871Z","iopub.status.idle":"2023-02-03T11:27:31.344184Z","shell.execute_reply.started":"2023-02-03T11:26:03.66583Z","shell.execute_reply":"2023-02-03T11:27:31.342849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Scoring","metadata":{}},{"cell_type":"code","source":"preds_pth = work_path / \"y_preds.npy\"\nwith open(preds_pth, \"rb\") as f:\n    y_preds = np.load(f).astype(int)\ndisplay(y_preds)","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:27:31.346462Z","iopub.execute_input":"2023-02-03T11:27:31.346776Z","iopub.status.idle":"2023-02-03T11:27:31.365773Z","shell.execute_reply.started":"2023-02-03T11:27:31.346745Z","shell.execute_reply":"2023-02-03T11:27:31.36471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_y_preds = X_test[y_preds.astype(bool)].iloc[:, [0,1]]\ny_final_preds=df_y_preds.set_index('topic_id').groupby(level=0).agg(lambda x: ' '.join(x)).reset_index()\nprint (\"\\n This is the current model prediction for the input given:\\n\\n\")\nprint (y_preds)\nprint (y_final_preds)","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:27:31.367865Z","iopub.execute_input":"2023-02-03T11:27:31.36827Z","iopub.status.idle":"2023-02-03T11:27:31.833714Z","shell.execute_reply.started":"2023-02-03T11:27:31.368231Z","shell.execute_reply":"2023-02-03T11:27:31.832577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submissions","metadata":{}},{"cell_type":"code","source":"#import pickle\n#pickle.dump(model, open(f'ST-KNN-{k[1]}', 'wb'))\ny_final_preds.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:27:31.835572Z","iopub.execute_input":"2023-02-03T11:27:31.836036Z","iopub.status.idle":"2023-02-03T11:27:31.948977Z","shell.execute_reply.started":"2023-02-03T11:27:31.835998Z","shell.execute_reply":"2023-02-03T11:27:31.94794Z"},"trusted":true},"execution_count":null,"outputs":[]}]}