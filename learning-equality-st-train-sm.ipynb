{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Kaggle Challenge - Learning Equality","metadata":{"id":"88080462"}},{"cell_type":"markdown","source":"https://www.kaggle.com/competitions/learning-equality-curriculum-recommendations/overview\n\n## Goal of the Competition\n\nThe goal of this competition is to streamline the process of matching educational content to specific topics in a curriculum. You will develop an accurate and efficient model trained on a library of K-12 educational materials that have been organized into a variety of topic taxonomies. These materials are in diverse languages, and cover a wide range of topics, particularly in STEM (Science, Technology, Engineering, and Mathematics).\n\nYour work will enable students and educators to more readily access relevant educational content to support and supplement learning.","metadata":{"id":"e44162a6"}},{"cell_type":"markdown","source":"## Submission File\n\nFor each **topic_id** in the test set, you must predict a space-delimited list of recommended **content_ids** for that topic. The file should contain a header and have the following format:\n\n~~~\ntopic_id,content_ids\nt_00004da3a1b2,c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c_76231f9d0b5e\nt_00068291e9a4,c_639ea2ef9c95 c_89ce9367be10 c_ac1672cdcd2c c_ebb7fdf10a7e\nt_00069b63a70a,c_11a1dc0bfb99\n...\n~~~","metadata":{"id":"d827eb0b"}},{"cell_type":"markdown","source":"## Scoring\nMean F2 score","metadata":{"id":"de5f7ef4"}},{"cell_type":"markdown","source":"## Evaluation Metric - Efficiency Scoring\nWe compute a submission's efficiency score by:\n\n\\begin{equation} \\text{Efficiency} = \\frac{1}{ \\text{Benchmark} - \\max\\text{F2} }\\text{F2} + \\frac{1}{32400}\\text{RuntimeSeconds} \\end{equation}\n\n\nwhere **F2** is the submission's score on the main competition metric, **Benchmark** is the score of the benchmark sample_submission.csv, **maxF2** is the maximum  of all submissions on the Private Leaderboard, and **RuntimeSeconds** is the number of seconds it takes for the submission to be evaluated. The objective is to minimize the efficiency score.\n\nDuring the training period of the competition, you may see a leaderboard for the public test data in the following notebook, updated daily: Efficiency Leaderboard. After the competition ends, we will update this leaderboard with efficiency scores on the private data. During the training period, this leaderboard will show only the rank of each team, but not the complete score.","metadata":{"id":"b86e3e62"}},{"cell_type":"markdown","source":"# Data","metadata":{"id":"e2cc9cb4"}},{"cell_type":"markdown","source":"## Imports","metadata":{"id":"eb712db6"}},{"cell_type":"code","source":"!pip install -U sentence-transformers","metadata":{"id":"2eBKbVKiQm-Z","execution":{"iopub.status.busy":"2023-01-20T11:00:17.085257Z","iopub.execute_input":"2023-01-20T11:00:17.085727Z","iopub.status.idle":"2023-01-20T11:00:31.661676Z","shell.execute_reply.started":"2023-01-20T11:00:17.085631Z","shell.execute_reply":"2023-01-20T11:00:31.660539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport string\nfrom sentence_transformers import SentenceTransformer, util","metadata":{"id":"b5f3a3b6","execution":{"iopub.status.busy":"2023-01-20T11:00:31.665016Z","iopub.execute_input":"2023-01-20T11:00:31.666125Z","iopub.status.idle":"2023-01-20T11:00:35.177501Z","shell.execute_reply.started":"2023-01-20T11:00:31.666061Z","shell.execute_reply":"2023-01-20T11:00:35.176439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"markdown","source":"# Data Collection","metadata":{"id":"e55f4587"}},{"cell_type":"markdown","source":"## Load dataframes","metadata":{"id":"FJLGLdJ-wKZI"}},{"cell_type":"code","source":"#drive_path = '/content/drive/My Drive/Colab Notebooks/learning_equality/'\ndrive_path = '/kaggle/input/learning-equality-curriculum-recommendations/'\ndataset_path = '/kaggle/input/learning-equality-files/'\nwork_path = '/kaggle/working/'\nmodel_path = '/kaggle/input/learning-equality-files/ST-all-MiniLM-L6-v2-trained'\n\n# load 'topics' data into pandas dataframe\ndf_topics = pd.read_csv(f'{drive_path}topics.csv', index_col=0).fillna({\"title\": \"\", \"description\": \"\"})\nprint (\"\\nLoaded 'df_topics'\")","metadata":{"id":"debc1002","outputId":"6ac0efe1-3179-41ba-f8c1-bc3c77928517","execution":{"iopub.status.busy":"2023-01-20T11:00:35.197277Z","iopub.execute_input":"2023-01-20T11:00:35.198266Z","iopub.status.idle":"2023-01-20T11:00:35.716172Z","shell.execute_reply.started":"2023-01-20T11:00:35.198221Z","shell.execute_reply":"2023-01-20T11:00:35.715062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load 'content' data into pandas dataframe\ndf_content = pd.read_csv(f'{drive_path}content.csv', index_col=0).fillna(\"\")\nprint (\"\\nLoaded 'df_content'\")","metadata":{"id":"f29e0027","outputId":"7a7843d3-0ba6-4d0f-b57a-b94df23137c1","execution":{"iopub.status.busy":"2023-01-20T11:00:35.717510Z","iopub.execute_input":"2023-01-20T11:00:35.718198Z","iopub.status.idle":"2023-01-20T11:00:56.270240Z","shell.execute_reply.started":"2023-01-20T11:00:35.718158Z","shell.execute_reply":"2023-01-20T11:00:56.269161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load 'correlations' data into pandas dataframe\ndf_corr = pd.read_csv(f'{drive_path}correlations.csv', index_col=0)\nprint (\"\\nLoaded 'df_corr'\")","metadata":{"id":"29667ed7","outputId":"8f3c7bd9-ebd8-4729-a901-ba908e7739fb","execution":{"iopub.status.busy":"2023-01-20T11:00:56.271595Z","iopub.execute_input":"2023-01-20T11:00:56.273384Z","iopub.status.idle":"2023-01-20T11:00:56.438122Z","shell.execute_reply.started":"2023-01-20T11:00:56.273330Z","shell.execute_reply":"2023-01-20T11:00:56.437018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load 'topic_breadcrumbs' data into pandas dataframe\ndf_topic_breadcrumbs = pd.read_csv(f'{dataset_path}topic_breadcrumbs.csv', index_col=0)\nprint (\"\\nLoaded 'df_topic_breadcrumbs'\")","metadata":{"outputId":"7681b90b-c5fe-425a-8588-a482bca3a5ae","id":"uHXeHxwfQ4qX","execution":{"iopub.status.busy":"2023-01-20T11:00:56.439809Z","iopub.execute_input":"2023-01-20T11:00:56.440223Z","iopub.status.idle":"2023-01-20T11:00:56.772029Z","shell.execute_reply.started":"2023-01-20T11:00:56.440183Z","shell.execute_reply":"2023-01-20T11:00:56.770911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Restructure 'df_corr' (correlations): explode the target column to be more practical to use - one topic -> one content\ny = df_corr.copy()\ny['content_ids'] = y.content_ids.str.split(' ')\ny = y.explode('content_ids')\ny.reset_index(inplace=True)\nprint (\"\\nCreated expanded 'y'\")","metadata":{"id":"281bbca0","outputId":"c6521999-01f3-4b8b-feb8-0d592e652740","execution":{"iopub.status.busy":"2023-01-20T11:00:56.773637Z","iopub.execute_input":"2023-01-20T11:00:56.774014Z","iopub.status.idle":"2023-01-20T11:00:56.912176Z","shell.execute_reply.started":"2023-01-20T11:00:56.773977Z","shell.execute_reply":"2023-01-20T11:00:56.911159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Cleaning","metadata":{"id":"CP4lmcnV20yH"}},{"cell_type":"markdown","source":"## Data cleaning params","metadata":{"id":"rjw9Pdqqlzdp"}},{"cell_type":"code","source":"topic_cols = ['title_x', 'description_x', 'topic_breadcrumbs']\ncontent_cols = ['title_y', 'description_y', 'kind', 'text']\ncat_for_val = 'aligned'\nprint (\"\\nLoaded parameters to clean data\")","metadata":{"id":"qpgsrMQyl10Y","execution":{"iopub.status.busy":"2023-01-20T11:00:56.924051Z","iopub.execute_input":"2023-01-20T11:00:56.924385Z","iopub.status.idle":"2023-01-20T11:00:56.955677Z","shell.execute_reply.started":"2023-01-20T11:00:56.924358Z","shell.execute_reply":"2023-01-20T11:00:56.954758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data cleaning functions","metadata":{"id":"Hwk6JtmRbn42"}},{"cell_type":"code","source":"# Clean up text\ndef clean_text(text_col):\n    \"\"\"\n    Clean ponctuation and special chars from a dataframe column\n    \"\"\"\n    punctuations = string.punctuation\n    text_col = text_col.str.replace('\\W', ' ', regex=True)\n    for punct in string.punctuation:\n        text_col = text_col.str.replace(punct, ' ', regex=True)\n    return text_col","metadata":{"id":"xRgKUBVjbstB","execution":{"iopub.status.busy":"2023-01-20T11:00:56.957191Z","iopub.execute_input":"2023-01-20T11:00:56.957524Z","iopub.status.idle":"2023-01-20T11:00:56.963922Z","shell.execute_reply.started":"2023-01-20T11:00:56.957492Z","shell.execute_reply":"2023-01-20T11:00:56.962862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Features\n\n*   Filter by category (do not use 'aligned', use only for validation)\n*   Clean strings: ponctuation and special chars (\\n\\t...)\n*   Merge columns in 'df_topics' from 'topic_cols' into 1 sentence (Sentence1)\n*   Merge columns in 'df_content' from 'topic_cols' into 1 sentence (Sentence1)\n*   Merge both datasets using y (correlations.csv)\n\nBy merging both sentences column using correlations, we get a pair of similar sentences with size of y","metadata":{"id":"WmkMQLZHaDmd"}},{"cell_type":"code","source":"# Merge 'df_topics' with 'topics_breadcrumbs' and 'df_content'\nprint (\"\\nMerging dataframes 'df_topics', 'df_contents' and 'y'...\")\nfeatures = df_topics.copy()[df_topics.category != cat_for_val].reset_index().rename(columns={'id': 'topic_id'})\nfeatures = y.merge (features, how='left', left_on='topic_id', right_on='topic_id')\nfeatures = features.merge (df_content, how='left', left_on='content_ids', right_on='id')\nfeatures = features.merge (df_topic_breadcrumbs.reset_index(), how='left', left_on='topic_id', right_on='index')\n#Cleaning tasks\nprint (\"\\nCleaning data...\")\nfor col in topic_cols:\n    features[col] = clean_text(features[col])\nfor col in content_cols:\n    features[col] = clean_text(features[col])\n#Create 'sentence1' column\nprint (\"\\nCreating sentences from 'df_topics'...\")\nfeatures['sentence1'] = features[topic_cols].apply(lambda x: '.'.join(x.dropna().astype(str)), axis=1)\n#Create 'sentence2' column\nprint (\"\\nCreating sentences from 'df_contents'...\")\nfeatures['sentence2'] = features[content_cols].apply(lambda x: '.'.join(x.dropna().astype(str)), axis=1)\n#Clean unnecessary columns\nfeatures = features[['sentence1', 'sentence2']]\nprint (\"\\nCreated 'features' to train model\")","metadata":{"id":"prh6uaPXlyMr","execution":{"iopub.status.busy":"2023-01-20T11:00:56.965598Z","iopub.execute_input":"2023-01-20T11:00:56.966031Z","iopub.status.idle":"2023-01-20T11:04:47.237969Z","shell.execute_reply.started":"2023-01-20T11:00:56.965992Z","shell.execute_reply":"2023-01-20T11:04:47.236939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"id":"0866f1f5"}},{"cell_type":"markdown","source":"## Model params","metadata":{"id":"iI-1sqraZhLv"}},{"cell_type":"code","source":"backbone = 'all-MiniLM-L6-v2' #explore also msmarco models and multilanguage\ndataset_limit = 10\nbatch_size = 64\nshuffle = True\nnum_epochs = 2\nwarmup_steps = int(len(features) * num_epochs * 0.2)\nwarmup_steps\nprint (\"\\nLoaded model training parameters...\")","metadata":{"id":"HJou8xoM4H2A","execution":{"iopub.status.busy":"2023-01-20T11:08:59.236928Z","iopub.execute_input":"2023-01-20T11:08:59.237606Z","iopub.status.idle":"2023-01-20T11:08:59.243670Z","shell.execute_reply.started":"2023-01-20T11:08:59.237568Z","shell.execute_reply":"2023-01-20T11:08:59.242578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sentence Transformer train\n\n- Using 'all-MiniLM-L6-v2' as from discussions it seems to be best model, but may use other models\n- Using pair of sentences and label\n- Sentence1: topic_title + topic_description' + topic_breadcrumbs\n- Sentence2: content title + content description + kind + content text\n- Target: correlations. 1 if it's a match, 0 if there's no match","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import InputExample, losses\nfrom torch.utils.data import DataLoader\n\nprint (f\"\\nLoading model {backbone}...\")\nmodel = SentenceTransformer(backbone)\ntrain_sentences = []\nX_train = features\nmatches = len(X_train)\n\nprint (\"Converting 'features' to proper format...\")\nfor i in range(matches):\n    train_sentences.append(InputExample(texts=[X_train.iloc[i, 0], X_train.iloc[i, 1]]))\n\ntrain_dataloader = DataLoader(train_sentences, shuffle=shuffle, batch_size=batch_size)\n\n#print (\"Setting multi GPU process...\")\n#pool = model.start_multi_process_pool()\n\nprint (\"\\nDefining model loss function...\")\ntrain_loss = losses.MultipleNegativesRankingLoss(model=model)\nprint (f\"\\nAll set to train model\")","metadata":{"execution":{"iopub.status.busy":"2023-01-20T11:09:03.576674Z","iopub.execute_input":"2023-01-20T11:09:03.577058Z","iopub.status.idle":"2023-01-20T11:09:32.825755Z","shell.execute_reply.started":"2023-01-20T11:09:03.577016Z","shell.execute_reply":"2023-01-20T11:09:32.824525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (f\"\\nTraining model with {warmup_steps} sentences and {train_loss}...\")\nmodel.fit(train_objectives=[(train_dataloader, train_loss)],\n          epochs=num_epochs,\n          warmup_steps=warmup_steps) \n\nprint (f\"\\nSaving model ST-{backbone}-trained...\")\nmodel.save (f\"{work_path}/ST-{backbone}-trained'\")\nprint (\"Model saved.\")","metadata":{"execution":{"iopub.status.busy":"2023-01-20T11:14:04.729237Z","iopub.execute_input":"2023-01-20T11:14:04.729631Z","iopub.status.idle":"2023-01-20T11:15:25.602049Z","shell.execute_reply.started":"2023-01-20T11:14:04.729596Z","shell.execute_reply":"2023-01-20T11:15:25.600433Z"},"trusted":true},"execution_count":null,"outputs":[]}]}