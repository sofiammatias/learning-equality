{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Kaggle Challenge - Learning Equality","metadata":{"id":"88080462"}},{"cell_type":"markdown","source":"https://www.kaggle.com/competitions/learning-equality-curriculum-recommendations/overview\n\n## Goal of the Competition\n\nThe goal of this competition is to streamline the process of matching educational content to specific topics in a curriculum. You will develop an accurate and efficient model trained on a library of K-12 educational materials that have been organized into a variety of topic taxonomies. These materials are in diverse languages, and cover a wide range of topics, particularly in STEM (Science, Technology, Engineering, and Mathematics).\n\nYour work will enable students and educators to more readily access relevant educational content to support and supplement learning.","metadata":{"id":"e44162a6"}},{"cell_type":"markdown","source":"## Submission File\n\nFor each **topic_id** in the test set, you must predict a space-delimited list of recommended **content_ids** for that topic. The file should contain a header and have the following format:\n\n~~~\ntopic_id,content_ids\nt_00004da3a1b2,c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c_76231f9d0b5e\nt_00068291e9a4,c_639ea2ef9c95 c_89ce9367be10 c_ac1672cdcd2c c_ebb7fdf10a7e\nt_00069b63a70a,c_11a1dc0bfb99\n...\n~~~","metadata":{"id":"d827eb0b"}},{"cell_type":"markdown","source":"## Scoring\nMean F2 score","metadata":{"id":"de5f7ef4"}},{"cell_type":"markdown","source":"## Evaluation Metric - Efficiency Scoring\nWe compute a submission's efficiency score by:\n\n\\begin{equation} \\text{Efficiency} = \\frac{1}{ \\text{Benchmark} - \\max\\text{F2} }\\text{F2} + \\frac{1}{32400}\\text{RuntimeSeconds} \\end{equation}\n\n\nwhere **F2** is the submission's score on the main competition metric, **Benchmark** is the score of the benchmark sample_submission.csv, **maxF2** is the maximum  of all submissions on the Private Leaderboard, and **RuntimeSeconds** is the number of seconds it takes for the submission to be evaluated. The objective is to minimize the efficiency score.\n\nDuring the training period of the competition, you may see a leaderboard for the public test data in the following notebook, updated daily: Efficiency Leaderboard. After the competition ends, we will update this leaderboard with efficiency scores on the private data. During the training period, this leaderboard will show only the rank of each team, but not the complete score.","metadata":{"id":"b86e3e62"}},{"cell_type":"markdown","source":"# Data","metadata":{"id":"e2cc9cb4"}},{"cell_type":"markdown","source":"## Imports","metadata":{"id":"eb712db6"}},{"cell_type":"code","source":"!pip install -U sentence-transformers","metadata":{"id":"2eBKbVKiQm-Z","execution":{"iopub.status.busy":"2023-01-20T17:17:24.054277Z","iopub.execute_input":"2023-01-20T17:17:24.055145Z","iopub.status.idle":"2023-01-20T17:17:38.609786Z","shell.execute_reply.started":"2023-01-20T17:17:24.055050Z","shell.execute_reply":"2023-01-20T17:17:38.608647Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting sentence-transformers\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m630.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.20.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.64.0)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.11.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.12.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.21.6)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.0.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.7.3)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (3.8.1)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.1.97)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.10.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (22.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.1.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.7.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.13.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.11.10)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.12.1)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers) (1.0.1)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers) (8.1.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence-transformers) (3.1.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->sentence-transformers) (9.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers) (3.8.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.13)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3)\nBuilding wheels for collected packages: sentence-transformers\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=ec9ab997e1a48bae299b3bd81b91612ed880c7b6d71a5206dcf79a8bc9abb393\n  Stored in directory: /root/.cache/pip/wheels/bf/06/fb/d59c1e5bd1dac7f6cf61ec0036cc3a10ab8fecaa6b2c3d3ee9\nSuccessfully built sentence-transformers\nInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-2.2.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport string\nfrom sentence_transformers import SentenceTransformer, util\nfrom sklearn.metrics import fbeta_score, precision_score, recall_score, make_scorer\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV","metadata":{"id":"b5f3a3b6","execution":{"iopub.status.busy":"2023-01-20T11:00:31.665016Z","iopub.execute_input":"2023-01-20T11:00:31.666125Z","iopub.status.idle":"2023-01-20T11:00:35.177501Z","shell.execute_reply.started":"2023-01-20T11:00:31.666061Z","shell.execute_reply":"2023-01-20T11:00:35.176439Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"markdown","source":"# Data Collection","metadata":{"id":"e55f4587"}},{"cell_type":"markdown","source":"## Helper functions and classes for data traversal (breadcrumbs = topic context)","metadata":{"id":"PGb4tvZm26GS"}},{"cell_type":"code","source":"# define some helper functions and classes to aid with data traversal\n\nclass ContentItem:\n    \"\"\"\n    Class to handle content relations (breadcrumbs)\n    \"\"\"\n    def __init__(self, content_id):\n        self.id = content_id\n\n    @property\n    def topics(self):\n        return [Topic(topic_id) for topic_id in df_topics.loc[df_corr[df_corr.content_ids.str.contains(self.id)].index].index]\n\n    def get_all_breadcrumbs(self, separator=\" >> \", include_root=True):\n        breadcrumbs = []\n        title = self.title\n        for topic in self.topics:\n            new_breadcrumb = topic.get_breadcrumbs(separator=separator, include_root=include_root)\n            if new_breadcrumb:\n                new_breadcrumb = new_breadcrumb + separator + title\n            else:\n                new_breadcrumb = title\n            breadcrumbs.append(new_breadcrumb)\n        return breadcrumbs\n\nclass Topic:\n    \"\"\"\n    Class to handle topics relations (breadcrumbs)\n    \"\"\"\n    def __init__(self, topic_id):\n        self.id = topic_id\n\n    @property\n    def parent(self):\n        parent_id = df_topics.loc[self.id].parent\n        if pd.isna(parent_id):\n            return None\n        else:\n            return Topic(parent_id)\n\n    @property\n    def ancestors(self):\n        ancestors = []\n        parent = self.parent\n        while parent is not None:\n            ancestors.append(parent)\n            parent = parent.parent\n        return ancestors\n\n    @property\n    def content(self):\n        if self.id in df_corr.index:\n            return [ContentItem(content_id) for content_id in df_corr.loc[self.id].content_ids.split()]\n        else:\n            return tuple([]) if self.has_content else []\n\n    def get_breadcrumbs(self, separator=\" >> \", include_self=True, include_root=True):\n        ancestors = self.ancestors\n        if include_self:\n            ancestors = [self] + ancestors\n        if not include_root:\n            ancestors = ancestors[:-1]\n        return separator.join(reversed([a.title for a in ancestors]))","metadata":{"id":"D3_paOBLo_pV","execution":{"iopub.status.busy":"2023-01-20T11:00:35.181031Z","iopub.execute_input":"2023-01-20T11:00:35.181655Z","iopub.status.idle":"2023-01-20T11:00:35.194124Z","shell.execute_reply.started":"2023-01-20T11:00:35.181625Z","shell.execute_reply":"2023-01-20T11:00:35.193003Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Load dataframes","metadata":{"id":"FJLGLdJ-wKZI"}},{"cell_type":"code","source":"#drive_path = '/content/drive/My Drive/Colab Notebooks/learning_equality/'\ndrive_path = '/kaggle/input/learning-equality-curriculum-recommendations/'\ndataset_path = '/kaggle/input/learning-equality-files/'\nwork_path = '/kaggle/working/'\n\n# load 'topics' data into pandas dataframe\ndf_topics = pd.read_csv(f'{drive_path}topics.csv', index_col=0).fillna({\"title\": \"\", \"description\": \"\"})\nprint (\"\\nLoaded 'df_topics'\")","metadata":{"id":"debc1002","outputId":"6ac0efe1-3179-41ba-f8c1-bc3c77928517","execution":{"iopub.status.busy":"2023-01-20T11:00:35.197277Z","iopub.execute_input":"2023-01-20T11:00:35.198266Z","iopub.status.idle":"2023-01-20T11:00:35.716172Z","shell.execute_reply.started":"2023-01-20T11:00:35.198221Z","shell.execute_reply":"2023-01-20T11:00:35.715062Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\nLoaded 'df_topics'\n","output_type":"stream"}]},{"cell_type":"code","source":"# load 'content' data into pandas dataframe\ndf_content = pd.read_csv(f'{drive_path}content.csv', index_col=0).fillna(\"\")\nprint (\"\\nLoaded 'df_content'\")","metadata":{"id":"f29e0027","outputId":"7a7843d3-0ba6-4d0f-b57a-b94df23137c1","execution":{"iopub.status.busy":"2023-01-20T11:00:35.717510Z","iopub.execute_input":"2023-01-20T11:00:35.718198Z","iopub.status.idle":"2023-01-20T11:00:56.270240Z","shell.execute_reply.started":"2023-01-20T11:00:35.718158Z","shell.execute_reply":"2023-01-20T11:00:56.269161Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"\nLoaded 'df_content'\n","output_type":"stream"}]},{"cell_type":"code","source":"# load 'correlations' data into pandas dataframe\ndf_corr = pd.read_csv(f'{drive_path}correlations.csv', index_col=0)\nprint (\"\\nLoaded 'df_corr'\")","metadata":{"id":"29667ed7","outputId":"8f3c7bd9-ebd8-4729-a901-ba908e7739fb","execution":{"iopub.status.busy":"2023-01-20T11:00:56.271595Z","iopub.execute_input":"2023-01-20T11:00:56.273384Z","iopub.status.idle":"2023-01-20T11:00:56.438122Z","shell.execute_reply.started":"2023-01-20T11:00:56.273330Z","shell.execute_reply":"2023-01-20T11:00:56.437018Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"\nLoaded 'df_corr'\n","output_type":"stream"}]},{"cell_type":"code","source":"# load 'topic_breadcrumbs' data into pandas dataframe\ndf_topic_breadcrumbs = pd.read_csv(f'{dataset_path}topic_breadcrumbs.csv', index_col=0)\nprint (\"\\nLoaded 'df_topic_breadcrumbs'\")","metadata":{"outputId":"7681b90b-c5fe-425a-8588-a482bca3a5ae","id":"uHXeHxwfQ4qX","execution":{"iopub.status.busy":"2023-01-20T11:00:56.439809Z","iopub.execute_input":"2023-01-20T11:00:56.440223Z","iopub.status.idle":"2023-01-20T11:00:56.772029Z","shell.execute_reply.started":"2023-01-20T11:00:56.440183Z","shell.execute_reply":"2023-01-20T11:00:56.770911Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"\nLoaded 'df_topic_breadcrumbs'\n","output_type":"stream"}]},{"cell_type":"code","source":"# Restructure 'df_corr' (correlations): explode the target column to be more practical to use - one topic -> one content\ny = df_corr.copy()\ny['content_ids'] = y.content_ids.str.split(' ')\ny = y.explode('content_ids')\ny.reset_index(inplace=True)\nprint (\"\\nCreated expanded 'y'\")","metadata":{"id":"281bbca0","outputId":"c6521999-01f3-4b8b-feb8-0d592e652740","execution":{"iopub.status.busy":"2023-01-20T11:00:56.773637Z","iopub.execute_input":"2023-01-20T11:00:56.774014Z","iopub.status.idle":"2023-01-20T11:00:56.912176Z","shell.execute_reply.started":"2023-01-20T11:00:56.773977Z","shell.execute_reply":"2023-01-20T11:00:56.911159Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"\nCreated expanded 'y'\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Create breadcrumbs for topics","metadata":{"id":"UGfLE-eRwTyT"}},{"cell_type":"code","source":"#%%time\n# - Create breadcrumbs for topics and save in csv file\n#  these command lines were spending 1h20m without finishingt:\n#       df_X['topic_id'].apply (lambda topic: Topic(topic).get_breadcrumbs()))\n#       df_X['content_ids'].apply (lambda content: ContentItem(content).get_all_breadcrumbs())\n# with for loop + list append it took 5m for topic\n\n#topic_breadcrumbs=[]\n#topic_ids=[]\n#for i, topic in enumerate(df_topics.reset_index()['id']):\n#    topic_ids.append (topic)\n#    topic_breadcrumbs.append (Topic(topic).get_breadcrumbs(separator=' '))\n#    print (i, ' : ', topic, ' - ', topic_breadcrumbs[-1])\n\n# Save 'topic_breadcrumbs'\n#df_topic_breadcrumbs = pd.DataFrame (topic_breadcrumbs, columns='breadcrumbs', index_col=topic_ids)\n#df_topic_breadcrumbs.to_csv(f'{drive_path}topic_breadcrumbs.csv')","metadata":{"id":"l3cLmldq0R7R","execution":{"iopub.status.busy":"2023-01-20T11:00:56.914161Z","iopub.execute_input":"2023-01-20T11:00:56.914847Z","iopub.status.idle":"2023-01-20T11:00:56.920236Z","shell.execute_reply.started":"2023-01-20T11:00:56.914807Z","shell.execute_reply":"2023-01-20T11:00:56.919116Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Data Cleaning","metadata":{"id":"CP4lmcnV20yH"}},{"cell_type":"markdown","source":"## Data cleaning params","metadata":{"id":"rjw9Pdqqlzdp"}},{"cell_type":"code","source":"levels = {0: 'zero', 1: 'one', 2: 'two', 3: 'three', 4: 'four', 5: 'five', 6: 'six', 7: 'seven', 8: 'eight', 9: 'nine', 10: 'ten'}\nlangs_t = pd.DataFrame (df_topics['language'].unique(), columns=['lang']) \nlangs_c = pd.DataFrame (df_content['language'].unique(), columns=['lang']) \nlangs = langs_t.merge (langs_c, how='left')\n# Output: ['bg', 'en', 'pt', 'gu', 'my', 'zh', 'ar', 'te', 'es', 'fr', 'sw', 'mr', 'hi', 'bn', 'fil', 'ru', 'it', 'or', 'pnb', 'km', 'as', 'kn','ur', 'pl', 'ta', 'swa', 'tr', 'mul']\ntopic_cols = ['title_x', 'description_x', 'topic_breadcrumbs']\ncontent_cols = ['title_y', 'description_y', 'kind', 'text']\ncat_for_val = 'aligned'\nprint (\"\\nLoaded parameters to clean data\")","metadata":{"id":"qpgsrMQyl10Y","execution":{"iopub.status.busy":"2023-01-20T11:00:56.924051Z","iopub.execute_input":"2023-01-20T11:00:56.924385Z","iopub.status.idle":"2023-01-20T11:00:56.955677Z","shell.execute_reply.started":"2023-01-20T11:00:56.924358Z","shell.execute_reply":"2023-01-20T11:00:56.954758Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"\nLoaded parameters to clean data\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Data cleaning functions","metadata":{"id":"Hwk6JtmRbn42"}},{"cell_type":"code","source":"# Filter by language\ndef filter_lang(X, lang):\n    \"\"\"\n    Filter dataframes by 'language'\n    \"\"\"\n    return X[X.language_x == lang].copy()\n\n\n# Clean up text\ndef clean_text(text_col):\n    \"\"\"\n    Clean ponctuation and special chars from a dataframe column\n    \"\"\"\n    punctuations = string.punctuation\n    text_col = text_col.str.replace('\\W', ' ', regex=True)\n    for punct in string.punctuation:\n        text_col = text_col.str.replace(punct, ' ', regex=True)\n    return text_col","metadata":{"id":"xRgKUBVjbstB","execution":{"iopub.status.busy":"2023-01-20T11:00:56.957191Z","iopub.execute_input":"2023-01-20T11:00:56.957524Z","iopub.status.idle":"2023-01-20T11:00:56.963922Z","shell.execute_reply.started":"2023-01-20T11:00:56.957492Z","shell.execute_reply":"2023-01-20T11:00:56.962862Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Features\n\n*   Filter by category (do not use 'aligned', use only for validation)\n*   Clean strings: ponctuation and special chars (\\n\\t...)\n*   Merge columns in 'df_topics' from 'topic_cols' into 1 sentence (Sentence1)\n*   Merge columns in 'df_content' from 'topic_cols' into 1 sentence (Sentence1)\n*   Merge both datasets using y (correlations.csv)\n\nBy merging both sentences column using correlations, we get a pair of similar sentences with size of y","metadata":{"id":"WmkMQLZHaDmd"}},{"cell_type":"code","source":"# Merge 'df_topics' with 'topics_breadcrumbs' and 'df_content'\nprint (\"\\nMerging dataframes 'df_topics', 'df_contents' and 'y'...\")\nfeatures = df_topics.copy()[df_topics.category != cat_for_val].reset_index().rename(columns={'id': 'topic_id'})\nfeatures = y.merge (features, how='left', left_on='topic_id', right_on='topic_id')\nfeatures = features.merge (df_content, how='left', left_on='content_ids', right_on='id')\nfeatures = features.merge (df_topic_breadcrumbs.reset_index(), how='left', left_on='topic_id', right_on='index')\n#Cleaning tasks\nprint (\"\\nCleaning data...\")\nfor col in topic_cols:\n    features[col] = clean_text(features[col])\nfor col in content_cols:\n    features[col] = clean_text(features[col])\n#Create 'sentence1' column\nprint (\"\\nCreating sentences from 'df_topics'...\")\nfeatures['sentence1'] = features[topic_cols].apply(lambda x: '.'.join(x.dropna().astype(str)), axis=1)\n#Create 'sentence2' column\nprint (\"\\nCreating sentences from 'df_contents'...\")\nfeatures['sentence2'] = features[content_cols].apply(lambda x: '.'.join(x.dropna().astype(str)), axis=1)\n#Clean unnecessary columns\nfeatures = features[['sentence1', 'sentence2']]\nprint (\"\\nCreated 'features' to train model\")","metadata":{"id":"prh6uaPXlyMr","execution":{"iopub.status.busy":"2023-01-20T11:00:56.965598Z","iopub.execute_input":"2023-01-20T11:00:56.966031Z","iopub.status.idle":"2023-01-20T11:04:47.237969Z","shell.execute_reply.started":"2023-01-20T11:00:56.965992Z","shell.execute_reply":"2023-01-20T11:04:47.236939Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"\nMerging dataframes 'df_topics', 'df_contents' and 'y'...\n\nCleaning data...\n\nCreating sentences from 'df_topics'...\n\nCreating sentences from 'df_contents'...\n\nCreated 'features' to train model\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model","metadata":{"id":"0866f1f5"}},{"cell_type":"markdown","source":"## Scoring\n\nScoring is based in mean F2 score","metadata":{"id":"mWXqw0LbeCf6"}},{"cell_type":"code","source":"def model_scoring (y_test, y_pred, average='weighted'):\n    \"\"\"\n    Calculate precision, recall and f2-score for y_test and y_pred\n    \"\"\"\n    precision = precision_score(y_test['content_ids'], y_pred['content_id'], average=average)\n    print ('Precision:', Precision)\n    recall = recall_score(y_test['content_ids'], y_pred['content_id'], average=average)\n    print ('Recall:', Recall)\n    F2macro = fbeta_score(y_test['content_ids'], y_pred['content_id'], beta=2, average='macro')\n    print ('F2 macro:', F2macro)\n    F2micro = fbeta_score(y_test['content_ids'], y_pred['content_id'], beta=2, average='micro')\n    print ('F2 micro:', F2micro)\n    return precision, recall, F2macro, F2micro","metadata":{"id":"7cd4d95d","execution":{"iopub.status.busy":"2023-01-20T11:08:55.470674Z","iopub.execute_input":"2023-01-20T11:08:55.471196Z","iopub.status.idle":"2023-01-20T11:08:55.478770Z","shell.execute_reply.started":"2023-01-20T11:08:55.471051Z","shell.execute_reply":"2023-01-20T11:08:55.477673Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Model params","metadata":{"id":"iI-1sqraZhLv"}},{"cell_type":"code","source":"backbone = 'all-MiniLM-L6-v2' #explore also msmarco models and multilanguage\ndataset_limit = 10\nbatch_size = 64\nshuffle = True\nnum_epochs = 2\nwarmup_steps = int(len(features) * num_epochs * 0.2)\nwarmup_steps\nprint (\"\\nLoaded model training parameters...\")","metadata":{"id":"HJou8xoM4H2A","execution":{"iopub.status.busy":"2023-01-20T11:08:59.236928Z","iopub.execute_input":"2023-01-20T11:08:59.237606Z","iopub.status.idle":"2023-01-20T11:08:59.243670Z","shell.execute_reply.started":"2023-01-20T11:08:59.237568Z","shell.execute_reply":"2023-01-20T11:08:59.242578Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"\nLoaded model training parameters...\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Sentence Transformer train\n\n- Using 'all-MiniLM-L6-v2' as from discussions it seems to be best model, but may use other models\n- Using pair of similar sentences\n- Sentence1: topic_title + topic_description' + topic_breadcrumbs\n- Sentence2: content title + content description + kind + content text","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import InputExample, losses\nfrom torch.utils.data import DataLoader\n\nprint (f\"\\nLoading model {backbone}...\")\nmodel = SentenceTransformer(backbone)\ntrain_sentences = []\nX_train = features\nmatches = len(X_train)\n\nprint (\"Converting 'features' to proper format...\")\nfor i in range(matches):\n    train_sentences.append(InputExample(texts=[X_train.iloc[i, 0], X_train.iloc[i, 1]]))\n\ntrain_dataloader = DataLoader(train_sentences, shuffle=shuffle, batch_size=batch_size)\n\n#print (\"Setting multi GPU process...\")\n#pool = model.start_multi_process_pool()\n\nprint (\"\\nDefining model loss function...\")\ntrain_loss = losses.MultipleNegativesRankingLoss(model=model)\nprint (f\"\\nAll set to train model\")","metadata":{"execution":{"iopub.status.busy":"2023-01-20T11:09:03.576674Z","iopub.execute_input":"2023-01-20T11:09:03.577058Z","iopub.status.idle":"2023-01-20T11:09:32.825755Z","shell.execute_reply.started":"2023-01-20T11:09:03.577016Z","shell.execute_reply":"2023-01-20T11:09:32.824525Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"\nLoading model all-MiniLM-L6-v2...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6b01a20f3e642dba97b44ec559b6dcd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57c23ad8331e421d8176d5f5d3c1c2c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/10.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e436f00adfe4b11af490e80eb1ff3a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0437431c701940c9bb3c67659299bb46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf99d1a8eb674b38a6996b4ab32ed376"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/39.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c1a9120fe9a44c4be235e1ea96e5d7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4f18e938dbc4bcda9a6b3270861438c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d5844d1cbae448789f3a1b07339aa91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae29488d1a6a4c318e0d5729d1e2c07c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e18a9419ed541aa85aa21753bbd6862"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"985d115509ec48a18889283b35f9b159"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/13.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aff0b61d078841df80fb3b1305a0a8df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1db30cee0f24c15926192f2e52de592"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"defda0a2e67e418db119bd6fbccd8f37"}},"metadata":{}},{"name":"stdout","text":"Converting 'features' to proper format...\n\nDefining model loss function...\n\nAll set to train model\n","output_type":"stream"}]},{"cell_type":"code","source":"print (f\"\\nTraining model with {warmup_steps} sentences and {train_loss}...\")\nmodel.fit(train_objectives=[(train_dataloader, train_loss)],\n          epochs=num_epochs,\n          warmup_steps=warmup_steps) \n\nprint (f\"\\nSaving model ST-{backbone}-trained...\")\nmodel.save (f\"{work_path}/ST-{backbone}-trained\")\nprint (\"Model saved.\")","metadata":{"execution":{"iopub.status.busy":"2023-01-20T11:14:04.729237Z","iopub.execute_input":"2023-01-20T11:14:04.729631Z","iopub.status.idle":"2023-01-20T11:15:25.602049Z","shell.execute_reply.started":"2023-01-20T11:14:04.729596Z","shell.execute_reply":"2023-01-20T11:15:25.600433Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"\nTraining model with 111967 sentences and MultipleNegativesRankingLoss(\n  (model): SentenceTransformer(\n    (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n    (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n    (2): Normalize()\n  )\n  (cross_entropy_loss): CrossEntropyLoss()\n)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d643c2c1bb924b28a1c111686e96e6a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/4374 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf61afd8739f4d53a96d61f81399c398"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/2942940690.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m model.fit(train_objectives=[(train_dataloader, train_loss)],\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m           warmup_steps=warmup_steps) \n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nSaving model ST-{backbone}-trained...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit)\u001b[0m\n\u001b[1;32m    720\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m                         \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m                         \u001b[0mloss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m                         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{"id":"8qMs56xlGurY"},"execution_count":null,"outputs":[]}]}